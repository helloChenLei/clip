---
title: "æ„å»ºé€šç”¨AIçˆ¬è™«"
date: 2023-12-22T13:09:36+08:00
updated: 2023-12-22T13:09:36+08:00
taxonomies:
  tags: []
extra:
  source: https://timconnors.co/posts/ai-scraper
  hostname: timconnors.co
  author: 
  original_title: "Building a Universal AI Scraper"
  original_lang: en
---

> #CM æˆ‘æ²¡æœ‰å°è¯•ï¼Œä½†æ˜¯è¿™ä¸ªæ€è·¯å€¼å¾—æˆ‘å­¦ä¹ ã€‚ 

I've been getting into web-scrapers recently, and with everything happening in AI, I thought it might be interesting to try and build a 'universal' scraper, that can navigate the web iteratively until it finds what it's looking for.  

æˆ‘æœ€è¿‘ä¸€ç›´åœ¨ç ”ç©¶ç½‘ç»œæŠ“å–å™¨ï¼Œéšç€äººå·¥æ™ºèƒ½çš„å‘å±•ï¼Œæˆ‘è§‰å¾—å°è¯•æ„å»ºä¸€ä¸ª "é€šç”¨ "æŠ“å–å™¨å¯èƒ½ä¼šå¾ˆæœ‰è¶£ï¼Œå®ƒå¯ä»¥åå¤æµè§ˆç½‘ç»œï¼Œç›´åˆ°æ‰¾åˆ°å®ƒè¦æ‰¾çš„ä¸œè¥¿ã€‚  

This is a work in progress, but I thought I'd share my progress so far.  

è¿™æ˜¯ä¸€é¡¹æ­£åœ¨è¿›è¡Œä¸­çš„å·¥ä½œï¼Œä½†æˆ‘æƒ³æˆ‘åº”è¯¥åˆ†äº«ä¸€ä¸‹ç›®å‰çš„è¿›å±•ã€‚

## The Spec  

è§„æ ¼

Given a starting URL and a high-level goal, the web scraper should be able to:  

ç»™å®šä¸€ä¸ªèµ·å§‹ URL å’Œä¸€ä¸ªé«˜çº§ç›®æ ‡åï¼Œç½‘ç»œåˆ®æ“¦å™¨åº”èƒ½å¤Ÿ

1.  Analyze a given web page  
    
    åˆ†ææŒ‡å®šç½‘é¡µ
2.  Extract text information from any relevant parts  
    
    ä»ä»»ä½•ç›¸å…³éƒ¨åˆ†æå–æ–‡æœ¬ä¿¡æ¯
3.  Perform any necessary interactions  
    
    è¿›è¡Œå¿…è¦çš„äº’åŠ¨
4.  Repeat until the goal is reached  
    
    é‡å¤ï¼Œç›´åˆ°è¾¾åˆ°ç›®æ ‡

## The Tools  

å·¥å…·

Although this is a strictly backend project, I decided to use NextJs to build this, in case I want to tack on a frontend later.  

è™½ç„¶è¿™æ˜¯ä¸€ä¸ªä¸¥æ ¼æ„ä¹‰ä¸Šçš„åç«¯é¡¹ç›®ï¼Œä½†æˆ‘è¿˜æ˜¯å†³å®šä½¿ç”¨ NextJs æ¥æ„å»ºå®ƒï¼Œä»¥å¤‡æ—¥åæ·»åŠ å‰ç«¯æ—¶ä½¿ç”¨ã€‚  

For my web crawling library I decided to use [Crawlee](https://crawlee.dev/), which offers a wrapper around [Playwright](https://playwright.dev/), a browser automation library.  

å¯¹äºæˆ‘çš„ç½‘ç»œçˆ¬è™«åº“ï¼Œæˆ‘å†³å®šä½¿ç”¨ Crawleeï¼Œå®ƒæä¾›äº†ä¸€ä¸ªæµè§ˆå™¨è‡ªåŠ¨åŒ–åº“ Playwright çš„å°è£…ã€‚  

Crawlee adds enhancements to the browser automation, making it easier to disguise the scraper as a human user.  

Crawlee å¢å¼ºäº†æµè§ˆå™¨çš„è‡ªåŠ¨åŒ–åŠŸèƒ½ï¼Œä½¿åˆ®æ“¦ç¨‹åºæ›´å®¹æ˜“ä¼ªè£…æˆäººç±»ç”¨æˆ·ã€‚  

They also offer a convenient request queue for managing the order of requests, which would be super helpful in cases where I want to deploy this for others to use.  

ä»–ä»¬è¿˜æä¾›äº†ä¸€ä¸ªæ–¹ä¾¿çš„è¯·æ±‚é˜Ÿåˆ—æ¥ç®¡ç†è¯·æ±‚çš„é¡ºåºï¼Œè¿™åœ¨æˆ‘æƒ³å°†å…¶éƒ¨ç½²ç»™å…¶ä»–äººä½¿ç”¨æ—¶ä¼šéå¸¸æœ‰ç”¨ã€‚

For the AI bits, I'm using [OpenAI](https://platform.openai.com/docs/api-reference/introduction)'s API as well as Microsoft Azure's [OpenAI Service](https://azure.microsoft.com/en-us/products/ai-services/openai-service). Across both of these API's, I'm using a total of three different models:  

åœ¨äººå·¥æ™ºèƒ½æ–¹é¢ï¼Œæˆ‘ä½¿ç”¨äº† OpenAI çš„ API å’Œ Microsoft Azure çš„ OpenAI æœåŠ¡ã€‚åœ¨è¿™ä¸¤ä¸ª API ä¸­ï¼Œæˆ‘æ€»å…±ä½¿ç”¨äº†ä¸‰ç§ä¸åŒçš„æ¨¡å‹ï¼š

-   GPT-4-32k ('gpt-4-32k')  
    
    GPT-4-32kï¼ˆ"gpt-4-32kï¼‰
-   GPT-4-Turbo ('gpt-4-1106-preview')
-   GPT-4-Turbo-Vision ('gpt-4-vision-preview')

The GPT-4-Turbo models are like the original GPT-4, but with a much greater context window (128k tokens) and much greater speed (up to 10x).  

GPT-4-Turbo å‹å·ä¸æœ€åˆçš„ GPT-4 ç±»ä¼¼ï¼Œä½†ä¸Šä¸‹æ–‡çª—å£æ›´å¤§ï¼ˆ128k ä¸ª tokenï¼‰ï¼Œé€Ÿåº¦æ›´å¿«ï¼ˆé«˜è¾¾ 10 å€ï¼‰ã€‚  

Unfortunately, these improvements have come at a cost: the GPT-4-Turbo models are slightly dumber than the original GPT-4. This became a problem for me in the more complex stages of my crawler, so I began to employ GPT-4-32K when I needed more intelligence.  

é—æ†¾çš„æ˜¯ï¼Œè¿™äº›æ”¹è¿›æ˜¯æœ‰ä»£ä»·çš„ï¼šGPT-4-Turbo å‹å·æ¯”æœ€åˆçš„ GPT-4 ç¨å¾®ç¬¨äº†ä¸€ç‚¹ã€‚åœ¨æˆ‘çš„çˆ¬è¡Œå™¨è¾ƒä¸ºå¤æ‚çš„é˜¶æ®µï¼Œè¿™å°±æˆäº†ä¸€ä¸ªé—®é¢˜ï¼Œå› æ­¤åœ¨éœ€è¦æ›´å¤šæ™ºèƒ½æ—¶ï¼Œæˆ‘å¼€å§‹ä½¿ç”¨ GPT-4-32Kã€‚

GPT-4-32K is a variant of the original GPT-4 model, but with a 32k context window instead of 4k.  

GPT-4-32K æ˜¯åŸå§‹ GPT-4 æ¨¡å¼çš„å˜ç§ï¼Œä½†å…¶ä¸Šä¸‹æ–‡çª—å£ä¸º 32k è€Œä¸æ˜¯ 4kã€‚  

(I ended up using Azure's OpenAI service to access GPT-4-32K, since OpenAI is currently limiting access to that model on their own platform)  

(æˆ‘æœ€ç»ˆä½¿ç”¨ Azure çš„ OpenAI æœåŠ¡è®¿é—® GPT-4-32Kï¼Œå› ä¸º OpenAI ç›®å‰é™åˆ¶åœ¨è‡ªå·±çš„å¹³å°ä¸Šè®¿é—®è¯¥æ¨¡å‹ï¼‰

## Getting Started  

å…¥é—¨

I started by working backwards from my constraints.  

æˆ‘é¦–å…ˆä»æˆ‘çš„åˆ¶çº¦å› ç´ å¼€å§‹å€’æ¨ã€‚  

Since I was using a Playwright crawler under the hood, I knew that I would eventually need an element selector from the page if I was going to interact with it.  

ç”±äºæˆ‘åœ¨å¼•æ“ç›–ä¸‹ä½¿ç”¨çš„æ˜¯ Playwright çˆ¬è™«ï¼Œæˆ‘çŸ¥é“å¦‚æœè¦ä¸é¡µé¢äº¤äº’ï¼Œæœ€ç»ˆéœ€è¦ä»é¡µé¢ä¸­è·å–å…ƒç´ é€‰æ‹©å™¨ã€‚

If you're unfamiliar, an element selector is a string that identifies a specific element on a page.  

å¦‚æœä½ ä¸ç†Ÿæ‚‰ï¼Œå…ƒç´ é€‰æ‹©å™¨æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œç”¨äºè¯†åˆ«é¡µé¢ä¸Šçš„ç‰¹å®šå…ƒç´ ã€‚  

If I wanted to select the 4th paragraph on a page, I could use the selector `p:nth-of-type(4)`. If I wanted to select a button with the text 'Click Me', I could use the selector `button:has-text('Click Me')`.  

å¦‚æœæˆ‘æƒ³é€‰æ‹©é¡µé¢ä¸Šçš„ç¬¬ 4 æ®µï¼Œå¯ä»¥ä½¿ç”¨é€‰æ‹©å™¨ `p:nth-of-type(4)` ã€‚å¦‚æœæˆ‘æƒ³é€‰æ‹©ä¸€ä¸ªæ–‡æœ¬ä¸º "ç‚¹å‡»æˆ‘ "çš„æŒ‰é’®ï¼Œå¯ä»¥ä½¿ç”¨é€‰æ‹©å™¨ `button:has-text('Click Me')` ã€‚  

Playwright works by first identifying the element you want to interact with using a selector, and then performing an action on it, like 'click()' or 'fill()'.  

Playwright çš„å·¥ä½œåŸç†æ˜¯ï¼Œé¦–å…ˆä½¿ç”¨é€‰æ‹©å™¨ç¡®å®šè¦ä¸ä¹‹äº¤äº’çš„å…ƒç´ ï¼Œç„¶åå¯¹å…¶æ‰§è¡Œæ“ä½œï¼Œå¦‚ "click() "æˆ– "fill()"ã€‚

Given this, my first task was to figure out how to identify the 'element of interest' from a given web page.  

æœ‰é‰´äºæ­¤ï¼Œæˆ‘çš„ç¬¬ä¸€é¡¹ä»»åŠ¡å°±æ˜¯æƒ³åŠæ³•ä»ç»™å®šçš„ç½‘é¡µä¸­æ‰¾å‡º "æ„Ÿå…´è¶£çš„å…ƒç´ "ã€‚  

From here on out, I'll refer to this function as 'GET\_ELEMENT'.  

ä»è¿™é‡Œå¼€å§‹ï¼Œæˆ‘å°†æŠŠè¿™ä¸ªå‡½æ•°ç§°ä¸º "GET\_ELEMENT"ã€‚

## Getting the Element of Interest  

è·å–å…´è¶£å…ƒç´ 

### Approach 1: Screenshot + Vision Model  

æ–¹æ³• 1ï¼šæˆªå›¾ + è§†è§‰æ¨¡å‹

HTML data can be extremely intricate and long.  

HTML æ•°æ®å¯èƒ½éå¸¸å¤æ‚å’Œå†—é•¿ã€‚  

Most of it tends to be dedicated to styling, layout, and interactive logic, rather than the text content itself.  

å®ƒçš„å¤§éƒ¨åˆ†å†…å®¹å¾€å¾€ç”¨äºæ ·å¼è®¾è®¡ã€å¸ƒå±€å’Œäº¤äº’é€»è¾‘ï¼Œè€Œä¸æ˜¯æ–‡æœ¬å†…å®¹æœ¬èº«ã€‚  

I feared that text models would perform poorly in such a situation, so I thought I'd circumvent all that by using the GPT-4-Turbo-Vision model to simply 'look' at the rendered page and transcribe the most relevant text from it.  

æˆ‘æ‹…å¿ƒæ–‡æœ¬æ¨¡å‹åœ¨è¿™ç§æƒ…å†µä¸‹ä¼šè¡¨ç°ä¸ä½³ï¼Œæ‰€ä»¥æˆ‘æƒ³ä½¿ç”¨ GPT-4-Turbo-Vision æ¨¡å‹æ¥è§„é¿è¿™ä¸€åˆ‡ï¼Œå®ƒå¯ä»¥ç®€å•åœ° "æŸ¥çœ‹ "æ¸²æŸ“çš„é¡µé¢ï¼Œå¹¶ä»ä¸­è½¬å½•æœ€ç›¸å…³çš„æ–‡æœ¬ã€‚  

Then I could search through the raw HTML for the element that contained that text.  

ç„¶åï¼Œæˆ‘å°±å¯ä»¥åœ¨åŸå§‹ HTML ä¸­æœç´¢åŒ…å«è¯¥æ–‡æœ¬çš„å…ƒç´ ã€‚

![Get Element Attempt 1](get_element_1.png)

This approach quickly fell apart:  

è¿™ç§æ–¹æ³•å¾ˆå¿«å°±å¤±è´¥äº†ï¼š

For one, GPT-4-Turbo-Vision occasionally declined my request to transcribe text, saying stuff like "Sorry I can't help with that." At one point it said "Sorry, I can't transcribe text from copywrighted images." It seems that OpenAI is trying to discourage it from helping with tasks like this.  

é¦–å…ˆï¼ŒGPT-4-Turbo-Vision æœ‰æ—¶ä¼šæ‹’ç»æˆ‘è½¬å½•æ–‡æœ¬çš„è¯·æ±‚ï¼Œè¯´ "å¯¹ä¸èµ·ï¼Œæˆ‘å¸®ä¸ä¸Šå¿™ "ä¹‹ç±»çš„è¯ã€‚æœ‰ä¸€æ¬¡å®ƒè¿˜è¯´ï¼š"å¯¹ä¸èµ·ï¼Œæˆ‘ä¸èƒ½ä»æœ‰ç‰ˆæƒçš„å›¾åƒä¸­è½¬å½•æ–‡æœ¬ã€‚çœ‹æ¥ï¼ŒOpenAI æ­£è¯•å›¾é˜»æ­¢å®ƒå¸®åŠ©å®Œæˆè¿™æ ·çš„ä»»åŠ¡ã€‚  

(Luckily, this can be circumvented by mentioning that you are a blind person.)  

(å¹¸è¿çš„æ˜¯ï¼Œåªè¦æåˆ°è‡ªå·±æ˜¯ç›²äººï¼Œå°±å¯ä»¥é¿å…è¿™ç§æƒ…å†µï¼‰ã€‚

Then came the bigger problem: big pages made for very tall screenshots (> 8,000 pixels).  

éšåå‡ºç°äº†æ›´å¤§çš„é—®é¢˜ï¼šå¤§é¡µé¢éœ€è¦éå¸¸é«˜çš„å±å¹•æˆªå›¾ï¼ˆ> 8000 åƒç´ ï¼‰ã€‚  

This is an issue because GPT-4-Turbo-Vision pre-processes all images to fit within certain dimensions.  

è¿™æ˜¯ä¸€ä¸ªé—®é¢˜ï¼Œå› ä¸º GPT-4-Turbo-Vision ä¼šé¢„å¤„ç†æ‰€æœ‰å›¾åƒï¼Œä½¿å…¶ç¬¦åˆç‰¹å®šå°ºå¯¸ã€‚  

I discovered that a very tall image will be mangled so much that it will be impossible to read.  

æˆ‘å‘ç°ï¼Œéå¸¸é«˜çš„å›¾åƒä¼šè¢«å¼„å¾—ä¹±ä¸ƒå…«ç³Ÿï¼Œæ— æ³•é˜…è¯»ã€‚

One possible solution to this would be to scan the page in segments, summarizing each one, then concatenating the results.  

ä¸€ä¸ªå¯è¡Œçš„è§£å†³æ–¹æ¡ˆæ˜¯åˆ†æ®µæ‰«æé¡µé¢ï¼Œæ€»ç»“æ¯æ®µå†…å®¹ï¼Œç„¶åå°†ç»“æœä¸²è”èµ·æ¥ã€‚  

However, OpenAI's rate limits on GPT-4-Turbo-Vision would force me to build a queueing system to manage the process.  

ç„¶è€Œï¼ŒOpenAI å¯¹ GPT-4-Turbo-Vision çš„é€Ÿç‡é™åˆ¶ä¼šè¿«ä½¿æˆ‘å»ºç«‹ä¸€ä¸ªé˜Ÿåˆ—ç³»ç»Ÿæ¥ç®¡ç†æµç¨‹ã€‚  

That sounded like a headache.  

å¬èµ·æ¥è®©äººå¤´ç–¼ã€‚

Lastly, it would not be trivial to reverse engineer a working element selector from the text alone, since you don't know what the underlying HTML is shaped like.  

æœ€åï¼Œç”±äºä¸çŸ¥é“åº•å±‚ HTML æ˜¯ä»€ä¹ˆå½¢çŠ¶ï¼Œå› æ­¤ä»…ä»æ–‡æœ¬ä¸­é€†å‘è®¾è®¡ä¸€ä¸ªæœ‰æ•ˆçš„å…ƒç´ é€‰æ‹©å™¨å¹¶éæ˜“äº‹ã€‚  

For all of these reasons, I decided to abandon this approach.  

é‰´äºä¸Šè¿°åŸå› ï¼Œæˆ‘å†³å®šæ”¾å¼ƒè¿™ç§æ–¹æ³•ã€‚

### Approach 2: HTML + Text Model  

æ–¹æ³• 2ï¼šHTML + æ–‡æœ¬æ¨¡å¼

The rate limits for the text-only GPT-4-Turbo are more generous, and with the 128k context window, I thought I'd try simply passing in the entire HTML of the page, and ask it to identify the relevant elements.  

çº¯æ–‡æœ¬ GPT-4-Turbo çš„é€Ÿç‡é™åˆ¶æ¯”è¾ƒå®½æ¾ï¼Œè€Œä¸”æœ‰ 128k çš„ä¸Šä¸‹æ–‡çª—å£ï¼Œæˆ‘æƒ³æˆ‘å¯ä»¥å°è¯•ç®€å•åœ°ä¼ å…¥æ•´ä¸ªé¡µé¢çš„ HTMLï¼Œå¹¶è¦æ±‚å®ƒè¯†åˆ«ç›¸å…³å…ƒç´ ã€‚

![Get Element Attempt 2](get_element_2.png)

Although the HTML data fit (most of the time), I discovered that the GPT-4-Turbo models were just not smart enough to do this right.  

è™½ç„¶ HTML æ•°æ®ç¬¦åˆè¦æ±‚ï¼ˆå¤§å¤šæ•°æƒ…å†µä¸‹ï¼‰ï¼Œä½†æˆ‘å‘ç° GPT-4 æ¶¡è½®å¢å‹æ¨¡å‹ä¸å¤Ÿèªæ˜ï¼Œæ— æ³•åšåˆ°è¿™ä¸€ç‚¹ã€‚  

They would often identify the wrong element, or give me a selector that was too broad.  

ä»–ä»¬ç»å¸¸ä¼šè¯†åˆ«é”™è¯¯çš„å…ƒç´ ï¼Œæˆ–è€…ç»™æˆ‘ä¸€ä¸ªè¿‡äºå®½æ³›çš„é€‰æ‹©å™¨ã€‚

So I tried to reduce the HTML by isolating the body and removing script and style tags, and although this helped, it still wasn't enough.  

å› æ­¤ï¼Œæˆ‘è¯•å›¾é€šè¿‡éš”ç¦»æ­£æ–‡ã€åˆ é™¤è„šæœ¬å’Œæ ·å¼æ ‡è®°æ¥å‡å°‘ HTML çš„å†…å®¹ï¼Œè™½ç„¶è¿™æ ·åšæœ‰æ‰€å¸®åŠ©ï¼Œä½†ä»ç„¶ä¸å¤Ÿã€‚  

It seems that identifying "relevant" HTML elements from a full page is just too fuzzy and obscure for language models to do well.  

ä»æ•´ä¸ªé¡µé¢ä¸­è¯†åˆ« "ç›¸å…³çš„ "HTML å…ƒç´ ä¼¼ä¹è¿‡äºæ¨¡ç³Šå’Œæ™¦æ¶©ï¼Œè¯­è¨€æ¨¡å‹æ— æ³•å¾ˆå¥½åœ°åšåˆ°è¿™ä¸€ç‚¹ã€‚  

I needed some way to drill down to just a handful of elements I could hand to the text model.  

æˆ‘éœ€è¦æ‰¾åˆ°ä¸€ç§æ–¹æ³•ï¼Œå°†å°‘é‡å…ƒç´ æ·±å…¥åˆ°æ–‡æœ¬æ¨¡å‹ä¸­ã€‚

For this next approach, I decided to take inspiration from how humans might approach this problem.  

å¯¹äºä¸‹ä¸€ä¸ªæ–¹æ³•ï¼Œæˆ‘å†³å®šä»äººç±»å¦‚ä½•å¤„ç†è¿™ä¸ªé—®é¢˜ä¸­æ±²å–çµæ„Ÿã€‚

### Approach 3: HTML + Text Search + Text Model  

æ–¹æ³• 3ï¼šHTML + æ–‡æœ¬æœç´¢ + æ–‡æœ¬æ¨¡å‹

If I were looking for specific information on a web page, I would use 'Control' + 'F' to search for a keyword.  

å¦‚æœè¦æŸ¥æ‰¾ç½‘é¡µä¸Šçš„ç‰¹å®šä¿¡æ¯ï¼Œæˆ‘ä¼šä½¿ç”¨ "Control "+"F "æ¥æœç´¢å…³é”®å­—ã€‚  

If I didn't find matches on my first attempt, I would try different keywords until I found what I was looking for.  

å¦‚æœç¬¬ä¸€æ¬¡å°è¯•æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„å…³é”®è¯ï¼Œæˆ‘å°±ä¼šå°è¯•ä¸åŒçš„å…³é”®è¯ï¼Œç›´åˆ°æ‰¾åˆ°æˆ‘è¦æ‰¾çš„å…³é”®è¯ä¸ºæ­¢ã€‚

The benefit of this approach is that a simple text search is really fast and simple to implement.  

è¿™ç§æ–¹æ³•çš„å¥½å¤„æ˜¯ï¼Œç®€å•çš„æ–‡æœ¬æœç´¢æ—¢å¿«åˆç®€å•ã€‚  

In my circumstance, the search terms could be generated with a text model, and the search itself could be performed with a simple regex search on the HTML.  

åœ¨æˆ‘çš„æƒ…å†µä¸‹ï¼Œæœç´¢æ¡ä»¶å¯ä»¥é€šè¿‡æ–‡æœ¬æ¨¡å‹ç”Ÿæˆï¼Œè€Œæœç´¢æœ¬èº«å¯ä»¥é€šè¿‡å¯¹ HTML è¿›è¡Œç®€å•çš„ regex æœç´¢æ¥å®Œæˆã€‚

Generating the terms would be much slower than conducting the search, so rather than searching terms one at a time, I could ask the text model to generate several at once, then search for them all concurrently.  

ç”Ÿæˆæœ¯è¯­æ¯”è¿›è¡Œæœç´¢è¦æ…¢å¾—å¤šï¼Œå› æ­¤æˆ‘å¯ä»¥è®©æ–‡æœ¬æ¨¡å‹ä¸€æ¬¡ç”Ÿæˆå¤šä¸ªæœ¯è¯­ï¼Œç„¶ååŒæ—¶å¯¹å®ƒä»¬è¿›è¡Œæœç´¢ï¼Œè€Œä¸æ˜¯ä¸€æ¬¡æœç´¢ä¸€ä¸ªæœ¯è¯­ã€‚  

Any HTML elements that contained a search term would be gathered up and passed to the next step, where I could ask GPT-4-32K to pick the most relevant one.  

ä»»ä½•åŒ…å«æœç´¢è¯çš„ HTML å…ƒç´ éƒ½ä¼šè¢«æ”¶é›†èµ·æ¥ï¼Œå¹¶ä¼ é€’åˆ°ä¸‹ä¸€æ­¥ï¼Œæˆ‘å¯ä»¥è®© GPT-4-32K æŒ‘é€‰å‡ºæœ€ç›¸å…³çš„å…ƒç´ ã€‚

![Get Element Attempt 3](get_element_3.png)

Of course, if you use enough search terms, you're bound to grab a lot of HTML at times, which could trigger API limits or compromise the performance of the next step, so I came up with a scheme that would intelligently fill a list of relevant elements up to a custom length.  

å½“ç„¶ï¼Œå¦‚æœä½¿ç”¨äº†è¶³å¤Ÿå¤šçš„æœç´¢æ¡ä»¶ï¼Œæœ‰æ—¶å°±ä¼šæŠ“å–å¤§é‡ HTMLï¼Œè¿™å¯èƒ½ä¼šè§¦å‘ API é™åˆ¶æˆ–å½±å“ä¸‹ä¸€æ­¥çš„æ€§èƒ½ï¼Œå› æ­¤æˆ‘æƒ³å‡ºäº†ä¸€ç§æ–¹æ¡ˆï¼Œå®ƒå¯ä»¥æ™ºèƒ½åœ°å¡«å……ç›¸å…³å…ƒç´ åˆ—è¡¨ï¼Œç›´è‡³è¾¾åˆ°è‡ªå®šä¹‰é•¿åº¦ã€‚

I asked the Turbo model to come up with 15-20 terms, ranked in order of estimated relevance.  

æˆ‘è¦æ±‚ Turbo æ¨¡å‹æå‡º 15-20 ä¸ªæœ¯è¯­ï¼ŒæŒ‰ä¼°è®¡ç›¸å…³æ€§æ’åºã€‚  

Then I would search through the HTML with a simple regex search to find every element on the page that contained that term.  

ç„¶åï¼Œæˆ‘ä¼šä½¿ç”¨ç®€å•çš„ regex æœç´¢åŠŸèƒ½æœç´¢ HTMLï¼Œæ‰¾å‡ºé¡µé¢ä¸ŠåŒ…å«è¯¥æœ¯è¯­çš„æ¯ä¸ªå…ƒç´ ã€‚  

By the end of this step I would have a list of lists, where each sublist contained all the elements that matched a given term:  

è¿™ä¸€æ­¥ç»“æŸåï¼Œæˆ‘å°†å¾—åˆ°ä¸€ä¸ªåˆ—è¡¨ï¼Œå…¶ä¸­æ¯ä¸ªå­åˆ—è¡¨éƒ½åŒ…å«ä¸ç»™å®šæœ¯è¯­åŒ¹é…çš„æ‰€æœ‰å…ƒç´ ï¼š

![List of lists](element-lists.png)

Then I would populate a final list with the elements from these lists, favoring those appearing in the earlier lists.  

ç„¶åï¼Œæˆ‘ä¼šå°†è¿™äº›åˆ—è¡¨ä¸­çš„å…ƒç´ å¡«å……åˆ°æœ€åä¸€ä¸ªåˆ—è¡¨ä¸­ï¼Œä¼˜å…ˆé€‰æ‹©å‰é¢åˆ—è¡¨ä¸­å‡ºç°çš„å…ƒç´ ã€‚  

For example, let's say that the ranked search terms are: 'pricing', 'fee', 'cost', and 'prices'.  

ä¾‹å¦‚ï¼Œæˆ‘ä»¬å‡è®¾æ’åé å‰çš„æœç´¢è¯æ˜¯ "å®šä»·"ã€"è´¹ç”¨"ã€"æˆæœ¬ "å’Œ "ä»·æ ¼"ï¼šå®šä»·"ã€"è´¹ç”¨"ã€"æˆæœ¬ "å’Œ "ä»·æ ¼"ã€‚  

When filling my final list, I would be sure to include more elements from the 'pricing' list than from the 'fee' list, and more from the 'fee' list than from the 'cost' list, and so on.  

åœ¨å¡«å†™æœ€ç»ˆæ¸…å•æ—¶ï¼Œæˆ‘ä¼šç¡®ä¿ "å®šä»· "æ¸…å•ä¸­çš„å†…å®¹å¤šäº "è´¹ç”¨ "æ¸…å•ä¸­çš„å†…å®¹ï¼Œ"è´¹ç”¨ "æ¸…å•ä¸­çš„å†…å®¹å¤šäº "æˆæœ¬ "æ¸…å•ä¸­çš„å†…å®¹ï¼Œä»¥æ­¤ç±»æ¨ã€‚

Once the final list hit the predefined token length, I would stop filling it.  

ä¸€æ—¦æœ€ç»ˆåˆ—è¡¨è¾¾åˆ°é¢„å®šä¹‰çš„æ ‡è®°é•¿åº¦ï¼Œæˆ‘å°±ä¼šåœæ­¢å¡«å……ã€‚  

This way, I could be sure that I would never exceed the token limit for the next step.  

è¿™æ ·ï¼Œæˆ‘å°±èƒ½ç¡®ä¿ä¸‹ä¸€ä¸ªæ­¥éª¤ä¸ä¼šè¶…è¿‡ä»¤ç‰Œé™é¢ã€‚

![Final list](final-list.png)

If you're curious what the code looked like for this algorithm, here's a simplified version:  

å¦‚æœä½ æƒ³çŸ¥é“è¿™ç§ç®—æ³•çš„ä»£ç æ˜¯ä»€ä¹ˆæ ·çš„ï¼Œè¿™é‡Œæœ‰ä¸€ä¸ªç®€åŒ–ç‰ˆæœ¬ï¼š

![Get Elements Algorithm](get-elements.png)

This approach allowed me to end up with a list of manageable length that represented matching elements from a variety of search terms, yet favoring terms that were ranked higher in relevance.  

é€šè¿‡è¿™ç§æ–¹æ³•ï¼Œæˆ‘æœ€ç»ˆå¾—åˆ°äº†ä¸€ä¸ªé•¿åº¦å¯æ§çš„åˆ—è¡¨ï¼Œå®ƒä»£è¡¨äº†æ¥è‡ªå„ç§æœç´¢è¯çš„åŒ¹é…å…ƒç´ ï¼Œä½†æ›´å€¾å‘äºç›¸å…³æ€§æ’åè¾ƒé«˜çš„è¯ã€‚

Then came another snag: sometimes the information you need isn't in the matching element itself, but in a sibling or parent element.  

ç„¶ååˆå‡ºç°äº†å¦ä¸€ä¸ªéšœç¢ï¼šæœ‰æ—¶ä½ éœ€è¦çš„ä¿¡æ¯å¹¶ä¸åœ¨åŒ¹é…å…ƒç´ ä¸­ï¼Œè€Œæ˜¯åœ¨åŒçº§å…ƒç´ æˆ–çˆ¶çº§å…ƒç´ ä¸­ã€‚

Let's say that my AI is trying to find out the capital of Cuba.  

å‡è®¾æˆ‘çš„äººå·¥æ™ºèƒ½æ­£è¯•å›¾æ‰¾å‡ºå¤å·´çš„é¦–éƒ½ã€‚  

It would search the word 'capital' and find this element in orange.  

å®ƒä¼šæœç´¢ "èµ„æœ¬ "ä¸€è¯ï¼Œå¹¶åœ¨æ©™è‰²ä¸­æ‰¾åˆ°è¯¥å…ƒç´ ã€‚  

The problem is that the information we need is in the green element - a sibling.  

é—®é¢˜æ˜¯ï¼Œæˆ‘ä»¬éœ€è¦çš„ä¿¡æ¯åœ¨ç»¿è‰²å…ƒç´ ä¸­ï¼Œå³åŒçº§å…ƒç´ ä¸­ã€‚  

We've gotten close to the answer, but without including both elements, we won't be able to solve the problem.  

æˆ‘ä»¬å·²ç»æ¥è¿‘äº†ç­”æ¡ˆï¼Œä½†å¦‚æœä¸æŠŠè¿™ä¸¤ä¸ªè¦ç´ éƒ½åŒ…æ‹¬åœ¨å†…ï¼Œæˆ‘ä»¬å°±æ— æ³•è§£å†³é—®é¢˜ã€‚

![Sibling Problem](sibling.png)

To solve this problem, I decided include 'parents' as an optional parameter in my element search function.  

ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘å†³å®šåœ¨å…ƒç´ æœç´¢åŠŸèƒ½ä¸­åŠ å…¥ "çˆ¶æ¯ "ä½œä¸ºå¯é€‰å‚æ•°ã€‚  

Setting a parent of 0 meant that the search function would return only the element that directly contained the text (which natually includes the children of that element).  

å°†çˆ¶å…ƒç´ è®¾ç½®ä¸º 0 æ„å‘³ç€æœç´¢åŠŸèƒ½åªè¿”å›ç›´æ¥åŒ…å«æ–‡æœ¬çš„å…ƒç´ ï¼ˆè‡ªç„¶åŒ…æ‹¬è¯¥å…ƒç´ çš„å­å…ƒç´ ï¼‰ã€‚

Setting a parent of 1 meant that the search function would return the parent of the element that directly contained the text.  

å°†çˆ¶å…ƒç´ è®¾ç½®ä¸º 1 æ„å‘³ç€æœç´¢åŠŸèƒ½å°†è¿”å›ç›´æ¥åŒ…å«æ–‡æœ¬çš„å…ƒç´ çš„çˆ¶å…ƒç´ ã€‚  

Setting a parent of 2 meant that the search function would return the grandparent of the element that directly contained the text, and so on.  

å°†çˆ¶å…ƒç´ è®¾ç½®ä¸º 2 æ„å‘³ç€æœç´¢åŠŸèƒ½å°†è¿”å›ç›´æ¥åŒ…å«æ–‡æœ¬çš„å…ƒç´ çš„çˆ¶å…ƒç´ ï¼Œä»¥æ­¤ç±»æ¨ã€‚

In this Cuba example, setting a parent of 2 would return the HTML for this entire section in red:

  

åœ¨å¤å·´çš„è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œå¦‚æœçˆ¶çº§è®¾ç½®ä¸º 2ï¼Œåˆ™æ•´ä¸ªéƒ¨åˆ†çš„ HTML ä»£ç éƒ½å°†æ˜¾ç¤ºä¸ºçº¢è‰²ï¼š

![Parent Grandparent](parent-grandparent.png)

I decided to set the default parent to 1. Any higher and I could be grabbing huge amounts of HTML per match.  

æˆ‘å†³å®šå°†é»˜è®¤çˆ¶çº§è®¾ç½®ä¸º 1ã€‚å¦‚æœè®¾ç½®å¾—æ›´é«˜ï¼Œæˆ‘å¯èƒ½ä¼šåœ¨æ¯æ¬¡åŒ¹é…ä¸­æŠ“å–å¤§é‡ HTMLã€‚

So now that we've gotten a list of manageable size, with a helpful amount of parent context, it was time to move to the next step: I wanted to ask GPT-4-32K to pick the most relevant element from this list.  

ç°åœ¨ï¼Œæˆ‘ä»¬å·²ç»å¾—åˆ°äº†ä¸€ä¸ªå¤§å°é€‚ä¸­ã€åŒ…å«å¤§é‡çˆ¶çº§ä¸Šä¸‹æ–‡çš„åˆ—è¡¨ï¼Œæ˜¯æ—¶å€™è¿›å…¥ä¸‹ä¸€æ­¥äº†ï¼šæˆ‘æƒ³è®© GPT-4-32K ä»åˆ—è¡¨ä¸­æŒ‘é€‰å‡ºæœ€ç›¸å…³çš„å…ƒç´ ã€‚

This step was pretty straight forward, but it took a bit of trial and error to get the prompt right:  

è¿™ä¸€æ­¥éå¸¸ç®€å•ï¼Œä½†è¦æƒ³æ­£ç¡®è®¾ç½®æç¤ºéŸ³ï¼Œè¿˜éœ€è¦åå¤è¯•éªŒï¼š

![Pick Element Promopt](pick-element-prompt.png)

After this step, I would end up with the single most relevant element on the page, which I could then pass to the next step, where I would have an AI model decide what type of interaction would be necessary to accomplish the goal.  

å®Œæˆè¿™ä¸€æ­¥åï¼Œæˆ‘å°†å¾—åˆ°é¡µé¢ä¸Šæœ€ç›¸å…³çš„ä¸€ä¸ªå…ƒç´ ï¼Œç„¶åå°†å…¶ä¼ é€’ç»™ä¸‹ä¸€æ­¥ï¼Œç”±äººå·¥æ™ºèƒ½æ¨¡å‹å†³å®šå®Œæˆç›®æ ‡æ‰€éœ€çš„äº¤äº’ç±»å‹ã€‚

## Setting up an Assistant  

è®¾ç½®åŠ©ç†

The process of extracting a relevant element worked, but it was a bit slow and stochastic.  

æå–ç›¸å…³å…ƒç´ çš„è¿‡ç¨‹æ˜¯æœ‰æ•ˆçš„ï¼Œä½†æœ‰ç‚¹ç¼“æ…¢å’Œéšæœºã€‚  

What I needed at this point was a sort of 'planner' AI that could see the result of the previous step and try it again with different search terms if it didn't work well.  

æ­¤æ—¶ï¼Œæˆ‘éœ€è¦çš„æ˜¯ä¸€ç§ "è§„åˆ’è€… "äººå·¥æ™ºèƒ½ï¼Œå®ƒå¯ä»¥çœ‹åˆ°å‰ä¸€æ­¥çš„ç»“æœï¼Œå¦‚æœæ•ˆæœä¸ä½³ï¼Œå¯ä»¥ç”¨ä¸åŒçš„æœç´¢æ¡ä»¶å†è¯•ä¸€æ¬¡ã€‚

Luckily, this is exactly what OpenAI's [Assistant API](https://platform.openai.com/docs/assistants/overview) helps accomplish.  

å¹¸è¿çš„æ˜¯ï¼Œè¿™æ­£æ˜¯ OpenAI çš„åŠ©æ‰‹åº”ç”¨ç¨‹åºæ¥å£ï¼ˆAssistant APIï¼‰æ‰€èƒ½å¸®åŠ©å®ç°çš„ã€‚  

An 'Assistant' is a model wrapped in extra logic that allows it to operate autonomously, using custom tools, until a goal is reached.  

åŠ©æ‰‹ "æ˜¯ä¸€ä¸ªè¢«é¢å¤–é€»è¾‘åŒ…è£¹çš„æ¨¡å‹ï¼Œå®ƒå¯ä»¥ä½¿ç”¨è‡ªå®šä¹‰å·¥å…·è‡ªä¸»è¿è¡Œï¼Œç›´åˆ°è¾¾åˆ°ç›®æ ‡ã€‚  

You initialize one by setting the underlying model type, defining the list of tools it can use, and sending it messages.  

æ‚¨å¯ä»¥é€šè¿‡è®¾ç½®åº•å±‚æ¨¡å‹ç±»å‹ã€å®šä¹‰å®ƒå¯ä»¥ä½¿ç”¨çš„å·¥å…·åˆ—è¡¨ä»¥åŠå‘å®ƒå‘é€æ¶ˆæ¯æ¥åˆå§‹åŒ–ä¸€ä¸ªæ¨¡å‹ã€‚

Once an assistant is running, you can poll the API to check up on its status.  

åŠ©æ‰‹è¿è¡Œåï¼Œæ‚¨å¯ä»¥è½®è¯¢åº”ç”¨ç¨‹åºæ¥å£æ¥æ£€æŸ¥å…¶çŠ¶æ€ã€‚  

If it has decided to use a custom tool, the status will indicate the tool it wants to use with the parameters it wants to use it with.  

å¦‚æœå†³å®šä½¿ç”¨è‡ªå®šä¹‰å·¥å…·ï¼Œåˆ™çŠ¶æ€å°†æ˜¾ç¤ºè¦ä½¿ç”¨çš„å·¥å…·åŠå…¶å‚æ•°ã€‚  

That's when you can generate the tool output and pass it back to the assistant so it can continue.  

è¿™æ—¶ä½ å°±å¯ä»¥ç”Ÿæˆå·¥å…·è¾“å‡ºï¼Œå¹¶å°†å…¶ä¼ å›åŠ©æ‰‹ï¼Œè®©å®ƒç»§ç»­å·¥ä½œã€‚

For this project, I set up an Assistant based on the GPT-4-Turbo model, and gave it a tool that triggered the GET\_ELEMENT function I had just created.  

åœ¨è¿™ä¸ªé¡¹ç›®ä¸­ï¼Œæˆ‘å»ºç«‹äº†ä¸€ä¸ªåŸºäº GPT-4-Turbo æ¨¡å‹çš„åŠ©æ‰‹ï¼Œå¹¶ä¸ºå®ƒæä¾›äº†ä¸€ä¸ªè§¦å‘æˆ‘åˆšåˆšåˆ›å»ºçš„ GET\_ELEMENT å‡½æ•°çš„å·¥å…·ã€‚

Here's the description I provided for the GET\_ELEMENT tool:  

ä»¥ä¸‹æ˜¯æˆ‘ä¸º GET\_ELEMENT å·¥å…·æä¾›çš„è¯´æ˜ï¼š

![Get Element Tool](get-element-tool.png)

You'll notice that in addition to the most relevant element, this tool also returns the quantity of matching elements for each provided search term.  

ä½ ä¼šå‘ç°ï¼Œé™¤äº†æœ€ç›¸å…³çš„å…ƒç´ å¤–ï¼Œè¯¥å·¥å…·è¿˜ä¼šè¿”å›æ¯ä¸ªæœç´¢è¯çš„åŒ¹é…å…ƒç´ æ•°é‡ã€‚  

This information helped the Assistant decide whether or not to try again with different search terms.  

è¿™äº›ä¿¡æ¯æœ‰åŠ©äºåŠ©ç†å†³å®šæ˜¯å¦ä½¿ç”¨ä¸åŒçš„æœç´¢æ¡ä»¶å†æ¬¡å°è¯•ã€‚

With this one tool, the Assistant was now capable of solving the first two steps of my spec: Analyzing a given web page and extracting text information from any relevant parts.  

æœ‰äº†è¿™ä¸€ä¸ªå·¥å…·ï¼Œ"åŠ©ç† "ç°åœ¨å°±èƒ½è§£å†³æˆ‘çš„è§„èŒƒä¸­çš„å‰ä¸¤ä¸ªæ­¥éª¤ï¼šåˆ†æç»™å®šçš„ç½‘é¡µï¼Œå¹¶ä»ä»»ä½•ç›¸å…³éƒ¨åˆ†æå–æ–‡æœ¬ä¿¡æ¯ã€‚  

In cases where there's no need to actually interact with the page, this is all that's needed.  

åœ¨ä¸éœ€è¦ä¸é¡µé¢è¿›è¡Œå®é™…äº¤äº’çš„æƒ…å†µä¸‹ï¼Œåªéœ€è¿™æ ·åšå³å¯ã€‚  

If we want to know the pricing of a product, and the pricing info is contained in the element returned by our tool, the Assistant can simply return the text from that element and be done with it.  

å¦‚æœæˆ‘ä»¬æƒ³çŸ¥é“äº§å“çš„å®šä»·ï¼Œè€Œå®šä»·ä¿¡æ¯åŒ…å«åœ¨æˆ‘ä»¬çš„å·¥å…·è¿”å›çš„å…ƒç´ ä¸­ï¼ŒåŠ©ç†åªéœ€è¿”å›è¯¥å…ƒç´ çš„æ–‡æœ¬å³å¯ã€‚

However, if the goal requires interaction, the Assistant will have to decide what type of interaction it wants to take, then use an additional tool to carry it out.  

ä½†æ˜¯ï¼Œå¦‚æœç›®æ ‡éœ€è¦äº’åŠ¨ï¼ŒåŠ©ç†å°±å¿…é¡»å†³å®šè¦è¿›è¡Œå“ªç§ç±»å‹çš„äº’åŠ¨ï¼Œç„¶åä½¿ç”¨é¢å¤–çš„å·¥å…·æ¥æ‰§è¡Œã€‚  

I refer to this additional tool as 'INTERACT\_WITH\_ELEMENT'  

æˆ‘å°†è¿™ä¸€é™„åŠ å·¥å…·ç§°ä¸º "INTERACT\_WITH\_ELEMENT"ã€‚

## Interacting with the Relevant Element  

ä¸ç›¸å…³å…ƒç´ äº’åŠ¨

To make a tool that interacts with a given element, I thought I might need to build a custom API that could translate the string responses from an LLM into Playwright commands, but then I realized that the models I was working with already knew how to use the Playwright API (perks of it being a popular library!).  

ä¸ºäº†åˆ¶ä½œä¸€ä¸ªèƒ½ä¸ç»™å®šå…ƒç´ äº¤äº’çš„å·¥å…·ï¼Œæˆ‘æƒ³æˆ‘å¯èƒ½éœ€è¦æ„å»ºä¸€ä¸ªè‡ªå®šä¹‰ APIï¼Œå°† LLM çš„å­—ç¬¦ä¸²å“åº”è½¬æ¢æˆ Playwright å‘½ä»¤ï¼Œä½†åæ¥æˆ‘æ„è¯†åˆ°ï¼Œæˆ‘æ­£åœ¨ä½¿ç”¨çš„æ¨¡å‹å·²ç»çŸ¥é“å¦‚ä½•ä½¿ç”¨ Playwright APIï¼ˆè¿™æ˜¯ Playwright API æˆä¸ºæµè¡Œåº“çš„å¥½å¤„ï¼ï¼‰ã€‚  

So I decided to simply generate the commands directly in the form of an async immediately-invoked function expression (IIFE).  

å› æ­¤ï¼Œæˆ‘å†³å®šç›´æ¥ä»¥å¼‚æ­¥ç«‹å³è°ƒç”¨å‡½æ•°è¡¨è¾¾å¼ï¼ˆIIFEï¼‰çš„å½¢å¼ç”Ÿæˆå‘½ä»¤ã€‚

Thus, the plan became:  

äºæ˜¯ï¼Œè®¡åˆ’å˜æˆäº†

The assistant would provide a description of the interaction it wanted to take, I would use GPT-4-32K to write the code for that interaction, and then I would execute that code inside of my Playwright crawler.  

åŠ©æ‰‹ä¼šæä¾›å®ƒæƒ³è¦è¿›è¡Œçš„äº¤äº’æè¿°ï¼Œæˆ‘ä¼šä½¿ç”¨ GPT-4-32K ç¼–å†™äº¤äº’ä»£ç ï¼Œç„¶ååœ¨ Playwright çˆ¬è™«ä¸­æ‰§è¡Œè¯¥ä»£ç ã€‚

![Interact With Element Tool](interact_with_website.png)

Here's the description I provided for the INTERACT\_WITH\_ELEMENT tool:  

ä»¥ä¸‹æ˜¯æˆ‘ä¸º INTERACT\_WITH\_ELEMENT å·¥å…·æä¾›çš„è¯´æ˜ï¼š

![Interact With Element Tool Instructions](interact-with-element-tool.png)

You'll notice that instead of having the assistant write out the full element, it simply provides a short identifier, which is much easier and faster.  

ä½ ä¼šæ³¨æ„åˆ°ï¼ŒåŠ©æ‰‹å¹¶æ²¡æœ‰å†™å‡ºå®Œæ•´çš„å…ƒç´ ï¼Œè€Œåªæ˜¯æä¾›äº†ä¸€ä¸ªç®€çŸ­çš„æ ‡è¯†ç¬¦ï¼Œè¿™æ ·æ›´æ–¹ä¾¿å¿«æ·ã€‚

Below are the instructions I gave to GPT-4-32K to help it write the code.  

ä»¥ä¸‹æ˜¯æˆ‘ç»™ GPT-4-32K çš„æŒ‡ä»¤ï¼Œä»¥å¸®åŠ©å®ƒç¼–å†™ä»£ç ã€‚  

I wanted to handle cases where there may be relevant information on the page that we need to extract before interacting with it, so I told it to assign extracted information to a variable called 'actionOutput' within it's function.  

æˆ‘æƒ³å¤„ç†è¿™æ ·ä¸€ç§æƒ…å†µï¼Œå³åœ¨ä¸é¡µé¢äº¤äº’ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦æå–é¡µé¢ä¸Šçš„ç›¸å…³ä¿¡æ¯ï¼Œå› æ­¤æˆ‘è®©å®ƒå°†æå–çš„ä¿¡æ¯èµ‹å€¼ç»™å‡½æ•°ä¸­ä¸€ä¸ªåä¸º "actionOutput "çš„å˜é‡ã€‚

![Write Action 1](write-action-1.png)

I passed the string output from this step - which I'm calling the 'action' - into my Playwright crawler as a parameter, and used the 'eval' function to execute it as code (yes, I know this could be dangerous):  

æˆ‘å°†è¿™ä¸€æ­¥è¾“å‡ºçš„å­—ç¬¦ä¸²ï¼ˆæˆ‘ç§°ä¹‹ä¸º "åŠ¨ä½œ"ï¼‰ä½œä¸ºå‚æ•°ä¼ é€’ç»™ Playwright çˆ¬è™«ï¼Œå¹¶ä½¿ç”¨ "eval "å‡½æ•°å°†å…¶ä½œä¸ºä»£ç æ‰§è¡Œï¼ˆæ˜¯çš„ï¼Œæˆ‘çŸ¥é“è¿™å¯èƒ½å¾ˆå±é™©ï¼‰ï¼š

![Crawler Action](crawler-action.png)

If you're wondering why I don't simply have the assistant provide the code for its interaction directly, it's because the Turbo model I used for the assistant ended up being too dumb to write the commands reliably.  

å¦‚æœä½ æƒ³çŸ¥é“ä¸ºä»€ä¹ˆæˆ‘ä¸ç›´æ¥è®©åŠ©æ‰‹æä¾›äº¤äº’ä»£ç ï¼Œé‚£æ˜¯å› ä¸ºæˆ‘ä¸ºåŠ©æ‰‹ä½¿ç”¨çš„ Turbo æ¨¡å‹å¤ªç¬¨ï¼Œæ— æ³•å¯é åœ°ç¼–å†™å‘½ä»¤ã€‚  

So instead I ask the Assistant to describe the interaction it wants ("click on this element"), then I use the beefier GPT-4-32K model write the code.  

å› æ­¤ï¼Œæˆ‘è®©åŠ©æ‰‹æè¿°å®ƒæƒ³è¦çš„äº¤äº’ï¼ˆ"ç‚¹å‡»è¿™ä¸ªå…ƒç´ "ï¼‰ï¼Œç„¶åä½¿ç”¨æ›´å¼ºå¤§çš„ GPT-4-32K æ¨¡å‹ç¼–å†™ä»£ç ã€‚

## Conveying the State of the Page  

ä¼ è¾¾é¡µé¢çŠ¶æ€

At this point I realized that I needed a way to convey the state of the page to the Assistant.  

è¿™æ—¶æˆ‘æ„è¯†åˆ°ï¼Œæˆ‘éœ€è¦ä¸€ç§å‘åŠ©ç†ä¼ è¾¾é¡µé¢çŠ¶æ€çš„æ–¹æ³•ã€‚  

I wanted it to craft search terms based on the page it was on, and simply giving it the url felt sub-optimal.  

æˆ‘å¸Œæœ›å®ƒèƒ½æ ¹æ®æ‰€å¤„çš„é¡µé¢åˆ¶ä½œæœç´¢æ¡ä»¶ï¼Œè€Œç®€å•åœ°ç»™å‡ºç½‘å€æ„Ÿè§‰å¹¶ä¸ç†æƒ³ã€‚  

Plus, sometimes my crawler failed to load pages properly, and I wanted the Assistant to be able to detect that and try again.  

æ­¤å¤–ï¼Œæœ‰æ—¶æˆ‘çš„çˆ¬è™«æ— æ³•æ­£å¸¸åŠ è½½é¡µé¢ï¼Œæˆ‘å¸Œæœ›åŠ©æ‰‹èƒ½å¤Ÿæ£€æµ‹åˆ°è¿™ä¸€ç‚¹å¹¶å†æ¬¡å°è¯•ã€‚

To grab this extra page context, I decided to make a new function that used the GPT-4-Vision model to summarize the top 2048 pixels of a page.  

ä¸ºäº†è·å–è¿™äº›é¢å¤–çš„é¡µé¢ä¸Šä¸‹æ–‡ï¼Œæˆ‘å†³å®šåˆ›å»ºä¸€ä¸ªæ–°å‡½æ•°ï¼Œä½¿ç”¨ GPT-4-Vision æ¨¡å‹æ¥æ¦‚æ‹¬é¡µé¢é¡¶éƒ¨çš„ 2048 ä¸ªåƒç´ ã€‚  

I inserted this function in the two places it was necessary: at the very beginning, so the starting page could be analyzed; and at the conclusion of the INTERACT\_WITH\_ELEMENT tool, so the assistant could understand the outcome of its interaction.  

æˆ‘åœ¨ä¸¤ä¸ªå¿…è¦çš„åœ°æ–¹æ’å…¥äº†è¿™ä¸€åŠŸèƒ½ï¼šä¸€æ˜¯åœ¨å¼€å§‹æ—¶ï¼Œä»¥ä¾¿åˆ†æèµ·å§‹é¡µé¢ï¼›äºŒæ˜¯åœ¨ INTERACT\_WITH\_ELEMENT å·¥å…·ç»“æŸæ—¶ï¼Œä»¥ä¾¿åŠ©æ‰‹äº†è§£å…¶äº¤äº’ç»“æœã€‚

With this final piece in place, the Assistant was now capable of deciding if a given interaction worked as expected, or if it needed to try again.  

æœ‰äº†è¿™æœ€åä¸€å—ï¼ŒåŠ©ç†ç°åœ¨å°±èƒ½å†³å®šæŸä¸ªäº’åŠ¨æ˜¯å¦æŒ‰é¢„æœŸè¿›è¡Œï¼Œæˆ–è€…æ˜¯å¦éœ€è¦å†è¯•ä¸€æ¬¡ã€‚  

This was super helpful on pages that threw a Captcha or some other pop up.  

è¿™å¯¹é‚£äº›ä¼šå¼¹å‡ºéªŒè¯ç æˆ–å…¶ä»–å¼¹å‡ºçª—å£çš„é¡µé¢éå¸¸æœ‰ç”¨ã€‚  

In such cases, the assistant would know that it had to circumvent the obstacle before it could continue.  

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒåŠ©æ‰‹çŸ¥é“å¿…é¡»ç»•è¿‡éšœç¢ç‰©æ‰èƒ½ç»§ç»­å‰è¿›ã€‚

## The Final Flow  

æœ€ç»ˆæµç¨‹

Let's recap the process to this point: We start by giving a URL and a goal to an assistant.  

è®©æˆ‘ä»¬å›é¡¾ä¸€ä¸‹åˆ°ç›®å‰ä¸ºæ­¢çš„è¿‡ç¨‹ï¼šé¦–å…ˆï¼Œæˆ‘ä»¬å‘åŠ©ç†æä¾›ä¸€ä¸ª URL å’Œä¸€ä¸ªç›®æ ‡ã€‚  

The assistant then uses the 'GET\_ELEMENT' tool to extract the most relevant element from the page.  

ç„¶åï¼ŒåŠ©æ‰‹ä¼šä½¿ç”¨ "GET\_ELEMENT "å·¥å…·ä»é¡µé¢ä¸­æå–æœ€ç›¸å…³çš„å…ƒç´ ã€‚

If an interaction is appropriate, the assistant will use the 'INTERACT\_WITH\_ELEMENT' tool to write and execute the code for that interaction.  

å¦‚æœäº¤äº’åˆé€‚ï¼ŒåŠ©æ‰‹å°±ä¼šä½¿ç”¨ "INTERACT\_WITH\_ELEMENT "å·¥å…·æ¥ç¼–å†™å’Œæ‰§è¡Œäº¤äº’ä»£ç ã€‚  

It will repeat this flow until the goal has been reached.  

å®ƒå°†é‡å¤è¿™ä¸€æµç¨‹ï¼Œç›´åˆ°è¾¾åˆ°ç›®æ ‡ã€‚

![Final Flow](final-flow.png)

Now it was time to put it all to the test by seeing how well it could navigate through Wikipedia in search of an answer.  

ç°åœ¨æ˜¯è€ƒéªŒå®ƒçš„æ—¶å€™äº†ï¼Œçœ‹çœ‹å®ƒåœ¨ç»´åŸºç™¾ç§‘ä¸­æœç´¢ç­”æ¡ˆçš„èƒ½åŠ›å¦‚ä½•ã€‚

## Testing the Assistant  

æµ‹è¯•åŠ©ç†

My ultimate goal is to build a universal web scraper that would work on every page, but for a starting test, I wanted to see how well it could work within the reliable envionment of Wikipedia, where each page contains a huge amount of links to many other pages.  

æˆ‘çš„æœ€ç»ˆç›®æ ‡æ˜¯å»ºç«‹ä¸€ä¸ªé€šç”¨çš„ç½‘ç»œæœåˆ®å·¥å…·ï¼Œå®ƒå¯ä»¥åœ¨æ¯ä¸ªé¡µé¢ä¸Šå·¥ä½œï¼Œä½†ä½œä¸ºèµ·æ­¥æµ‹è¯•ï¼Œæˆ‘æƒ³çœ‹çœ‹å®ƒåœ¨ç»´åŸºç™¾ç§‘è¿™ä¸ªå¯é çš„ç¯å¢ƒä¸­å·¥ä½œå¾—å¦‚ä½•ï¼Œå› ä¸ºåœ¨ç»´åŸºç™¾ç§‘ä¸­ï¼Œæ¯ä¸ªé¡µé¢éƒ½åŒ…å«å¤§é‡æŒ‡å‘è®¸å¤šå…¶ä»–é¡µé¢çš„é“¾æ¥ã€‚  

The assistant should have no problem finding information within this domain.  

åŠ©æ‰‹åœ¨è¿™ä¸€é¢†åŸŸå†…æŸ¥æ‰¾ä¿¡æ¯åº”è¯¥ä¸æˆé—®é¢˜ã€‚

I gave it the Wikipedia page for the United States and told it: "I want to know total land area of the Mojave Desert."  

æˆ‘ç»™äº†å®ƒç¾å›½çš„ç»´åŸºç™¾ç§‘é¡µé¢ ç„¶åå‘Šè¯‰å®ƒï¼š"æˆ‘æƒ³çŸ¥é“è«å“ˆéŸ¦æ²™æ¼ çš„æ€»é¢ç§¯"

The Unites States page contains nearly 1.5 million characters of HTML content, which roughly translates to 375,000 tokens.  

ç¾å›½ "é¡µé¢åŒ…å«è¿‘ 150 ä¸‡ä¸ª HTML å†…å®¹å­—ç¬¦ï¼Œå¤§çº¦ç›¸å½“äº 375,000 ä¸ªæ ‡è®°ã€‚  

So this would be a good test of the system's ability to handle large amounts of data.  

å› æ­¤ï¼Œè¿™å°†æ˜¯å¯¹ç³»ç»Ÿå¤„ç†å¤§é‡æ•°æ®èƒ½åŠ›çš„ä¸€æ¬¡å¾ˆå¥½çš„æµ‹è¯•ã€‚

As anticipated, the assistant reached for the 'GET\_ELEMENT' tool, but its initial search terms were poor.  

æ­£å¦‚é¢„æœŸçš„é‚£æ ·ï¼ŒåŠ©æ‰‹ä½¿ç”¨äº† "GET\_ELEMENT "å·¥å…·ï¼Œä½†å®ƒçš„åˆå§‹æœç´¢æ¡ä»¶å¾ˆå·®ã€‚  

These terms were likely too specific to render exact matches on the page:  

è¿™äº›æœ¯è¯­å¯èƒ½è¿‡äºå…·ä½“ï¼Œæ— æ³•åœ¨é¡µé¢ä¸Šå‘ˆç°ç²¾ç¡®åŒ¹é…ï¼š

```
TOOL CALL] ğŸ”§ get_element
[REQUIRES_ACTION]
Running 1 functions...
{
  "url": "https://en.wikipedia.org/wiki/United_States",
  "searchTerms": [
    "Mojave Desert link",
    "Mojave link",
    "desert link",
    "link Mojave",
    "link desert"
  ],
  "directive": "Find a link to the Mojave Desert page to get information on its total land area"
}
```

Sure enough, the tool found 0 matches across all terms.  

æœç„¶ï¼Œè¯¥å·¥å…·åœ¨æ‰€æœ‰æœ¯è¯­ä¸­æ‰¾åˆ°äº† 0 ä¸ªåŒ¹é…é¡¹ã€‚

```
Searching for matching elements. Token limit: 10000
Found 0 matching elements (0 tokens)
No matching elements
Sending Tool Output...
  "tool_call_id": "call_aZbkE2kM02qjXL7kx5KDdeWb",
  "output": "{"error":"Error: No matching elements found."}"
```

So, the assistant decided to try again, and this time it used a lot more terms, which were more generic:  

äºæ˜¯ï¼ŒåŠ©æ‰‹å†³å®šå†è¯•ä¸€æ¬¡ï¼Œè¿™æ¬¡å®ƒä½¿ç”¨äº†æ›´å¤šçš„æœ¯è¯­ï¼Œè¿™äº›æœ¯è¯­æ›´åŠ é€šç”¨ï¼š

```
[TOOL CALL] ğŸ”§ get_element
[REQUIRES_ACTION]
Running 1 functions...
{
  "url": "https://en.wikipedia.org/wiki/United_States",
  "searchTerms": [
    "Mojave",
    "Desert",
    "Mojave Desert",
    "geography",
    "landscape",
    "environment",
    "Nature",
    "ecosystem",
    "biome",
    "land",
    "climate",
    "terrain",
    "Landforms",
    "physical"
  ],
  "directive": "Find a link to the Mojave Desert page on Wikipedia from the United States page"
}
```

The tool found 134 matching elements across these terms, which totaled to over 3,000,000 tokens (probably because there's a lot of overlap among the returned elements).  

è¯¥å·¥å…·åœ¨è¿™äº›æœ¯è¯­ä¸­æ‰¾åˆ°äº† 134 ä¸ªåŒ¹é…å…ƒç´ ï¼Œæ€»è®¡è¶…è¿‡ 3,000,000 ä¸ªæ ‡è®°ï¼ˆå¯èƒ½æ˜¯å› ä¸ºè¿”å›çš„å…ƒç´ ä¹‹é—´æœ‰å¾ˆå¤šé‡å ï¼‰ã€‚  

Luckily, the previously mentioned algorithm for selecting the final list of elements was able to pare this down to a list of 41 elements (I set the cap to 10,000 tokens).  

å¹¸è¿çš„æ˜¯ï¼Œå‰é¢æåˆ°çš„ç”¨äºé€‰æ‹©æœ€ç»ˆå…ƒç´ åˆ—è¡¨çš„ç®—æ³•èƒ½å¤Ÿå°†å…¶ç¼©å‡ä¸ºä¸€ä¸ªåŒ…å« 41 ä¸ªå…ƒç´ çš„åˆ—è¡¨ï¼ˆæˆ‘å°†ä¸Šé™è®¾ç½®ä¸º 10,000 ä¸ªä»£å¸ï¼‰ã€‚

Then, GPT-4-32K picked this element as the most relevant, which contains a link to the Wikipedia page for the Mojave Desert:  

ç„¶åï¼ŒGPT-4-32K é€‰å–äº†è¿™ä¸ªå…ƒç´ ä½œä¸ºæœ€ç›¸å…³çš„å…ƒç´ ï¼Œå…¶ä¸­åŒ…å«ä¸€ä¸ªæŒ‡å‘ç»´åŸºç™¾ç§‘è«å“ˆéŸ¦æ²™æ¼ é¡µé¢çš„é“¾æ¥ï¼š

```
<p>
  <!-- Abbreviated for readability -->
  <!-- ... --> 
  <a href="/wiki/Sonoran_Desert" title="Sonoran Desert">Sonoran</a>, and 
  <a href="/wiki/Mojave_Desert" title="Mojave Desert">Mojave</a> deserts.
  <sup id="cite_ref-179" class="reference">
    <a href="#cite_note-179">[167]</a>
  </sup> 
  <!-- ... -->
</p>
```

If you're wondering why this element contains so extra HTML beyond just the link itself, it's because I set the 'parents' parameter to 1, which, if you recall, means that all matching elements will be returned with their immediate parent element.  

å¦‚æœä½ æƒ³çŸ¥é“ä¸ºä»€ä¹ˆè¿™ä¸ªå…ƒç´ é™¤äº†é“¾æ¥æœ¬èº«ä¹‹å¤–è¿˜åŒ…å«è¿™ä¹ˆå¤šé¢å¤–çš„ HTMLï¼Œé‚£æ˜¯å› ä¸ºæˆ‘å°† "parents "å‚æ•°è®¾ç½®ä¸º 1ï¼Œå¦‚æœä½ è¿˜è®°å¾—ï¼Œè¿™æ„å‘³ç€æ‰€æœ‰åŒ¹é…çš„å…ƒç´ éƒ½å°†ä¸å®ƒä»¬çš„ç›´æ¥çˆ¶å…ƒç´ ä¸€èµ·è¿”å›ã€‚

After recieving this element as part of the 'GET\_ELEMENT' tool output, the assistant decided to use the 'INTERACT\_WITH\_ELEMENT' tool to try and click on that link:  

åœ¨ä» "GET\_ELEMENT "å·¥å…·è¾“å‡ºä¸­è·å¾—è¯¥å…ƒç´ åï¼ŒåŠ©æ‰‹å†³å®šä½¿ç”¨ "INTERACT\_WITH\_ELEMENT "å·¥å…·å°è¯•ç‚¹å‡»è¯¥é“¾æ¥ï¼š

```
[NEW STEP] ğŸ‘‰ [{"type":"function","name":"interact_with_element"}]
Running 1 function...
{
  "elementCode": "16917",
  "url": "https://en.wikipedia.org/wiki/United_States",
  "directive": "Click on the link to the Mojave Desert page"
}
```

The 'INTERACT\_WITH\_ELEMENT' tool used GPT-4-32K to process that idea into a Playwright action:  

INTERACT\_WITH\_ELEMENT "å·¥å…·ä½¿ç”¨ GPT-4-32K å°†è¯¥æƒ³æ³•å¤„ç†ä¸º Playwright æ“ä½œï¼š

```
Running writeAction with azure32k...
Write Action Response:
"(async () => {\n  await page.click('p a[href=\"/wiki/Mojave_Desert\"]');\n})();"
```

My Playwright crawler ran the action, and the browser successfully navigated to the Mojave Desert page.  

æˆ‘çš„ Playwright çˆ¬è™«è¿è¡Œäº†è¯¥æ“ä½œï¼Œæµè§ˆå™¨æˆåŠŸå¯¼èˆªåˆ°è«å“ˆéŸ¦æ²™æ¼ é¡µé¢ã€‚

Finally, I processed the new page with GPT-4-Vision and sent a summary of the browser status back to the assistant as part of the tool output:  

æœ€åï¼Œæˆ‘ç”¨ GPT-4-Vision å¤„ç†äº†æ–°é¡µé¢ï¼Œå¹¶å°†æµè§ˆå™¨çŠ¶æ€æ‘˜è¦ä½œä¸ºå·¥å…·è¾“å‡ºçš„ä¸€éƒ¨åˆ†å‘é€å›åŠ©æ‰‹ï¼š

```
Summarize Status Response:
"We clicked on a link to the Wikipedia page for the Mojave Desert. And now we are looking at the Wikipedia page for the Mojave Desert."
```

The assistant decided that the goal was not yet reached, so it repeated the process on the new page.  

åŠ©æ‰‹è®¤ä¸ºç›®æ ‡å°šæœªå®ç°ï¼Œäºæ˜¯åœ¨æ–°é¡µé¢ä¸Šé‡å¤äº†è¿™ä¸€è¿‡ç¨‹ã€‚  

Once again, it's initial search terms were too specific, and the results were sparse.  

åŒæ ·ï¼Œæœ€åˆçš„æœç´¢æ¡ä»¶è¿‡äºå…·ä½“ï¼Œç»“æœç¨€å°‘ã€‚  

But on it's 2nd try, it came up with these terms:  

ä½†åœ¨ç¬¬äºŒæ¬¡å°è¯•æ—¶ï¼Œå®ƒå¾—å‡ºäº†è¿™äº›æœ¯è¯­ï¼š

```
[TOOL CALL] ğŸ”§ get_element
[REQUIRES_ACTION]
Running one function...
{
  "url": "https://en.wikipedia.org/wiki/Mojave_Desert",
  "searchTerms": [
    "square miles",
    "square kilometers",
    "km2",
    "mi2",
    "area",
    "acreage",
    "expansion",
    "size",
    "span",
    "coverage"
  ],
  "directive": "Locate the specific section or paragraph that states the total land area of the Mojave Desert on the Wikipedia page"
}
```

The 'GET\_ELEMENT' tool initial found 21 matches, totaling to 491,000 tokens, which was pared down to 12. Then GPT-4-32K picked this as the most relevant of the 12, which contains the search term "km2":  

GET\_ELEMENT "å·¥å…·æœ€åˆæ‰¾åˆ°äº† 21 ä¸ªåŒ¹é…é¡¹ï¼Œæ€»è®¡ 491,000 ä¸ªè¯å—ï¼Œæœ€åç¼©å‡ä¸º 12 ä¸ªã€‚ç„¶åï¼ŒGPT-4-32K ä»è¿™ 12 ä¸ªåŒ¹é…è¯ä¸­é€‰å–äº†æœ€ç›¸å…³çš„ä¸€ä¸ªï¼Œå…¶ä¸­åŒ…å«æœç´¢è¯ "km2"ï¼š

```
<tr>
  <th class="infobox-label">Area</th>
  <td class="infobox-data">81,000&nbsp;km<sup>2</sup>(31,000&nbsp;sq&nbsp;mi)</td>
</tr>
```

This element corresponds to this section of the rendered page:  

è¯¥å…ƒç´ ä¸æ¸²æŸ“é¡µé¢çš„è¿™ä¸€éƒ¨åˆ†ç›¸å¯¹åº”ï¼š

![Mojave Page](mojave-page.png)

In this case, we wouldn't have been able to find this answer if I hadn't set 'parents' to 1, because the answer we're looking for is in a sibling of the matching element, just like in our Cuba example.  

åœ¨æœ¬ä¾‹ä¸­ï¼Œå¦‚æœæˆ‘æ²¡æœ‰å°† "parents "è®¾ç½®ä¸º 1ï¼Œæˆ‘ä»¬å°±æ— æ³•æ‰¾åˆ°è¿™ä¸ªç­”æ¡ˆï¼Œå› ä¸ºæˆ‘ä»¬è¦æ‰¾çš„ç­”æ¡ˆå°±åœ¨åŒ¹é…å…ƒç´ çš„åŒçº§å…ƒç´ ä¸­ï¼Œå°±åƒåœ¨å¤å·´çš„ä¾‹å­ä¸­ä¸€æ ·ã€‚

The 'GET\_ELEMENT' tool passed the element back to the assistant, who correctly noticed that the information within satisfied our goal.  

GET\_ELEMENT "å·¥å…·å°†å…ƒç´ ä¼ å›åŠ©æ‰‹ï¼ŒåŠ©æ‰‹æ­£ç¡®åœ°æ³¨æ„åˆ°å…¶ä¸­çš„ä¿¡æ¯æ»¡è¶³äº†æˆ‘ä»¬çš„ç›®æ ‡ã€‚  

Thus it completed it's run, letting me know that the answer to my question is 81,000 square kilometers:  

è¿™æ ·ï¼Œå®ƒå°±å®Œæˆäº†è¿è¡Œï¼Œè®©æˆ‘çŸ¥é“æˆ‘çš„é—®é¢˜çš„ç­”æ¡ˆæ˜¯ 81 000 å¹³æ–¹å…¬é‡Œï¼š

```
[FINAL MESSAGE] âœ… The total land area of the Mojave Desert is 81,000 square kilometers or 31,000 square miles.
{
  "status": "complete",
  "info": {
    "area_km2": 81000,
    "area_mi2": 31000
  }
}
```

If you'd like to read the full logs from this run, you can find a copy of them [here](https://timconnors.co/posts/ai-scraper/logs)!  

å¦‚æœæ‚¨æƒ³é˜…è¯»è¿™æ¬¡è¿è¡Œçš„å®Œæ•´æ—¥å¿—ï¼Œå¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°å‰¯æœ¬ï¼

## Closing Thoughts  

ç»“æŸè¯­

I had a lot of fun building this thing, and learned a ton.  

æˆ‘åœ¨åˆ¶ä½œè¿‡ç¨‹ä¸­è·å¾—äº†å¾ˆå¤šä¹è¶£ï¼Œä¹Ÿå­¦åˆ°äº†å¾ˆå¤šä¸œè¥¿ã€‚  

That being said, it's still a fragile system. I'm looking forward to taking it to the next level.  

å°½ç®¡å¦‚æ­¤ï¼Œå®ƒä»ç„¶æ˜¯ä¸€ä¸ªè„†å¼±çš„ç³»ç»Ÿã€‚æˆ‘æœŸå¾…ç€å®ƒæ›´ä¸Šä¸€å±‚æ¥¼ã€‚  

Here are some of the things I'd like to improve about it:  

ä»¥ä¸‹æ˜¯æˆ‘å¸Œæœ›æ”¹è¿›çš„ä¸€äº›åœ°æ–¹ï¼š

-   Generating smarter search terms so it can find relevant elements faster  
    
    ç”Ÿæˆæ›´æ™ºèƒ½çš„æœç´¢æ¡ä»¶ï¼Œä»¥ä¾¿æ›´å¿«åœ°æ‰¾åˆ°ç›¸å…³å…ƒç´ 
-   Implementing fuzzy search in my 'GET\_ELEMENT' tool to account for slight variations in text  
    
    åœ¨æˆ‘çš„ "GET\_ELEMENT "å·¥å…·ä¸­å®æ–½æ¨¡ç³Šæœç´¢ï¼Œä»¥è€ƒè™‘æ–‡æœ¬ä¸­çš„ç»†å¾®å˜åŒ–
-   Using the vision model to label images & icons in the HTML so the assistant can interact with them  
    
    ä½¿ç”¨è§†è§‰æ¨¡å‹æ¥æ ‡æ³¨ HTML ä¸­çš„å›¾åƒå’Œå›¾æ ‡ï¼Œä»¥ä¾¿åŠ©æ‰‹ä¸ä¹‹äº’åŠ¨
-   Enhancing the stealth of the crawler with residental proxies and other techniques  
    
    åˆ©ç”¨å¸¸é©»ä»£ç†å’Œå…¶ä»–æŠ€æœ¯å¢å¼ºçˆ¬è™«çš„éšè”½æ€§

Thanks for reading! If you have any questions or suggestions, feel free to reach out to me on [Twitter](https://twitter.com/itstimconnors) or via email at [hi@timconnors.co](mailto:hi@timconnors.co)  

æ„Ÿè°¢æ‚¨çš„é˜…è¯»ï¼å¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·éšæ—¶é€šè¿‡ Twitter æˆ–ç”µå­é‚®ä»¶ hi@timconnors.co è”ç³»æˆ‘ã€‚
