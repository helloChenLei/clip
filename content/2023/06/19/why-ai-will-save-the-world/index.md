---
title: "为什么人工智能会拯救世界 ？"
date: 2023-06-19T12:54:17+08:00
updated: 2023-06-19T12:54:17+08:00
taxonomies:
  tags: []
extra:
  source: https://a16z.com/2023/06/06/ai-will-save-the-world/
  hostname: a16z.com
  author: Marc Andreessen
  original_title: "Why AI Will Save the World"
  original_lang: zh
---

The era of Artificial Intelligence is here, and boy are people freaking out.  

人工智能的时代已经到来，而孩子们都吓坏了。

Fortunately, I am here to bring the good news: AI will not destroy the world, and in fact may save it.  

幸运的是，我在这里带来了一个好消息：人工智能不会毁灭世界，而且事实上可能会拯救世界。

First, a short description of what AI _is_: The application of mathematics and software code to teach computers how to understand, synthesize, and generate knowledge in ways similar to how people do it.  

AI is a computer program like any other – it runs, takes input, processes, and generates output.  

人工智能是一个与其他程序一样的计算机程序--它运行，接受输入，处理，并产生输出。  

AI’s output is useful across a wide range of fields, ranging from coding to medicine to law to the creative arts.  

人工智能的产出在广泛的领域都很有用，从编码到医学到法律到创意艺术。  

It is owned by people and controlled by people, like any other technology.  

它由人拥有，由人控制，就像任何其他技术一样。  

首先，简单介绍一下什么是人工智能：应用数学和软件代码来教计算机如何理解、综合和产生知识，其方式与人的方式相似。

A shorter description of what AI _isn’t_: Killer software and robots that will spring to life and decide to murder the human race or otherwise ruin everything, like you see in [the movies](https://movieweb.com/best-killer-robot-horror-movies-ranked/).  

对人工智能不是什么的一个简短描述：杀手软件和机器人会突然出现，决定谋杀人类或以其他方式毁掉一切，就像你在电影中看到的那样。

An even shorter description of what AI _could be_: A way to make everything we care about better.  

对人工智能可能是什么的描述更简短：一种使我们关心的一切变得更好的方法。

## **Why AI Can Make Everything We Care About Better  

为什么人工智能可以让我们关心的一切变得更好**

The most validated core conclusion of social science across many decades and thousands of studies is that _human_ intelligence makes a very broad range of life outcomes better.  

Smarter people have better outcomes in almost every domain of activity: academic achievement, job performance, occupational status, income, creativity, physical health, longevity, learning new skills, managing complex tasks, leadership, entrepreneurial success, conflict resolution, reading comprehension, financial decision making, understanding others’ perspectives, creative arts, parenting outcomes, and life satisfaction.  

聪明人几乎在每个活动领域都有更好的结果：学业成绩、工作表现、职业地位、收入、创造力、身体健康、寿命、学习新技能、管理复杂任务、领导力、创业成功、解决冲突、阅读理解、财务决策、理解他人的观点、创造性艺术、养育子女的结果以及生活满意度。  

在几十年的时间里，社会科学最有效的核心结论是，人类的智慧能使一系列非常广泛的生活结果变得更好。

Further, human intelligence is the lever that we have used for millennia to create the world we live in today: science, technology, math, physics, chemistry, medicine, energy, construction, transportation, communication, art, music, culture, philosophy, ethics, morality.  

此外，人类的智慧是我们几千年来用来创造我们今天生活的世界的杠杆：科学、技术、数学、物理、化学、医药、能源、建筑、交通、通讯、艺术、音乐、文化、哲学、伦理、道德。  

Without the application of intelligence on all these domains, we would all still be living in mud huts, scratching out a meager existence of subsistence farming.  

如果没有智能在所有这些领域的应用，我们都还会生活在泥屋里，靠自给自足的农作来维持微薄的生活。  

Instead we have used our intelligence to raise our standard of living on the order of 10,000X over the last 4,000 years.  

相反，我们利用我们的智慧，在过去的4000年里，将我们的生活水平提高了10000倍。

What AI offers us is the opportunity to profoundly _augment_ human intelligence to make all of these outcomes of intelligence – and many others, from the creation of new medicines to ways to solve climate change to technologies to reach the stars – much, much better from here.  

人工智能为我们提供的是深刻增强人类智能的机会，使所有这些智能成果--以及许多其他成果，从创造新药到解决气候变化的方法，再到到达星星的技术--从这里开始变得更好。

AI augmentation of human intelligence has already started – AI is already around us in the form of computer control systems of many kinds, is now rapidly escalating with AI Large Language Models like ChatGPT, and will accelerate very quickly from here – _if we let it_.  

人工智能对人类智能的增强已经开始了--人工智能已经以多种计算机控制系统的形式出现在我们身边，现在正以ChatGPT这样的人工智能大型语言模型迅速升级，并将从这里开始非常迅速地加速--如果我们允许它。

In our new era of AI:  

在我们的人工智能新时代：

-   Every child will have an AI tutor that is infinitely patient, infinitely compassionate, infinitely knowledgeable, infinitely helpful.  
    
    每个孩子都会有一个人工智能导师，他有无限的耐心、无限的同情心、无限的知识、无限的帮助。  
    
    The AI tutor will be by each child’s side every step of their development, helping them maximize their potential with the machine version of infinite love.  
    
    人工智能导师将在每个孩子的每一步发展中陪伴他们，用机器版的无限爱帮助他们最大限度地发挥潜能。
-   Every person will have an AI assistant/coach/mentor/trainer/advisor/therapist that is infinitely patient, infinitely compassionate, infinitely knowledgeable, and infinitely helpful.  
    
    每个人都会有一个人工智能助理/教练/导师/培训师/顾问/治疗师，他们有无限的耐心、无限的同情心、无限的知识和无限的帮助。
    
    The AI assistant will be present through all of life’s opportunities and challenges, maximizing every person’s outcomes.
    
      
    
    人工智能助理将贯穿生活中所有的机会和挑战，使每个人的成果最大化。
-   Every scientist will have an AI assistant/collaborator/partner that will greatly expand their scope of scientific research and achievement.  
    
    每个科学家都会有一个人工智能助手/合作者/伙伴，这将大大扩展他们的科学研究和成就范围。  
    
    Every artist, every engineer, every businessperson, every doctor, every caregiver will have the same in their worlds.  
    
    每个艺术家、每个工程师、每个商人、每个医生、每个护理人员在他们的世界里都会有同样的情况。
-   Every leader of people – CEO, government official, nonprofit president, athletic coach, teacher – will have the same.  
    
    每个人的领导者--首席执行官、政府官员、非营利组织主席、体育教练、教师--都会有同样的情况。  
    
    The magnification effects of better decisions by leaders across the people they lead are enormous, so this intelligence augmentation may be the most important of all.  
    
    领导人在他们所领导的人中做出更好的决定，其放大效应是巨大的，所以这种情报的增强可能是最重要的。
-   Productivity growth throughout the economy will accelerate dramatically, driving economic growth, creation of new industries, creation of new jobs, and wage growth, and resulting in a new era of heightened material prosperity across the planet.  
    
    整个经济的生产力增长将大大加快，推动经济增长，创造新的产业，创造新的就业机会和工资增长，并导致整个地球进入一个物质高度繁荣的新时代。
-   Scientific breakthroughs and new technologies and medicines will dramatically expand, as AI helps us further decode the laws of nature and harvest them for our benefit.  
    
    科学突破和新技术、新药物将急剧扩大，因为人工智能帮助我们进一步解码自然规律，并为我们的利益收获它们。
-   The creative arts will enter a golden age, as AI-augmented artists, musicians, writers, and filmmakers gain the ability to realize their visions far faster and at greater scale than ever before.  
    
    创意艺术将进入一个黄金时代，因为由人工智能增强的艺术家、音乐家、作家和电影制作人获得了比以往更快、更大规模地实现其愿景的能力。
-   I even think AI is going to improve warfare, when it has to happen, by reducing wartime death rates dramatically.  
    
    我甚至认为人工智能会改善战争，当战争不得不发生时，会大大降低战时的死亡率。  
    
    Every war is characterized by terrible decisions made under intense pressure and with sharply limited information by very limited human leaders.  
    
    每场战争的特点都是由非常有限的人类领袖在巨大的压力和极其有限的信息下做出可怕的决定。  
    
    Now, military commanders and political leaders will have AI advisors that will help them make much better strategic and tactical decisions, minimizing risk, error, and unnecessary bloodshed.  
    
    现在，军事指挥官和政治领导人将拥有人工智能顾问，帮助他们做出更好的战略和战术决策，最大限度地减少风险、错误和不必要的流血事件。
-   In short, anything that people do with their natural intelligence today can be done much better with AI, and we will be able to take on new challenges that have been impossible to tackle without AI, from curing all diseases to achieving interstellar travel.  
    
    简而言之，今天人们用自然智能做的任何事情都可以用人工智能做得更好，我们将能够接受没有人工智能就无法解决的新挑战，从治愈所有疾病到实现星际旅行。
-   And this isn’t just about intelligence! Perhaps the most underestimated quality of AI is how _humanizing_ it can be. AI art gives people who otherwise lack technical skills the freedom to [create and share their artistic ideas](https://www.forbes.com/sites/tjmccue/2023/01/23/midjourney-ai-based-art-generator-creates-dazzling-images-from-words/?sh=737b460a5f61). Talking to an empathetic AI friend really does improve [their ability to handle adversity](https://www.npr.org/sections/health-shots/2023/01/19/1147081115/therapy-by-chatbot-the-promise-and-challenges-in-using-ai-for-mental-health). And AI medical chatbots are already [more empathetic](https://www.usatoday.com/story/news/health/2023/05/01/chatbots-show-more-empathy-than-doctors-in-answeringpatient-questions-with-more-empathy-than-doctors/70170816007/) than their human counterparts. Rather than making the world harsher and more mechanistic, infinitely patient and sympathetic AI will make the world warmer and nicer.  
    
    而且这不仅仅是关于智能的问题!也许人工智能最被低估的品质是它可以如何人性化。人工智能艺术给那些本来缺乏技术的人提供了创造和分享其艺术理念的自由。与一个有同情心的人工智能朋友交谈，确实可以提高他们处理逆境的能力。而人工智能医疗聊天机器人已经比他们的人类同行更有同理心。无限耐心和富有同情心的人工智能不会让世界变得更加严酷和机械化，而是会让世界变得更加温暖和美好。

The stakes here are high. The opportunities are profound.  

这里的风险很高。机会是深远的。  

AI is quite possibly the most important – and best – thing our civilization has ever created, certainly on par with electricity and microchips, and probably beyond those.  

人工智能很可能是我们的文明所创造的最重要--也是最好--的东西，当然与电力和微芯片相提并论，而且可能超越这些。

The development and proliferation of AI – far from a risk that we should fear – is a moral obligation that we have to ourselves, to our children, and to our future.  

人工智能的发展和扩散--远不是我们应该害怕的风险--是我们对自己、对我们的孩子、对我们的未来所承担的道德义务。

We should be living in a much better world with AI, and now we can.  

我们应该生活在一个有人工智能的更美好的世界，现在我们可以了。

## **So Why The Panic? 那么，为什么会出现恐慌？**

In contrast to this positive view, the public conversation about AI is presently shot through with hysterical fear and paranoia.  

与这种积极的观点相反，关于人工智能的公共对话目前被歇斯底里的恐惧和偏执所击穿。

We hear claims that AI will variously kill us all, ruin our society, take all our jobs, cause crippling inequality, and enable bad people to do awful things.  

我们听到的说法是，人工智能将杀死我们所有人，毁掉我们的社会，夺走我们所有的工作，造成严重的不平等，并使坏人能够做可怕的事情。

What explains this divergence in potential outcomes from near utopia to horrifying dystopia?  

是什么原因导致了这种从近乎乌托邦到可怕的乌托邦的潜在结果的分歧？

Historically, every new technology that matters, from electric lighting to automobiles to radio to the Internet, has sparked a _moral panic_ – a [social contagion](https://en.wikipedia.org/wiki/Moral_panic) that convinces people the new technology is going to destroy the world, or society, or both. The fine folks at [Pessimists Archive](https://pessimistsarchive.org/) have documented these technology-driven moral panics over the decades; their history makes the pattern vividly clear. It turns out this present panic is [not even the first for AI](https://newsletter.pessimistsarchive.org/p/the-original-ai-doomer-dr-norbert).  

从历史上看，每一项重要的新技术，从电灯到汽车到无线电到互联网，都引发了道德恐慌--一种社会传染病，使人们相信新技术将摧毁世界，或社会，或两者。悲观主义者档案馆的好心人记录了几十年来这些技术驱动的道德恐慌；他们的历史使这种模式变得生动清晰。事实证明，目前的恐慌甚至不是人工智能的第一次。

Now, it is certainly the case that many new technologies have led to bad outcomes – often the same technologies that have been otherwise enormously beneficial to our welfare.  

现在，许多新技术确实导致了不好的结果--往往是那些在其他方面对我们的福利有极大好处的技术。  

So it’s not that the mere existence of a moral panic means there is nothing to be concerned about.  

因此，并不是说仅有道德恐慌的存在就意味着没有什么可担心的。

But a moral panic is by its very nature _irrational_ – it takes what may be a legitimate concern and inflates it into a level of hysteria that ironically makes it harder to confront actually serious concerns.  

但是，道德恐慌就其本质而言是非理性的--它把可能是合理的担忧，膨胀成一种歇斯底里的程度，具有讽刺意味的是，这使得人们更难面对实际的严重问题。

And wow do we have a [full-blown moral panic about AI](https://time.com/6255952/ai-impact-chatgpt-microsoft-google/) right now.  

而且，我们现在对人工智能有一种全面的道德恐慌。

This moral panic is already being used as a motivating force by a variety of actors to demand policy action – new AI restrictions, regulations, and laws.  

这种道德恐慌已经被各种行为者用作激励力量，要求采取政策行动--新的人工智能限制、规定和法律。  

These actors, who are making [extremely dramatic public statements](https://nypost.com/2023/01/26/rogue-ai-could-kill-everyone-scientists-warn/) about the dangers of AI – feeding on and further inflaming moral panic – all present themselves as selfless champions of the public good.  

这些行为者对人工智能的危险发表了极其戏剧性的公开声明--助长并进一步煽动道德恐慌--都把自己当作公共利益的无私拥护者。

But are they? 但它们是吗？

And are they right or wrong?  

那么他们是对还是错呢？

## **The Baptists And Bootleggers Of AI  

人工智能的浸礼者和酒商**

Economists have observed a [longstanding pattern](https://en.wikipedia.org/wiki/Bootleggers_and_Baptists) in reform movements of this kind. The actors within movements like these fall into two categories – “Baptists” and “Bootleggers” – drawing on the historical example of the [prohibition of alcohol in the United States in the 1920’s](https://en.wikipedia.org/wiki/Prohibition_in_the_United_States):  

经济学家已经观察到这类改革运动的一个长期模式。像这样的运动中的行动者分为两类--"浸礼者 "和 "私酒者"--借鉴美国20年代禁酒的历史例子：

-   “Baptists” are the true believer social reformers who legitimately feel – deeply and emotionally, if not rationally – that new restrictions, regulations, and laws are required to prevent societal disaster. For alcohol prohibition, these actors were often literally [devout Christians](https://en.wikipedia.org/wiki/Carrie_Nation) who felt that alcohol was destroying the moral fabric of society. For AI risk, these actors are true believers that AI presents one or another existential risks – strap them to a polygraph, they really mean it.  
    
    "浸礼者 "是真正的社会改革者，他们合法地感觉到--即使不是理性的，也是深层次的和情感的--需要新的限制、规定和法律来防止社会灾难。对于禁酒令，这些行为者往往是字面上的虔诚基督徒，他们认为酒精正在破坏社会的道德结构。对于人工智能风险，这些行为者是真正的信徒，认为人工智能带来了这样或那样的生存风险--把他们绑在测谎仪上，他们真的是这样。
-   “Bootleggers” are the self-interested opportunists who stand to financially profit by the imposition of new restrictions, regulations, and laws that insulate them from competitors. For alcohol prohibition, these were the [literal bootleggers](https://en.wikipedia.org/wiki/Category:Bootleggers) who made a fortune selling illicit alcohol to Americans when legitimate alcohol sales were banned. For AI risk, these are CEOs who stand to make more money if regulatory barriers are erected that form a cartel of government-blessed AI vendors protected from new startup and open source competition – the software version of “too big to fail” banks.  
    
    "私酒商 "是那些自利的机会主义者，他们通过实施新的限制、规定和法律，使他们与竞争对手隔绝，从而在经济上获利。就禁酒令而言，这些人是字面上的私酒商，当合法的酒类销售被禁止时，他们向美国人出售非法酒类而发财。对于人工智能风险来说，如果建立监管壁垒，形成一个由政府资助的人工智能供应商组成的卡特尔，保护他们不受新的创业公司和开源竞争的影响--软件版的 "大到不能倒 "的银行，这些CEO们就能赚更多的钱。

A cynic would suggest that some of the apparent Baptists are also Bootleggers – specifically the ones paid to attack AI by their [universities](https://hai.stanford.edu/news/new-report-assesses-progress-and-risks-artificial-intelligence), [think tanks](https://www.brookings.edu/blog/up-front/2023/05/22/the-us-government-should-regulate-ai/), [activist groups](https://www.humanetech.com/podcast/the-ai-dilemma), and [media outlets](https://www.washingtonpost.com/opinions/2023/05/26/ai-regulation-congress-risk/). If you are [paid a salary](https://projects.propublica.org/nonprofits/organizations/582565917) or [receive grants](https://www.fhi.ox.ac.uk/grant-announcement/) to foster AI panic…you are probably a Bootlegger.  

愤世嫉俗者会认为，一些表面上的浸礼者也是盗版商--特别是那些由他们的大学、智囊团、活动团体和媒体机构支付报酬来攻击人工智能的人。如果你拿着工资或接受资助来促进人工智能的恐慌......你很可能是一个引导者。

The problem with the Bootleggers is that they _win_.  

The Baptists are naive ideologues, the Bootleggers are cynical operators, and so the result of reform movements like these is often that the Bootleggers get what they want – regulatory capture, insulation from competition, the formation of a cartel – and the Baptists are left wondering where their drive for social improvement went so wrong.  

浸礼会成员是天真的思想家，"盗版商 "是玩世不恭的经营者，因此，像这样的改革运动的结果往往是 "盗版商 "得到了他们想要的东西--监管权、与竞争绝缘、形成卡特尔--而浸礼会成员则想知道他们对社会改善的动力在哪里出了问题。  

盗版商的问题是，他们赢了。

We just lived through a stunning example of this – banking reform after the 2008 global financial crisis.  

我们刚刚经历了一个惊人的例子--2008年全球金融危机后的银行改革。  

The Baptists told us that we needed new laws and regulations to break up the “too big to fail” banks to prevent such a crisis from ever happening again.  

浸礼会成员告诉我们，我们需要新的法律和法规来瓦解 "大到不能倒 "的银行，以防止这样的危机再次发生。  

So Congress passed the Dodd-Frank Act of 2010, which was marketed as satisfying the Baptists’ goal, but in reality was coopted by the Bootleggers – the big banks.  

因此，国会通过了2010年的《多德-弗兰克法案》，该法案被推销为满足浸信会的目标，但实际上却被私酒商--大银行哄抢了。  

The result is that the same banks that were “too big to fail” in 2008 are _much, much larger_ now.  

其结果是，2008年 "大到不能倒 "的那些银行，现在已经大得多了。

So in practice, even when the Baptists are genuine – and even when the Baptists are _right_ – they are used as cover by manipulative and venal Bootleggers to benefit themselves.   

因此，在实践中，即使浸礼会成员是真正的--即使浸礼会成员是正确的--他们也被操纵和贪婪的赃物贩子用作掩护，使自己受益。

And this is what is happening in the drive for AI regulation right now.  

而这正是目前在推动人工智能监管方面所发生的事情。

However, it isn’t sufficient to simply identify the actors and impugn their motives. We should consider the arguments of both the Baptists and the Bootleggers on their merits.  

然而，仅仅确定行为人和指责他们的动机是不够的。我们应该根据浸礼会和私酒商的论点来考虑他们的优点。

## **AI Risk #1: Will AI Kill Us All?  

AI风险#1：人工智能会杀死我们所有人吗？**

The first and original AI doomer risk is that AI will decide to literally kill humanity.  

第一个也是最原始的人工智能斗士风险是，人工智能将决定从字面上杀死人类。

The fear that technology of our own creation will rise up and destroy us is deeply coded into our culture.  

对我们自己创造的技术将崛起并摧毁我们的恐惧深深地编入了我们的文化。  

The Greeks expressed this fear in the Prometheus Myth – Prometheus brought the destructive power of fire, and more generally technology (“techne”), to man, for which Prometheus was condemned to perpetual torture by the gods.  

希腊人在《普罗米修斯神话》中表达了这种恐惧--普罗米修斯给人类带来了火的破坏力，以及更普遍的技术（"techne"），为此，普罗米修斯被众神判处永远的酷刑。  

Later, Mary Shelley gave us moderns our own version of this myth in her novel _Frankenstein, or, The Modern Prometheus_, in which we develop the technology for eternal life, which then rises up and seeks to destroy us.  

And of course, no AI panic newspaper story is complete without a still image of a gleaming red-eyed killer robot from James Cameron’s后来，玛丽-雪莱在她的小说《弗兰肯斯坦》或《现代普罗米修斯》中为我们这些现代人提供了这个神话的版本。 _Terminator_ films.  

当然，如果没有詹姆斯-卡梅隆的《终结者》电影中一个闪着红眼睛的杀人机器人的静止图像，任何人工智能恐慌的报纸故事都是不完整的。

The presumed evolutionary purpose of this mythology is to motivate us to seriously consider potential risks of new technologies – fire, after all, can indeed be used to burn down entire cities.  

这种神话推测的进化目的是促使我们认真考虑新技术的潜在风险--毕竟，火确实可以用来烧毁整个城市。  

But just as fire was also the foundation of modern civilization as used to keep us warm and safe in a cold and hostile world, this mythology ignores the far greater upside of most – all?  

但是，正如火也是现代文明的基础，因为它用来使我们在一个寒冷和敌对的世界中保持温暖和安全，这种神话忽略了大多数--所有--的更大的好处？  

– new technologies, and in practice inflames destructive emotion rather than reasoned analysis.  

\- 新技术，并在实践中激起破坏性的情绪，而不是合理的分析。  

Just because premodern man freaked out like this doesn’t mean we have to; we can apply rationality instead.  

前现代人这样抓狂并不意味着我们必须这样做；我们可以运用理性来代替。

My view is that the idea that AI will decide to literally kill humanity is a profound [category error](https://en.wikipedia.org/wiki/Category_mistake). AI is not a living being that has been primed by billions of years of evolution to participate in the battle for the survival of the fittest, as animals are, and as we are.  

It is math – code – computers, built by people, owned by people, used by people, controlled by people.  

它是数学-代码-计算机，由人建造，由人拥有，由人使用，由人控制。  

The idea that it will at some point develop a mind of its own and decide that it has motivations that lead it to try to kill us is a superstitious handwave.  

认为它将在某个时候发展出自己的思想，并决定它有导致它试图杀死我们的动机的想法是一种迷信的手势。  

我的观点是，认为人工智能将决定真正杀死人类的想法是一个深刻的类别错误。人工智能不是一个被数十亿年的进化所激发的生命体，它像动物和我们一样，参与到适者生存的战斗中。

In short, AI doesn’t _want_, it doesn’t have _goals_, it doesn’t want to _kill you_, because it’s not _alive_. And AI is a machine – is not going to come alive any more than your toaster will.  

简而言之，人工智能不想要，它没有目标，它不想杀死你，因为它没有生命。而人工智能是一台机器--是不会像你的烤面包机那样活过来的。

Now, obviously, there are true believers in killer AI – Baptists – who are gaining a suddenly stratospheric amount of media coverage for their terrifying warnings, some of whom claim to have been studying the topic for decades and say they are now scared out of their minds by what they have learned.  

现在，很明显，有一些杀手锏人工智能的真正信徒--浸礼会成员--因其可怕的警告而突然获得平流层的媒体报道，其中一些人声称已经研究了几十年的主题，并说他们现在被他们所了解的情况吓得魂飞魄散。  

Some of these true believers are even [actual](https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html) [innovators](https://www.bbc.com/news/technology-65760449) of the technology. These actors are arguing for a variety of bizarre and extreme restrictions on AI ranging from a [ban on AI development](https://www.nytimes.com/2023/03/29/technology/ai-artificial-intelligence-musk-risks.html), all the way up to [military airstrikes on datacenters](https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/) and [nuclear war](https://mishtalk.com/economics/to-stop-ai-lunatics-are-willing-to-risk-a-global-nuclear-war). They argue that because people like me cannot rule out future catastrophic consequences of AI, that we must assume a [precautionary](https://en.wikipedia.org/wiki/Precautionary_principle) stance that may require large amounts of physical violence and death in order to prevent potential existential risk.  

其中一些忠实的信徒甚至是该技术的实际创新者。这些人主张对人工智能进行各种奇怪而极端的限制，从禁止人工智能发展，一直到对数据中心进行军事空袭和核战争。他们认为，由于像我这样的人无法排除人工智能未来的灾难性后果，所以我们必须采取预防措施，可能需要大量的身体暴力和死亡，以防止潜在的生存风险。

My response is that their position is non-scientific – What is the testable hypothesis? What would falsify the hypothesis? [How do we know when we are getting into a danger zone?](https://twitter.com/aidangomezzz/status/1651053357719535622?s=46&t=Oa_2uNFzXdquihp6LY7u1Q) These questions go mainly unanswered apart from “You can’t prove it won’t happen!” In fact, these Baptists’ position is _so_ non-scientific and _so_ extreme – a conspiracy theory about math and code – and is already calling for physical violence, that I will do something I would normally not do and question their motives as well.  

我的回答是，他们的立场是不科学的--什么是可检验的假说？什么会证伪这个假设？我们如何知道我们何时进入了危险区域？除了 "你不能证明它不会发生！"之外，这些问题主要没有得到回答。事实上，这些浸礼会成员的立场是如此的不科学，如此的极端--关于数学和代码的阴谋论--并且已经在呼吁使用身体暴力，所以我将做一些我通常不会做的事情，也质疑他们的动机。

Specifically, I think three things are going on:  

具体来说，我认为有三件事正在发生：

First, recall that John Von Neumann responded to Robert Oppenheimer’s famous hand-wringing about his role creating nuclear weapons – which helped end World War II and prevent World War III – with, “Some people confess guilt to claim credit for the sin.” What is the most dramatic way one can claim credit for the importance of one’s work without sounding overtly boastful?  

首先，回顾一下约翰-冯-诺伊曼对罗伯特-奥本海默关于他在创造核武器--有助于结束第二次世界大战和防止第三次世界大战--方面的著名的手忙脚乱的回应："有些人认罪是为了邀功"。一个人可以用什么最戏剧性的方式来宣称自己工作的重要性，而又不至于听起来明显地夸夸其谈？  

This explains the mismatch between the words and actions of the Baptists who are actually building and funding AI – watch their actions, not their words.  

这解释了实际建造和资助人工智能的浸信会成员言行不一的原因--看他们的行动，而不是他们的言论。  

(Truman was harsher after meeting with Oppenheimer: [“Don’t let that crybaby in here again.”](https://www.lrb.co.uk/the-paper/v22/n17/steven-shapin/don-t-let-that-crybaby-in-here-again))  

(杜鲁门在与奥本海默会面后更加严厉："不要再让那个爱哭的人进来了。")

Second, some of the Baptists are actually Bootleggers. There is a whole profession of “AI safety expert”, “AI ethicist”, “AI risk researcher”.  

第二，一些浸礼者实际上是盗版商。有一个完整的 "人工智能安全专家"、"人工智能伦理学家"、"人工智能风险研究员 "的职业。  

They are paid to be doomers, and their statements should be processed appropriately.  

他们是拿钱来当厄运者的，他们的报表应该得到适当的处理。

Third, [California is justifiably famous for our many thousands of cults](https://www.vanityfair.com/hollywood/2020/09/california-cults-nxivm-the-vow), from EST to the Peoples Temple, from Heaven’s Gate to the Manson Family.  

Many, although not all, of these cults are harmless, and maybe even serve a purpose for alienated people who find homes in them.  

许多，虽然不是全部，这些邪教是无害的，甚至可能对在其中找到家的被疏远的人有作用。  

But some are very dangerous indeed, and cults have a notoriously hard time straddling the line that ultimately leads to第三，加利福尼亚因我们成千上万的邪教而名声在外，从EST到人民圣殿，从天堂之门到曼森家族，都是名符其实的。 [violence and death](https://en.wikipedia.org/wiki/Peoples_Temple#Mass_murder/suicide_at_Jonestown,_Guyana).  

但有些确实非常危险，而邪教在最终导致暴力和死亡的界限上有一个众所周知的困难。

And the reality, which is obvious to everyone in the Bay Area but probably not outside of it, is that “AI risk” has [developed](https://studio.ribbonfarm.com/p/the-priest-in-the-arena) [into](https://twitter.com/QiaochuYuan/status/1542767419394912256) a [cult](https://www.lesswrong.com/posts/MnFqyPLqbiKL8nSR7/my-experience-at-and-around-miri-and-cfar-inspired-by-zoe), which has suddenly emerged into the daylight of global press attention and the public conversation.  

This cult has pulled in not just fringe characters, but also some actual industry experts and a not small number of wealthy donors – including, until recently,而现实，对湾区的每个人来说都是显而易见的，但对湾区以外的人来说可能就不是了，那就是 "人工智能风险 "已经发展成一个邪教，突然出现在全球媒体关注和公众谈话的日光之下。 [Sam Bankman-Fried](https://fortune.com/2022/11/15/sam-bankman-fried-ftx-collapse-a-i-safety-research-effective-altruism-debacle/). And it’s developed a full panoply of cult behaviors and beliefs.  

这个邪教不仅拉拢了一些边缘人物，而且还拉拢了一些真正的行业专家和数量不少的富有的捐赠者--包括直到最近的山姆-班克曼-弗里德。它已经形成了一整套的邪教行为和信仰。

This cult is why there are a set of AI risk doomers who [sound so extreme](https://www.youtube.com/watch?v=gA1sNLL6yg4) – it’s not that they actually have secret knowledge that make their extremism logical, it’s that they’ve whipped themselves into a frenzy and really are…extremely extreme.  

这个邪教就是为什么有一组听起来如此极端的人工智能风险厄运者--并不是他们真的有秘密的知识，使他们的极端主义合乎逻辑，而是他们把自己鞭打得晕头转向，真的是......极其极端。

It turns out that this type of cult isn’t new – there is a longstanding Western tradition of [millenarianism](https://en.wikipedia.org/wiki/Millenarianism), which generates apocalypse cults. The AI risk cult has all the hallmarks of a millenarian apocalypse cult. From Wikipedia, with additions by me:  

事实证明，这种类型的邪教并不新鲜--西方有悠久的千禧年主义传统，这产生了天启邪教。人工智能风险邪教具有千禧年天启邪教的所有特征。来自维基百科，由我补充：

> “Millenarianism is the belief by a group or movement \[AI risk doomers\] in a coming fundamental transformation of society \[the arrival of AI\], after which all things will be changed \[AI utopia, dystopia, and/or end of the world\].  
> 
> "千禧年主义是一个团体或运动\[人工智能风险预言家\]对即将到来的社会根本性转变\[人工智能的到来\]的信念，之后所有的东西都将被改变\[人工智能乌托邦、二维码和/或世界末日\]。  
> 
> Only dramatic events \[AI bans, airstrikes on datacenters, nuclear strikes on unregulated AI\] are seen as able to change the world \[prevent AI\] and the change is anticipated to be brought about, or survived, by a group of the devout and dedicated.  
> 
> 只有戏剧性的事件\[人工智能禁令、对数据中心的空袭、对不受管制的人工智能的核打击\]才被视为能够改变世界\[防止人工智能\]，而这种改变预计将由一群虔诚而敬业的人带来，或幸存下来。  
> 
> In most millenarian scenarios, the disaster or battle to come \[AI apocalypse, or its prevention\] will be followed by a new, purified world \[AI bans\] in which the believers will be rewarded \[or at least acknowledged to have been correct all along\].”  
> 
> 在大多数千禧年的设想中，即将到来的灾难或战斗\[人工智能启示录，或其预防\]将被一个新的、净化的世界\[人工智能禁令\]所取代，在这个世界里，信徒将得到回报\[或至少承认一直以来都是正确的\]。"

This apocalypse cult pattern is so obvious that I am surprised more people don’t see it.  

这种天启邪教的模式非常明显，我很惊讶更多的人没有看到它。

Don’t get me wrong, cults are fun to hear about, [their written material is often creative and fascinating](https://hpmor.com/), and their members are engaging at dinner parties and [on TV](https://www.youtube.com/watch?v=hO8aYSApnng). But their extreme beliefs should not determine the future of laws and society – _obviously_ not.  

不要误会我的意思，邪教是很有趣的，他们的书面材料往往是创造性的和迷人的，他们的成员在晚宴和电视上很有吸引力。但他们的极端信仰不应决定法律和社会的未来--显然不是。

## **AI Risk #2: Will AI Ruin Our Society?  

AI风险二：AI会毁掉我们的社会吗？**

The second widely mooted AI risk is that AI will ruin our society, by generating outputs that will be so “harmful”, to use the nomenclature of this kind of doomer, as to cause profound damage to humanity, even if we’re not literally killed.  

第二个被广泛讨论的人工智能风险是，人工智能将毁掉我们的社会，因为它产生的产出将是如此 "有害"，用这种做作的术语来说，会对人类造成深刻的损害，即使我们不是真的被杀死。

Short version: If the murder robots don’t get us, the hate speech and misinformation will.  

简短的版本：如果谋杀机器人没有抓住我们，仇恨言论和错误信息就会。

This is a relatively recent doomer concern that branched off from and somewhat took over the “AI risk” movement that I described above.  

这是一个相对较新的关注，它从我上面描述的 "人工智能风险 "运动中分化出来，并在某种程度上接管了这个运动。  

In fact, the terminology of AI risk recently changed from “AI safety” – the term used by people who are worried that AI would literally kill us – to “AI alignment” – the term used by people who are worried about societal “harms”.  

事实上，人工智能风险的术语最近从 "人工智能安全"--那些担心人工智能会真的杀死我们的人使用的术语--变成了 "人工智能调整"--那些担心社会 "伤害 "的人使用的术语。  

The original AI safety people are frustrated by this shift, although they don’t know how to put it back in the box – they now advocate that the _actual_ AI risk topic be renamed “AI notkilleveryoneism”, which has [not yet been widely adopted](https://www.greaterwrong.com/posts/jMzBhCRrr7otmqcvK/notkilleveryoneism-sounds-dumb) but is at least clear.  

原先的人工智能安全人士对这一转变感到沮丧，尽管他们不知道如何把它放回盒子里--他们现在主张把实际的人工智能风险话题改名为 "人工智能不自由主义"，这还没有被广泛采用，但至少是明确的。

The tipoff to the nature of the AI societal risk claim is its own term, “AI alignment”. [Alignment with what?](https://futureoflife.org/ai/align-artificial-intelligence-with-human-values/) Human values. [Whose human values?](https://arxiv.org/pdf/2301.03740.pdf) Ah, that’s where things get tricky.  

对人工智能社会风险主张的性质的提示是它自己的术语，"人工智能对齐"。与什么保持一致？人类的价值观。谁的人类价值观？啊，这就是事情变得棘手的地方。

As it happens, I have had a front row seat to an analogous situation – the social media “trust and safety” wars. As is [now](https://en.wikipedia.org/wiki/Twitter_Files) [obvious](https://twitter.com/AGAndrewBailey/status/1664286859344719872), social media services have been under massive pressure from governments and activists to ban, restrict, censor, and otherwise suppress a wide range of content for many years.  

And the same concerns of “hate speech” (and its mathematical counterpart, “algorithmic bias”) and “misinformation” are being恰好，我在前排看到了一个类似的情况--社交媒体的 "信任和安全 "战争。正如现在所见，社交媒体服务多年来一直受到来自政府和活动家的巨大压力，要求禁止、限制、审查和以其他方式压制各种内容。 [directly transferred](https://cyber.fsi.stanford.edu/io/news/forecasting-potential-misuses-language-models-disinformation-campaigns-and-how-reduce-risk) from the social media context to the new frontier of “AI alignment”.   

而对 "仇恨言论"（及其数学上的对应物 "算法偏见"）和 "错误信息 "的担忧也正从社交媒体背景直接转移到 "人工智能对接 "的新领域。

My big learnings from the social media wars are:  

我从社交媒体大战中得到的最大收获是：

On the one hand, there is no absolutist free speech position. First, every country, including the United States, [makes at least some content illegal](https://en.wikipedia.org/wiki/United_States_free_speech_exceptions).  

Second, there are certain kinds of content, like child pornography and incitements to real world violence, that are nearly universally agreed to be off limits – legal or not – by virtually every society.  

第二，有某些类型的内容，如儿童色情和煽动现实世界的暴力，几乎被每个社会普遍认为是禁区--无论是否合法。  

So any technological platform that facilitates or generates content – speech – is going to have一方面，不存在绝对主义的言论自由立场。首先，每个国家，包括美国，都至少有一些内容是非法的。 _some_ restrictions.  

因此，任何促进或产生内容--言论的技术平台都会有一些限制。

On the other hand, the slippery slope is not a fallacy, it’s an inevitability.  

另一方面，"滑坡 "不是一个谬论，而是一种不可避免的情况。  

Once a framework for restricting even egregiously terrible content is in place – for example, for hate speech, a specific hurtful word, or for misinformation, obviously false claims like “[the Pope is dead](https://www.americamagazine.org/politics-society/2022/07/12/pope-benedict-dead-fake-news-243347)” – a shockingly broad range of [government agencies](https://judiciary.house.gov/sites/evo-subsites/republicans-judiciary.house.gov/files/evo-media-document/2023-04-28-jdj-to-rubin-gec-subpoena-cover-letter.pdf) and [activist pressure groups](https://en.wikipedia.org/wiki/Color_of_Change) and [nongovernmental entities](https://cyber.fsi.stanford.edu/io) will kick into gear and demand ever greater levels of censorship and suppression of whatever speech they view as threatening to society and/or their own personal preferences.  

They will do this up to and including in ways that are nakedly一旦有了限制哪怕是极其糟糕的内容的框架--例如，针对仇恨言论、某个特定的伤害性词汇，或者针对错误信息、像 "教皇已死 "这样明显的虚假说法--令人震惊的广泛的政府机构和积极的压力团体以及非政府实体就会启动，要求对他们认为威胁到社会和/或其个人偏好的任何言论进行更高水平的审查和压制。 [felony](https://www.law.cornell.edu/uscode/text/18/241) [crimes](https://www.law.cornell.edu/uscode/text/18/242). This cycle in practice can run apparently forever, with the enthusiastic support of authoritarian hall monitors installed throughout our elite power structures.  

This has been cascading for a decade in social media and with only他们会这样做，包括以赤裸裸的重罪的方式。在我们整个精英权力结构中安装的专制大厅监视器的热情支持下，这种循环在实践中显然可以永远运行。 [certain](https://twitter.com/home) [exceptions](https://substack.com/) continues to get more fervent all the time.  

这种情况在社交媒体上已经持续了十年，而且除了某些例外情况，还在继续变得更加狂热。

And so this is the dynamic that has formed around “AI alignment” now.  

因此，这就是现在围绕 "AI对齐 "所形成的动态。  

Its proponents claim the wisdom to engineer AI-generated speech and thought that are good for society, and to ban AI-generated speech and thoughts that are bad for society. Its _opponents_ claim that the thought police are breathtakingly arrogant and presumptuous – and often outright criminal, at least in the US – and in fact are seeking to become a new kind of fused government-corporate-academic authoritarian speech dictatorship ripped straight from the pages of George Orwell’s _1984_.  

它的支持者声称，他们有智慧设计对社会有益的人工智能生成的言论和思想，并禁止对社会有害的人工智能生成的言论和思想。它的反对者声称，思想警察是惊人的傲慢和自以为是--至少在美国，往往是彻头彻尾的犯罪--事实上，他们正在寻求成为一种新的融合了政府-公司-学术界的专制言论独裁政权，直接从乔治-奥威尔的《1984》中扯出来。

As the proponents of both “trust and safety” and “AI alignment” are clustered into the very narrow slice of the global population that characterizes the American coastal elites – which includes many of the people who work in and write about the tech industry – many of my readers will find yourselves primed to argue that dramatic restrictions on AI output are required to avoid destroying society.  

由于 "信任与安全 "和 "人工智能调整 "的支持者都集中在全球人口中非常狭窄的片区，即美国沿海精英的特征--其中包括许多在科技行业工作和写文章的人--我的许多读者会发现，你们已经准备好论证，需要对人工智能产出进行巨大的限制，以避免破坏社会。  

I will not attempt to talk you out of this now, I will simply state that this is the nature of the demand, and that most people in the world neither agree with your ideology [nor want to see you win](https://www.nytimes.com/2022/03/18/opinion/cancel-culture-free-speech-poll.html).  

我现在不会试图说服你，我只想说这是需求的本质，世界上大多数人既不同意你的意识形态，也不希望看到你获胜。

If you _don’t_ agree with the prevailing niche morality that is being imposed on both social media and AI via ever-intensifying speech codes, you should also realize that the fight over what AI is allowed to say/generate will be even more important – by a _lot_ – than the fight over social media censorship. AI is highly likely to be the control layer for everything in the world.  

How it is allowed to operate is going to matter perhaps more than anything else has ever mattered.  

如何允许它运作，也许比其他任何事情都更重要。  

You should be aware of how a small and isolated coterie of partisan social engineers are trying to determine that right now, under cover of the age-old claim that they are protecting you.  

你应该意识到，一小撮孤立的党派社会工程师现在正试图以他们正在保护你的古老说法为掩护，来决定这一点。  

如果你不同意通过不断强化的言论准则强加给社交媒体和人工智能的主流小众道德，你也应该意识到，关于人工智能被允许说什么/生成什么的斗争将比社交媒体审查制度的斗争更加重要--重要得多。人工智能极有可能成为世界上一切事物的控制层。

In short, don’t let the thought police suppress AI.  

简而言之，不要让思想警察压制人工智能。

## **AI Risk #3: Will AI Take All Our Jobs?  

AI风险之三：AI会夺走我们所有的工作吗？**

The fear of job loss due variously to mechanization, automation, computerization, or AI has been a recurring panic for hundreds of years, since the original onset of machinery such as the [mechanical loom](https://en.wikipedia.org/wiki/Luddite). Even though every new major technology has led to more jobs at higher wages throughout history, each wave of this panic is accompanied by claims that “this time is different” – _this_ is the time it will finally happen, _this_ is the technology that will finally deliver the hammer blow to human labor. And yet, it never happens.   

自机械织布机等机械最初出现以来，对机械化、自动化、计算机化或人工智能导致的工作流失的恐惧，几百年来一直是一种反复出现的恐慌。尽管历史上每一项新的主要技术都导致了更多的工作机会和更高的工资，但每一波恐慌都伴随着 "这次不同 "的说法--这次终于要发生了，这是最终将给人类劳动力带来重击的技术。然而，它从未发生。

We’ve been through two such technology-driven unemployment panic cycles in our recent past – the [outsourcing](http://nfap.com/researchactivities/globalsourcing/itemsInterest/AndreesenDobbsCNN_030404.pdf) panic of the 2000’s, and the [automation](https://www.usatoday.com/story/money/2017/11/29/automation-could-kill-73-million-u-s-jobs-2030/899878001/) panic of the 2010’s. Notwithstanding many talking heads, pundits, and even [tech industry executives](https://www.ycombinator.com/blog/basic-income) pounding the table throughout both decades that mass unemployment was near, by late 2019 – right before the onset of COVID – the world had more jobs at higher wages than ever in history.  

在我们最近的过去，我们已经经历了两个这样的技术驱动的失业恐慌周期--2000年代的外包恐慌，以及2010年代的自动化恐慌。尽管在这两个十年中，许多谈话者、专家，甚至科技行业的高管都在敲打桌子，说大规模失业即将来临，但到2019年底--就在COVID开始之前--世界上有比历史上更多的工作机会，而且工资更高。

Nevertheless [this mistaken idea will not die](https://www.marxists.org/history/etol/newspape/isr/vol25/no03/adhoc.html).  

然而，这种错误的想法不会消失。

And sure enough, [it’s back](https://www.theinformation.com/articles/ai-will-destroy-jobs-so-what-are-we-going-to-do-about-it).  

果然，它回来了。

_This time_, we _finally_ have the technology that’s going to take all the jobs and render human workers superfluous – _real_ AI. Surely _this time_ history won’t repeat, and AI will cause mass unemployment – and not rapid economic, job, and wage growth – right?  

这一次，我们终于有了会抢走所有工作并使人类工人变得多余的技术--真正的人工智能。当然，这一次历史不会重演，人工智能将导致大规模失业--而不是经济、就业和工资的快速增长--对吗？

No, that’s not going to happen – and in fact AI, if allowed to develop and proliferate throughout the economy, may cause the most dramatic and sustained economic boom of all time, with correspondingly record job and wage growth – the exact opposite of the fear.  

不，这不会发生--事实上，如果允许人工智能在整个经济中发展和扩散，可能会导致有史以来最引人注目和持续的经济繁荣，相应的就业和工资增长也创下纪录--这与恐惧完全相反。

And here’s why.

 原因就在这里。

The core mistake the automation-kills-jobs doomers keep making is called the [Lump Of Labor Fallacy](https://en.wikipedia.org/wiki/Lump_of_labour_fallacy).  

This fallacy is the incorrect notion that there is a fixed amount of labor to be done in the economy at any given time, and either machines do it or people do it – and if machines do it, there will be no work for people to do.  

这种谬论是一种不正确的观念，即在任何时候经济中都有固定数量的劳动需要完成，要么机器做，要么人做--如果机器做，就没有工作给人做。  

自动化杀死工作的厄运者们一直在犯的核心错误被称为 "劳动力总量的谬误"。

The Lump Of Labor Fallacy flows naturally from naive intuition, but naive intuition here is wrong. When technology is applied to production, we get [_productivity growth_](https://en.wikipedia.org/wiki/Productivity) – an increase in output generated by a reduction in inputs. The result is _lower prices_ for goods and services. As prices for goods and services fall, we pay less for them, meaning that we now have _extra spending power_ with which to buy _other things_. This _increases demand_ in the economy, which drives the creation of _new production_ – including new products and new industries – which then creates new jobs for the people who were replaced by machines in prior jobs.  

The result is a larger economy with higher material prosperity, more industries, more products, and more jobs.  

其结果是一个更大的经济，具有更高的物质繁荣度，更多的产业，更多的产品和更多的就业机会。  

劳动块的谬误自然来自于天真的直觉，但天真的直觉在这里是错误的。当技术应用于生产时，我们会得到生产力的增长--通过减少投入而产生的产出的增加。其结果是商品和服务的价格降低。由于商品和服务的价格下降，我们为它们支付的费用减少，这意味着我们现在有额外的消费能力来购买其他东西。这增加了经济中的需求，从而推动了新生产的产生--包括新产品和新产业--然后为之前工作中被机器取代的人创造新的就业机会。

But the good news doesn’t stop there. We also get higher wages. This is because, at the level of the individual worker, the marketplace sets compensation as a function of the [_marginal productivity of the worker_](https://en.wikipedia.org/wiki/Marginal_revenue_productivity_theory_of_wages). A worker in a technology-infused business will be more productive than a worker in a traditional business.  

The employer will either pay that worker more money as he is now more productive, or another employer will, purely out of self interest.  

雇主要么向该工人支付更多的钱，因为他现在的生产力更高，要么另一个雇主会这样做，这完全是出于自身利益。  

The result is that technology introduced into an industry generally not only increases the number of jobs in the industry but also raises wages.  

其结果是，引入一个行业的技术通常不仅增加该行业的工作数量，而且还提高了工资。  

但好消息还不止于此。我们也得到了更高的工资。这是因为，在工人个人层面上，市场将报酬设定为工人的边际生产力的函数。一个在技术融合的企业工作的工人将比在传统企业工作的工人更有生产力。

To summarize, technology empowers people to be more productive. This causes the prices for existing goods and services to fall, and for wages to rise.  

总而言之，技术赋予人们更多的生产力。这导致现有商品和服务的价格下降，工资上升。  

This in turn causes economic growth and job growth, while motivating the creation of new jobs and new industries.  

这反过来又会引起经济增长和就业增长，同时激励创造新的就业机会和新的产业。  

If a market economy is allowed to function normally and if technology is allowed to be introduced freely, this is a perpetual upward cycle that never ends.  

如果允许市场经济正常运行，如果允许自由引进技术，这就是一个永远不会结束的上升循环。  

For, as Milton Friedman observed, “Human wants and needs are endless” – we always want more than we have.  

因为，正如米尔顿-弗里德曼所观察到的，"人类的愿望和需求是无止境的" - 我们总是想要比我们拥有的更多。  

A technology-infused market economy is the way we get closer to delivering everything everyone could conceivably want, but never all the way there. [And that is why technology doesn’t destroy jobs and never will.](https://www.aeaweb.org/articles?id=10.1257/jep.29.3.3)  

融入技术的市场经济是我们更接近于提供每个人可以想象的一切的方式，但永远不会完全实现。这就是为什么技术不会破坏工作，而且永远不会。

These are such mindblowing ideas for people who have not been exposed to them that it may take you some time to wrap your head around them.  

对于没有接触过这些想法的人来说，这些想法是如此令人心动，你可能需要一些时间来理清思路。  

But I swear I’m not making them up – in fact you can read all about them in standard economics textbooks. I recommend the chapter [_The Curse of Machinery_](https://fee.org/resources/economics-in-one-lesson#calibre_link-31) in Henry Hazlitt’s _Economics In One Lesson_, and Frederic Bastiat’s satirical _Candlemaker’s Petition_ to blot out the sun due to its unfair competition with the lighting industry, [here modernized for our times](https://www.aei.org/carpe-diem/the-candlemakers-petition-revised-and-modernized-for-todays-climate-of-rising-trade-protectionism/).  

但我发誓我没有编造它们--事实上，你可以在标准的经济学教科书中读到它们的全部内容。我推荐亨利-哈兹利特的《经济学一课》中的《机械的诅咒》一章，以及弗雷德里克-巴斯蒂亚特的讽刺性的《蜡烛制造者的请愿书》，由于它与照明行业的不公平竞争而遮住了太阳，这里为我们的时代做了现代化处理。

_But this time is different_, you’re thinking. _This time, with AI, we have the technology that can replace ALL human labor._  

但这次是不同的，你在想。这一次，有了人工智能，我们有了可以取代所有人类劳动的技术。

But, using the principles I described above, think of what it would mean for literally all existing human labor to be replaced by machines.  

但是，利用我上面描述的原则，想一想，如果所有现有的人类劳动都被机器取代，这意味着什么？

It would mean a takeoff rate of economic productivity growth that would be absolutely stratospheric, far beyond any historical precedent.  

这将意味着经济生产力的起飞速度将是绝对的平流层，远远超过任何历史先例。  

Prices of existing goods and services would drop across the board to virtually zero. Consumer welfare would skyrocket. Consumer spending power would skyrocket.  

现有商品和服务的价格将全面下降到几乎为零。消费者福利将急剧上升。消费者的消费能力将直线上升。  

New demand in the economy would explode. Entrepreneurs would create dizzying arrays of new industries, products, and services, and employ as many people _and_ AI as they could as fast as possible to meet all the new demand.  

经济中的新需求将爆炸性增长。企业家们会创造出令人眼花缭乱的新产业、新产品和新服务，并以最快的速度雇用尽可能多的人和人工智能来满足所有新的需求。

Suppose AI once again replaces _that_ labor? The cycle would repeat, driving consumer welfare, economic growth, and job and wage growth even higher.  

It would be a straight spiral up to a material utopia that neither Adam Smith or Karl Marx ever dared dream of.   

这将是一个直线上升到亚当-斯密和卡尔-马克思都不敢梦想的物质乌托邦。  

假设人工智能再次取代了这些劳动力？这个循环会重复，推动消费者福利、经济增长、就业和工资增长甚至更高。

We should be so lucky.  

我们应该是如此幸运。

## **AI Risk #4: Will AI Lead To Crippling Inequality?  

人工智能风险四：人工智能是否会导致残缺不全的不平等？**

Speaking of Karl Marx, the concern about AI taking jobs segues directly into the next claimed AI risk, which is, OK, Marc, suppose AI _does_ take all the jobs, either for bad or for good.  

Won’t that result in massive and crippling wealth inequality, as the owners of AI reap all the economic rewards and regular people get nothing?  

这难道不会导致大规模和严重的财富不平等，因为人工智能的拥有者获得了所有的经济回报，而普通人什么都没有得到？  

说到卡尔-马克思，对人工智能抢走工作的担忧直接进入了下一个声称的人工智能风险，也就是，好吧，马克思，假设人工智能真的抢走了所有的工作，无论是坏事还是好事。

As it happens, this was a central claim of Marxism, that the owners of the means of production – the bourgeoisie – would inevitably steal all societal wealth from the people who do the actual  work – the proletariat.  

恰好，这是马克思主义的一个核心主张，即生产资料的所有者--资产阶级--将不可避免地从从事实际工作的人--无产阶级那里偷走所有的社会财富。  

This is another fallacy that simply will not die no matter how often it’s disproved by reality. But let’s drive a stake through its heart anyway.  

这是另一个根本不会消亡的谬论，无论它被现实驳倒多少次。但我们还是要把木桩刺进它的心脏。

The flaw in this theory is that, as the owner of a piece of technology, it’s not in your own interest to keep it to yourself – in fact the opposite, it’s in your own interest to sell it to as many customers as possible.  

这一理论的缺陷在于，作为一项技术的所有者，把它留给自己并不符合你自己的利益--事实上恰恰相反，把它卖给尽可能多的客户才符合你自己的利益。  

The largest market in the world for any product is the entire world, all 8 billion of us.  

世界上任何产品的最大市场是整个世界，我们所有的80亿人。  

And so in reality, every new technology – even ones that start by selling to the rarefied air of high-paying big companies or wealthy consumers – rapidly proliferates until it’s in the hands of the largest possible mass market, ultimately everyone on the planet.  

因此，在现实中，每一项新技术--即使是那些一开始就卖给高薪大公司或富有的消费者的稀有空气--都会迅速扩散，直到它落入最大可能的大众市场手中，最终成为地球上的每个人。

The classic example of this was Elon Musk’s so-called [“secret plan”](https://www.tesla.com/blog/secret-tesla-motors-master-plan-just-between-you-and-me) – which he naturally published openly – for Tesla in 2006:  

这方面的典型例子是埃隆-马斯克在2006年为特斯拉制定的所谓 "秘密计划"--他自然会公开发表：

> Step 1, Build \[expensive\] sports car  
> 
> 第1步，建造\[昂贵的\]跑车
> 
> Step 2, Use that money to build an affordable car  
> 
> 第2步，用这些钱造出一辆经济适用的汽车
> 
> Step 3, Use that money to build an even more affordable car  
> 
> 第三步，用这些钱造出更实惠的汽车

…which is of course exactly what he’s done, becoming the richest man in the world as a result.  

...当然，这正是他所做的，并因此而成为世界上最富有的人。

That last point is key. Would Elon be even richer if he only sold cars to rich people today? No. Would he be even richer than that if he only made cars for himself? Of course not.  

最后一点是关键。如果埃隆今天只向富人出售汽车，他会更富有吗？不会。如果他只为自己制造汽车，他会比这更富有吗？当然不会。  

No, he maximizes his own profit by selling to the largest possible market, the world.  

不，他通过向最大可能的市场--世界--销售，使自己的利润最大化。

In short, everyone gets the thing – as we saw in the past with not just cars but also electricity, radio, computers, the Internet, mobile phones, and search engines.  

简而言之，每个人都会得到这个东西--正如我们在过去看到的不仅是汽车，还有电力、广播、计算机、互联网、手机和搜索引擎。  

The makers of such technologies are highly motivated to drive down their prices until everyone on the planet can afford them.  

这类技术的制造商有很大的动力来降低其价格，直到地球上的每个人都能买得起它们。  

This is precisely what is already happening in AI – it’s why you can use state of the art generative AI not just at low cost but even _for free_ today in the form of Microsoft Bing and Google Bard – and it is what will continue to happen.  

Not because such vendors are foolish or generous but precisely because they are greedy – they want to maximize the size of their market, which maximizes their profits.  

这并不是因为这类供应商愚蠢或慷慨，而恰恰是因为他们的贪婪--他们希望最大限度地扩大市场规模，从而使他们的利润最大化。  

这正是人工智能中已经发生的事情--这就是为什么你今天不仅可以低成本地使用最先进的生成性人工智能，甚至可以以微软必应和谷歌巴德的形式免费使用--这也是将继续发生的事情。

So what happens is the opposite of technology driving centralization of wealth – individual customers of the technology, ultimately including everyone on the planet, are empowered instead, and [capture most of the generated value](https://www.nber.org/digest/oct04/who-gains-innovation). As with prior technologies, the companies that build AI – assuming they have to function in a free market – will compete furiously to make this happen.  

因此，所发生的情况与技术推动财富集中化相反--技术的个人客户，最终包括地球上的每个人，反而被赋予了权力，并获得了大部分产生的价值。与之前的技术一样，建立人工智能的公司--假设它们必须在自由市场中运作--将激烈竞争以实现这一目标。

Marx was wrong then, and he’s wrong now.  

马克思当时是错的，现在也是错的。

This is _not_ to say that inequality is not an issue in our society. It is, it’s just not being driven by technology, [it’s being driven by the reverse](https://www.aei.org/carpe-diem/chart-of-the-day-or-century-8/), by the sectors of the economy that are the most _resistant_ to new technology, that have the most government intervention to _prevent_ the adoption of new technology like AI – specifically housing, education, and health care. The actual risk of AI and inequality is not that AI will _cause_ more inequality but rather that [we will not allow AI to be used to _reduce_ inequality](https://pmarca.substack.com/p/why-ai-wont-cause-unemployment)  

这并不是说不平等在我们的社会中不是一个问题。它是的，只是它不是由技术驱动的，而是由反面驱动的，由对新技术抵抗力最强的经济部门驱动的，这些部门有最多的政府干预来阻止采用像人工智能这样的新技术--特别是住房、教育和医疗保健。人工智能和不平等的实际风险不是人工智能将导致更多的不平等，而是我们将不允许人工智能被用来减少不平等。.

## **AI Risk #5: Will AI Lead To Bad People Doing Bad Things?  

人工智能风险之五：人工智能会导致坏人做坏事吗？**

So far I have explained why four of the five most often proposed risks of AI are not actually real – AI will not come to life and kill us, AI will not ruin our society, AI will not cause mass unemployment, and AI will not cause an ruinous increase in inequality.  

到目前为止，我已经解释了为什么在最常提出的五种人工智能风险中，有四种实际上并不真实--人工智能不会活过来并杀死我们，人工智能不会毁掉我们的社会，人工智能不会导致大规模失业，人工智能不会导致不平等现象的破坏性增加。  

But now let’s address the fifth, the one I actually agree with: AI will make it easier for bad people to do bad things.  

但现在我们来谈谈第五点，也就是我真正同意的那一点：人工智能将使坏人更容易做坏事。

In some sense this is a tautology. Technology is a tool.  

在某种意义上，这是一个同义词。技术是一种工具。  

Tools, starting with fire and rocks, can be used to do good things – cook food and build houses – and bad things – burn people and bludgeon people.  

工具，从火和石头开始，可以用来做善事--烹饪食物和建造房屋，也可以用来做恶事--烧死人和打伤人。  

Any technology can be used for good or bad. Fair enough. And AI will make it easier for criminals, terrorists, and hostile governments to do bad things, no question.  

任何技术都可以被用来做好事或做坏事。这很公平。而人工智能将使犯罪分子、恐怖分子和敌对政府更容易做坏事，这是毫无疑问的。

This causes some people to propose, _well, in that case, let’s not take the risk, let’s ban AI now before this can happen_. Unfortunately, AI is not some esoteric physical material that is hard to come by, like plutonium.  

It’s the opposite, it’s the easiest material in the world to come by – math and code.  

恰恰相反，它是世界上最容易得到的材料--数学和代码。  

这导致一些人提出，好吧，既然如此，我们就不要冒这个险了，我们现在就禁止人工智能，以免发生这种情况。不幸的是，人工智能并不是一些深奥的物理材料，像钚一样难以得到。

The AI cat is obviously already out of the bag.  

人工智能的猫显然已经出袋了。  

You can learn how to build AI from thousands of free online courses, books, papers, and videos, and there are outstanding open source implementations proliferating by the _day_. AI is like air – it will be everywhere.  

The level of totalitarian oppression that would be required to arrest that would be so draconian – a world government monitoring and controlling all computers?  

逮捕的极权主义压迫程度会如此严酷--一个世界政府监视和控制所有的计算机？  

jackbooted thugs in black helicopters seizing rogue GPUs? – that we would not have a society left to protect.  

开着黑色直升飞机的长靴暴徒夺取流氓GPU？- 那我们就没有一个可以保护的社会了。  

你可以从数以千计的免费在线课程、书籍、论文和视频中学习如何构建人工智能，而且有杰出的开源实施方案在不断涌现。人工智能就像空气一样--它将无处不在。

So instead, there are two very straightforward ways to address the risk of bad people doing bad things with AI, and these are precisely what we should focus on.  

因此，相反，有两种非常直接的方式来解决坏人利用人工智能做坏事的风险，而这些正是我们应该关注的。

First, we have laws on the books to criminalize most of the bad things that anyone is going to do with AI. Hack into the Pentagon? That’s a crime. Steal money from a bank?  

首先，我们有法律规定，任何人要用人工智能做的大部分坏事都是犯罪。入侵五角大楼？那是犯罪。从银行偷钱？  

That’s a crime. Create a bioweapon? That’s a crime. Commit a terrorist act? That’s a crime.  

那是一种犯罪。制造生物武器？这也是一种犯罪。实施恐怖主义行为？那就是犯罪。  

We can simply focus on preventing those crimes when we can, and prosecuting them when we cannot.  

我们可以简单地专注于在我们能够做到的时候防止这些犯罪，在我们不能做到的时候起诉他们。  

We don’t even need new laws – I’m not aware of a single actual bad use for AI that’s been proposed that’s not already illegal. And if a new bad use is identified, we ban that use.  

我们甚至不需要新的法律--我不知道已经提出的人工智能的任何一个实际的坏用途都是不合法的。如果发现有新的不良用途，我们就禁止这种用途。  

QED.

But you’ll notice what I slipped in there – I said we should focus first on _preventing_ AI-assisted crimes before they happen – wouldn’t such prevention mean banning AI? Well, there’s another way to prevent such actions, and that’s by _using AI as a defensive tool_.  

The same capabilities that make AI dangerous in the hands of bad guys with bad goals make it powerful in the hands of good guys with good goals – specifically the good guys whose job it is to prevent bad things from happening.  

使人工智能在有坏目标的坏人手中变得危险的同样能力，在有好目标的好人手中也变得强大--特别是那些其工作是防止坏事发生的好人。  

但是你会注意到我在那里滑落的东西--我说我们应该首先专注于在人工智能协助的犯罪行为发生之前预防它们--这样的预防不是意味着禁止人工智能吗？好吧，还有另一种方法来防止这种行为，那就是把人工智能作为一种防御工具。

For example, if you are worried about AI generating fake people and fake videos, the answer is to build new systems where people can verify [themselves](https://www.biometricupdate.com/202303/worldcoin-says-sdk-lets-you-prove-youre-a-human-online-coins-not-included) and [real content](https://www.wired.com/story/the-blockchain-solution-to-our-deepfake-problems/) via cryptographic signatures.  

Digital creation and alteration of both real and fake content was already here before AI; the answer is not to ban word processors and Photoshop – or AI – but to use technology to build a system that actually solves the problem.  

在人工智能之前，真实和虚假内容的数字创作和修改已经存在；答案不是禁止文字处理器和Photoshop--或人工智能--而是利用技术建立一个真正解决问题的系统。  

例如，如果你担心人工智能产生假人和假视频，答案是建立新的系统，人们可以通过加密签名验证自己和真实内容。

And so, second, let’s mount major efforts to use AI for good, legitimate, _defensive_ purposes.  

Let’s put AI to work in cyberdefense, in biological defense, in hunting terrorists, and in everything else that we do to keep ourselves, our communities, and our nation safe.  

让我们把人工智能用于网络防御、生物防御、猎杀恐怖分子，以及我们为保持自己、社区和国家安全所做的其他一切。  

因此，第二，让我们做出重大努力，将人工智能用于良好的、合法的、防御性的目的。

There are already many smart people in and out of government doing exactly this, of course – but if we apply all of the effort and brainpower that’s currently fixated on the futile prospect of _banning_ AI to _using_ AI to protect against bad people doing bad things, I think there’s no question a world infused with AI will be much safer than the world we live in today.  

当然，政府内外已经有很多聪明人在做这件事了--但如果我们把目前固定在禁止人工智能这一徒劳的前景上的所有努力和脑力都用于利用人工智能来防止坏人做坏事，我认为毫无疑问，一个注入人工智能的世界将比我们今天生活的世界安全得多。

## **The Actual Risk Of Not Pursuing AI With Maximum Force And Speed  

不以最大力度和速度追求人工智能的实际风险**

There is one final, and real, AI risk that is probably the scariest at all:  

有一个最后的，也是真实的人工智能风险，可能是最可怕的：

AI isn’t just being developed in the relatively free societies of the West, it is also being developed by the Communist Party of the People’s Republic of China.  

人工智能不仅仅是在西方相对自由的社会中发展，中华人民共和国的共产党也在发展。

China has a [vastly different vision](https://www.nytimes.com/2018/07/08/business/china-surveillance-technology.html) for AI than we do – they view it as a mechanism for authoritarian population control, full stop. They are not even being secretive about this, they are [very clear about it](https://digichina.stanford.edu/work/full-translation-chinas-new-generation-artificial-intelligence-development-plan-2017/), and they are already pursuing their agenda. And they do not intend to limit their AI strategy to China – they intend to [proliferate it all across the world](https://www.cfr.org/china-digital-silk-road/), everywhere they are powering 5G networks, everywhere they are loaning Belt And Road money, everywhere they are providing friendly consumer apps like Tiktok that serve as front ends to their centralized command and control AI.  

中国对人工智能的看法与我们大相径庭--他们将其视为一种专制的人口控制机制，完全是这样。他们甚至没有对此保密，他们对此非常清楚，而且他们已经在推行他们的议程。而且他们不打算将他们的人工智能战略局限于中国--他们打算在世界各地推广人工智能，在他们为5G网络提供动力的地方，在他们为 "一带一路 "贷款的地方，在他们提供像Tiktok这样友好的消费者应用程序的地方，作为他们集中式指挥和控制人工智能的前端。

_The single greatest risk of AI is that China wins global AI dominance and we – the United States and the West – do not.  

人工智能的最大风险是中国赢得全球人工智能主导地位，而我们--美国和西方--没有。_

I propose a simple strategy for what to do about this – in fact, the same strategy President Ronald Reagan used to win the first Cold War with the Soviet Union.  

我提出了一个简单的策略来解决这个问题--事实上，这也是罗纳德-里根总统用来赢得与苏联第一次冷战的策略。

[“We win, they lose.” "我们赢，他们输"。](https://claremontreviewofbooks.com/we-win-they-lose/)

Rather than allowing ungrounded panics around killer AI, “harmful” AI, job-destroying AI, and inequality-generating AI to put us on our back feet, we in the United States and the West should lean into AI as hard as we possibly can.  

与其让围绕杀手级人工智能、"有害的 "人工智能、破坏就业的人工智能和产生不平等的人工智能的毫无根据的恐慌使我们束手无策，我们美国和西方国家应该尽可能地靠向人工智能。

_We should seek to win the race to global AI technological superiority and ensure that China does not.  

我们应该寻求在全球人工智能技术优势的竞争中获胜，并确保中国不会这样做。_

In the process, we should drive AI into our economy and society as fast and hard as we possibly can, in order to maximize its gains for economic productivity and human potential.  

在这个过程中，我们应该尽可能快、尽可能努力地推动人工智能进入我们的经济和社会，以使其对经济生产力和人类潜力的收益最大化。

_This_ is the best way both to offset the _real_ AI risks and to ensure that our way of life is not displaced by the [much darker Chinese vision](https://www.theatlantic.com/magazine/archive/2020/09/china-ai-surveillance/614197/).  

这是最好的方法，既能抵消真正的人工智能风险，又能确保我们的生活方式不会被更黑暗的中国愿景所取代。

## **What Is To Be Done?  

该怎么做？**

I propose a simple plan:  

我提出一个简单的计划：

-   Big AI companies should be allowed to build AI as fast and aggressively as they can – but _not_ allowed to achieve regulatory capture, _not_ allowed to establish a government-protect cartel that is insulated from market competition due to incorrect claims of AI risk.  
    
    This will maximize the technological and societal payoff from the amazing capabilities of these companies, which are jewels of modern capitalism.  
    
    这将使这些作为现代资本主义明珠的公司的惊人能力在技术和社会方面得到最大的回报。  
    
    应该允许大的人工智能公司尽可能快地、积极地建立人工智能--但不允许其实现监管俘获，不允许其建立一个政府保护的卡特尔，由于对人工智能风险的不正确主张而与市场竞争隔绝。
-   Startup AI companies should be allowed to build AI as fast and aggressively as _they_ can. They should neither confront government-granted protection of big companies, nor should they receive government assistance. They should simply be allowed to compete.  
    
    If and as startups应该允许初创的人工智能公司尽可能快地、积极地建立人工智能。他们既不应该面对政府授予的大公司的保护，也不应该接受政府援助。他们应该只是被允许进行竞争。 _don’t_ succeed, their presence in the market will also continuously motivate big companies to be their best – our economies and societies win either way.  
    
    如果和创业公司不成功，他们在市场上的存在也会不断激励大公司做到最好--我们的经济和社会无论如何都会赢。
-   Open source AI should be allowed to freely proliferate and compete with both big AI companies and startups. There should be no regulatory barriers to open source whatsoever.  
    
    应该允许开源人工智能自由扩散，并与大型人工智能公司和初创公司竞争。对开源不应该有任何监管障碍。  
    
    Even when open source does not beat companies, its widespread availability is a boon to students all over the world who want to learn how to build and use AI to become part of the technological future, and will ensure that AI is available to everyone who can benefit from it no matter who they are or how much money they have.  
    
    即使开源没有打败公司，它的广泛使用也是全世界学生的福音，他们想学习如何构建和使用人工智能，成为技术未来的一部分，并将确保人工智能提供给每个人，无论他们是谁或有多少钱，都可以从中受益。
-   To offset the risk of bad people doing bad things with AI, governments working in partnership with the private sector should vigorously engage in each area of potential risk to use AI to maximize society’s defensive capabilities.  
    
    为了抵消坏人利用人工智能做坏事的风险，政府与私营部门合作，应大力参与每个潜在风险领域，利用人工智能最大限度地提高社会的防御能力。  
    
    This shouldn’t be limited to AI-enabled risks but also more general problems such as malnutrition, disease, and climate.  
    
    这不应该局限于人工智能带来的风险，还应该包括更普遍的问题，如营养不良、疾病和气候。  
    
    AI can be an incredibly powerful tool for solving problems, and we should embrace it as such.  
    
    人工智能可以成为解决问题的一个令人难以置信的强大工具，我们应该这样拥抱它。
-   To prevent the risk of China achieving global AI dominance, we should use the full power of our private sector, our scientific establishment, and our governments in concert to drive American and Western AI to absolute global dominance, including ultimately inside China itself.  
    
    为了防止中国实现全球人工智能主导地位的风险，我们应该充分利用我们的私营部门、我们的科学机构和我们的政府的力量，协同推动美国和西方的人工智能在全球的绝对主导地位，包括最终在中国本身内部。  
    
    We win, they lose. 我们赢，他们输。

And that is how we use AI to save the world.  

而这就是我们利用人工智能拯救世界的方式。

It’s time to build. 现在是建设的时候了。

## **Legends and Heroes 传说与英雄**

I close with two simple statements.  

我以两个简单的声明结束。

The development of AI started in the 1940’s, [simultaneous with the invention of the computer](https://www.amazon.com/Rise-Machines-Cybernetic-Thomas-Rid/dp/0393286002). The first scientific paper on neural networks – the architecture of the AI we have today – was [published in 1943](https://www.cs.cmu.edu/~./epxing/Class/10715/reading/McCulloch.and.Pitts.pdf). Entire generations of AI scientists over the last 80 years were born, went to school, worked, and in many cases passed away without seeing the payoff that we are receiving now.  

They are legends, every one.  

他们每个人都是传奇人物。  

人工智能的发展开始于20世纪40年代，与计算机的发明同时进行。第一篇关于神经网络的科学论文--我们今天拥有的人工智能的架构--发表于1943年。在过去的80年里，整整几代人工智能科学家出生、上学、工作，在许多情况下，在没有看到我们现在得到的回报的情况下就去世了。

Today, growing legions of engineers – many of whom are young and may have had grandparents or even great-grandparents involved in the creation of the ideas behind AI – are working to make AI a reality, against a wall of fear-mongering and doomerism that is attempting to paint them as reckless villains.  

今天，越来越多的工程师军团--其中许多人很年轻，他们的祖父母甚至曾祖父母可能都参与了人工智能背后理念的创造--正在努力使人工智能成为现实，对抗着试图将他们描绘成鲁莽的恶棍的恐惧宣传和嘲弄之声的墙。  

I do not believe they are reckless or villains. They are heroes, every one.  

我不相信他们是鲁莽的人或恶棍。他们是英雄，每一个人都是。  

My firm and I are thrilled to back as many of them as we can, and we will stand alongside them and their work 100%.  

我的公司和我很高兴能尽可能多地支持他们，我们将100%地与他们和他们的工作站在一起。

\* \* \*

_The views expressed here are those of the individual AH Capital Management, L.L.C. (“a16z”) personnel quoted and are not the views of a16z or its affiliates.  

这里所表达的观点是AH Capital Management, L.L.C.（"a16z"）人员个人的观点，并不代表a16z或其附属机构的观点。  

Certain information contained in here has been obtained from third-party sources, including from portfolio companies of funds managed by a16z.  

这里包含的某些信息是从第三方来源获得的，包括从a16z管理的基金的投资组合公司获得。  

While taken from sources believed to be reliable, a16z has not independently verified such information and makes no representations about the current or enduring accuracy of the information or its appropriateness for a given situation.  

虽然信息来源被认为是可靠的，但a16z没有独立核实这些信息，也不对信息的当前或持久的准确性或其对特定情况的适当性作出陈述。  

In addition, this content may include third-party advertisements; a16z has not reviewed such advertisements and does not endorse any advertising content contained therein.  

此外，这些内容可能包括第三方广告；a16z没有审查这些广告，也不认可其中的任何广告内容。_

_This content is provided for informational purposes only, and should not be relied upon as legal, business, investment, or tax advice.  

本内容仅用于提供信息，不应作为法律、商业、投资或税务建议而加以依赖。  

You should consult your own advisers as to those matters.  

你应该就这些问题咨询你自己的顾问。  

References to any securities or digital assets are for illustrative purposes only, and do not constitute an investment recommendation or offer to provide investment advisory services.  

对任何证券或数字资产的提及仅用于说明目的，并不构成投资建议或提供投资咨询服务。  

Furthermore, this content is not directed at nor intended for use by any investors or prospective investors, and may not under any circumstances be relied upon when making a decision to invest in any fund managed by a16z.  

此外，这些内容不针对也不打算供任何投资者或潜在投资者使用，在任何情况下，在作出投资于a16z管理的任何基金的决定时，不得依赖这些内容。_

_(An offering to invest in an a16z fund will be made only by the private placement memorandum, subscription agreement, and other relevant documentation of any such fund and should be read in their entirety.) Any investments or portfolio companies mentioned, referred to, or described are not representative of all investments in vehicles managed by a16z, and there can be no assurance that the investments will be profitable or that other investments made in the future will have similar characteristics or results._

_  

(投资于a16z基金的要约将仅由任何此类基金的私募备忘录、认购协议和其他相关文件作出，并应阅读其全部内容)。所提到、提及或描述的任何投资或投资组合公司并不代表A16Z管理的所有投资，而且不能保证这些投资将是有利可图的，也不能保证未来进行的其他投资将有类似的特点或结果。  

A list of investments made by funds managed by Andreessen Horowitz (excluding investments for which the issuer has not provided permission for a16z to disclose publicly as well as unannounced investments in publicly traded digital assets) is available at https://a16z.com/investments/.  

Andreessen Horowitz管理的基金所做的投资清单（不包括发行人未允许a16z公开披露的投资以及对公开交易的数字资产的未宣布的投资），可在https://a16z.com/investments/。_

_Charts and graphs provided within are for informational purposes solely and should not be relied upon when making any investment decision.  

其中提供的图表仅用于提供信息，在做出任何投资决定时不应依赖这些图表。  

Past performance is not indicative of future results. The content speaks only as of the date indicated.  

过去的业绩并不代表未来的结果。该内容仅代表截至所示日期的情况。  

Any projections, estimates, forecasts, targets, prospects, and/or opinions expressed in these materials are subject to change without notice and may differ or be contrary to opinions expressed by others.  

这些材料中表达的任何预测、估计、预报、目标、前景和/或意见都可能发生变化，恕不另行通知，并可能与其他人表达的意见不同或相反。  

Please see https://a16z.com/disclosures for additional important information.  

其他重要信息请见https://a16z.com/disclosures。_
