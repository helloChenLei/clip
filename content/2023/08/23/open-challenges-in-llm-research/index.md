---
title: "LLM ç ”ç©¶çš„å…¬å¼€æŒ‘æˆ˜"
date: 2023-08-23T07:34:40+08:00
updated: 2023-08-23T07:34:40+08:00
taxonomies:
  tags: []
extra:
  source: https://huyenchip.com/2023/08/16/llm-research-open-challenges.html
  hostname: huyenchip.com
  author: Chip Huyen
  original_title: "Open challenges in LLM research"
  original_lang: zh
---

> æœ¬æ–‡ç¿»è¯‘å­˜åœ¨é—®é¢˜ã€‚æ¯”å¦‚ LLM ç¿»è¯‘ä¸ºã€Œæ³•å¾‹ç¡•å£«ã€ï¼Œæ³¨æ„ç”„åˆ«ã€‚ 

Never before in my life had I seen so many smart people working on the same goal: making LLMs better.  

æˆ‘ä¸€ç”Ÿä¸­ä»æœªè§è¿‡å¦‚æ­¤å¤šçš„èªæ˜äººä¸ºåŒä¸€ä¸ªç›®æ ‡è€ŒåŠªåŠ›ï¼šè®©æ³•å¾‹ç¡•å£«å˜å¾—æ›´å¥½ã€‚  

After talking to many people working in both industry and academia, I noticed the 10 major research directions that emerged.  

åœ¨ä¸è®¸å¤šäº§ä¸šç•Œå’Œå­¦æœ¯ç•Œäººå£«äº¤æµåï¼Œæˆ‘æ³¨æ„åˆ°å‡ºç°äº† 10 ä¸ªä¸»è¦ç ”ç©¶æ–¹å‘ã€‚  

The first two directions, hallucinations and context learning, are probably the most talked about today.  

å‰ä¸¤ä¸ªæ–¹å‘ï¼Œå³å¹»è§‰å’Œæƒ…å¢ƒå­¦ä¹ ï¼Œå¯èƒ½æ˜¯å½“ä»Šæœ€çƒ­é—¨çš„è¯é¢˜ã€‚  

Iâ€™m the most excited about numbers 3 (multimodality), 5 (new architecture), and 6 (GPU alternatives).  

æˆ‘æœ€æ„Ÿå…´è¶£çš„æ˜¯ç¬¬ 3 é¡¹ï¼ˆå¤šæ¨¡å¼ï¼‰ã€ç¬¬ 5 é¡¹ï¼ˆæ–°æ¶æ„ï¼‰å’Œç¬¬ 6 é¡¹ï¼ˆGPU æ›¿ä»£æ–¹æ¡ˆï¼‰ã€‚

___

___

## 1\. Reduce and measure hallucinations  

1.å‡å°‘å’Œæµ‹é‡å¹»è§‰

[Hallucination](https://huyenchip.com/2023/05/02/rlhf.html#rlhf_and_hallucination) is a heavily discussed topic already so Iâ€™ll be quick. Hallucination happens when an AI model makes stuff up. For many creative use cases, hallucination is a feature.  

å¹»è§‰æ˜¯ä¸€ä¸ªå·²ç»è¢«å¤§é‡è®¨è®ºè¿‡çš„è¯é¢˜ï¼Œæ‰€ä»¥æˆ‘é•¿è¯çŸ­è¯´ã€‚å½“äººå·¥æ™ºèƒ½æ¨¡å‹èƒ¡ç¼–ä¹±é€ æ—¶ï¼Œå°±ä¼šäº§ç”Ÿå¹»è§‰ã€‚å¯¹äºè®¸å¤šåˆ›æ„ç”¨ä¾‹æ¥è¯´ï¼Œå¹»è§‰æ˜¯ä¸€ç§åŠŸèƒ½ã€‚  

However, for most other use cases, hallucination is a bug.  

ç„¶è€Œï¼Œå¯¹äºå¤§å¤šæ•°å…¶ä»–ä½¿ç”¨æƒ…å†µæ¥è¯´ï¼Œå¹»è§‰æ˜¯ä¸€ä¸ªé”™è¯¯ã€‚  

I was at a panel on LLM with Dropbox, Langchain, Elastics, and Anthropic recently, and the #1 roadblock they see for companies to adopt LLMs in production is hallucination.  

æœ€è¿‘ï¼Œæˆ‘ä¸ Dropboxã€Langchainã€Elastics å’Œ Anthropic ä¸€èµ·å‚åŠ äº†ä¸€ä¸ªå…³äº LLM çš„è®¨è®ºä¼šï¼Œä»–ä»¬è®¤ä¸ºå…¬å¸åœ¨ç”Ÿäº§ä¸­é‡‡ç”¨ LLM çš„ç¬¬ä¸€å¤§éšœç¢æ˜¯å¹»è§‰ã€‚

Mitigating hallucination and developing metrics to measure hallucination is a blossoming research topic, and Iâ€™ve seen many startups focus on this problem.  

å‡è½»å¹»è§‰å’Œåˆ¶å®šè¡¡é‡å¹»è§‰çš„æ ‡å‡†æ˜¯ä¸€ä¸ªè“¬å‹ƒå‘å±•çš„ç ”ç©¶è¯¾é¢˜ï¼Œæˆ‘çœ‹åˆ°è®¸å¤šåˆåˆ›å…¬å¸éƒ½åœ¨å…³æ³¨è¿™ä¸ªé—®é¢˜ã€‚  

There are also ad-hoc tips to reduce hallucination, such as adding more context to the prompt, chain-of-thought, self-consistency, or asking your model to be concise in its response.  

æ­¤å¤–ï¼Œè¿˜æœ‰ä¸€äº›å‡å°‘å¹»è§‰çš„ä¸´æ—¶æç¤ºï¼Œå¦‚åœ¨æç¤ºä¸­æ·»åŠ æ›´å¤šçš„ä¸Šä¸‹æ–‡ã€æ€ç»´é“¾ã€è‡ªæˆ‘ä¸€è‡´æ€§ï¼Œæˆ–è¦æ±‚ä½ çš„æ¨¡å‹åœ¨å›ç­”æ—¶ç®€æ˜æ‰¼è¦ã€‚

To learn more about hallucination:  

äº†è§£æ›´å¤šæœ‰å…³å¹»è§‰çš„ä¿¡æ¯ï¼š

-   [Survey of Hallucination in Natural Language Generation](https://arxiv.org/abs/2202.03629) (Ji et al., 2022)  
    
    è‡ªç„¶è¯­è¨€ç”Ÿæˆä¸­çš„å¹»è§‰è°ƒæŸ¥ï¼ˆJi ç­‰äººï¼Œ2022 å¹´ï¼‰
-   [How Language Model Hallucinations Can Snowball](https://arxiv.org/abs/2305.13534) (Zhang et al., 2023)  
    
    è¯­è¨€æ¨¡å‹å¹»è§‰å¦‚ä½•åƒæ»šé›ªçƒä¸€æ ·è¶Šæ»šè¶Šå¤§ï¼ˆZhang ç­‰äººï¼Œ2023 å¹´ï¼‰
-   [A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity](https://arxiv.org/abs/2302.04023) (Bang et al., 2023)  
    
    å¤šä»»åŠ¡ã€å¤šè¯­è¨€ã€å¤šæ¨¡æ€è¯„ä¼° ChatGPT å¯¹æ¨ç†ã€å¹»è§‰å’Œäº’åŠ¨æ€§çš„å½±å“ï¼ˆBang ç­‰äººï¼Œ2023 å¹´ï¼‰
-   [Contrastive Learning Reduces Hallucination in Conversations](https://arxiv.org/abs/2212.10400) (Sun et al., 2022)  
    
    å¯¹æ¯”å­¦ä¹ å¯å‡å°‘å¯¹è¯ä¸­çš„å¹»è§‰ï¼ˆSun ç­‰äººï¼Œ2022 å¹´ï¼‰
-   [Self-Consistency Improves Chain of Thought Reasoning in Language Models](https://arxiv.org/abs/2203.11171) (Wang et al., 2022)  
    
    è‡ªæˆ‘ä¸€è‡´æ€§æ”¹è¿›äº†è¯­è¨€æ¨¡å‹ä¸­çš„æ€ç»´é“¾æ¨ç†ï¼ˆWang ç­‰äººï¼Œ2022å¹´ï¼‰
-   [SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models](https://arxiv.org/abs/2303.08896) (Manakul et al., 2023)  
    
    SelfCheckGPTï¼šç”¨äºç”Ÿæˆå¼å¤§å‹è¯­è¨€æ¨¡å‹çš„é›¶èµ„æºé»‘ç›’å¹»è§‰æ£€æµ‹ï¼ˆManakul ç­‰äººï¼Œ2023 å¹´ï¼‰
-   A simple example of fact-checking and hallucination by [NVIDIAâ€™s NeMo-Guardrails](https://github.com/NVIDIA/NeMo-Guardrails/blob/main/examples/grounding_rail/README.md#grounding-fact-checking-and-hallucination)  
    
    è‹±ä¼Ÿè¾¾â„¢ï¼ˆNVIDIAÂ®ï¼‰NeMo-Guardrails éªŒè¯äº‹å®å’Œäº§ç”Ÿå¹»è§‰çš„ä¸€ä¸ªç®€å•ä¾‹å­

## 2\. Optimize context length and context construction  

2.ä¼˜åŒ–ä¸Šä¸‹æ–‡é•¿åº¦å’Œä¸Šä¸‹æ–‡ç»“æ„

A vast majority of questions require context.  

ç»å¤§å¤šæ•°é—®é¢˜éƒ½éœ€è¦è”ç³»ä¸Šä¸‹æ–‡ã€‚  

For example, if we ask ChatGPT: â€œWhatâ€™s the best Vietnamese restaurant?â€, the context needed would be â€œwhereâ€ because the best Vietnamese restaurant in Vietnam would be different from the best Vietnamese in the US.  

ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬é—® ChatGPTï¼š"æœ€å¥½çš„è¶Šå—é¤é¦†æ˜¯å“ªå®¶ï¼Ÿ"ï¼Œæ‰€éœ€çš„è¯­å¢ƒæ˜¯ "å“ªé‡Œ"ï¼Œå› ä¸ºè¶Šå—æœ€å¥½çš„è¶Šå—é¤é¦†å’Œç¾å›½æœ€å¥½çš„è¶Šå—é¤é¦†æ˜¯ä¸åŒçš„ã€‚

According to this cool paper [SituatedQA](https://arxiv.org/pdf/2109.06157.pdf) (Zhang & Choi, 2021), a significant proportion of information-seeking questions have context-dependent answers, e.g. roughly 16.5% of the [Natural Questions NQ-Open dataset](https://ai.google.com/research/NaturalQuestions). Personally, I suspect that this percentage would be even higher for enterprise use cases.  

æ ¹æ®è¿™ç¯‡å¾ˆé…·çš„è®ºæ–‡ SituatedQAï¼ˆZhang & Choiï¼Œ2021 å¹´ï¼‰ï¼Œå¾ˆå¤§ä¸€éƒ¨åˆ†ä¿¡æ¯æœç´¢é—®é¢˜çš„ç­”æ¡ˆéƒ½ä¸ä¸Šä¸‹æ–‡æœ‰å…³ï¼Œä¾‹å¦‚ï¼Œåœ¨è‡ªç„¶é—®é¢˜ NQ-Open æ•°æ®é›†ä¸­çº¦å  16.5%ã€‚æˆ‘ä¸ªäººè®¤ä¸ºï¼Œåœ¨ä¼ä¸šç”¨ä¾‹ä¸­ï¼Œè¿™ä¸€æ¯”ä¾‹ä¼šæ›´é«˜ã€‚  

For example, say a company builds a chatbot for customer support, for this chatbot to answer any customer question about any product, the context needed might be that customerâ€™s history or that productâ€™s information.  

ä¾‹å¦‚ï¼Œå¦‚æœä¸€å®¶å…¬å¸ä¸ºå®¢æˆ·æ”¯æŒå»ºç«‹äº†ä¸€ä¸ªèŠå¤©æœºå™¨äººï¼Œè¦è®©è¿™ä¸ªèŠå¤©æœºå™¨äººå›ç­”å®¢æˆ·å…³äºä»»ä½•äº§å“çš„ä»»ä½•é—®é¢˜ï¼Œæ‰€éœ€çš„ä¸Šä¸‹æ–‡å¯èƒ½æ˜¯è¯¥å®¢æˆ·çš„å†å²æˆ–è¯¥äº§å“çš„ä¿¡æ¯ã€‚

Because the model â€œlearnsâ€ from the context provided to it, this process is also called context learning.  

ç”±äºæ¨¡å‹æ˜¯ä»æä¾›ç»™å®ƒçš„ä¸Šä¸‹æ–‡ä¸­ "å­¦ä¹  "çš„ï¼Œå› æ­¤è¿™ä¸€è¿‡ç¨‹ä¹Ÿè¢«ç§°ä¸ºä¸Šä¸‹æ–‡å­¦ä¹ ã€‚

![Context needed for a customer support query](2-context.png)

Context length is especially important for RAG â€“ [Retrieval Augmented Generation](https://arxiv.org/abs/2005.11401) (Lewis et al., 2020) â€“ which has emerged to be the predominant pattern for LLM industry use cases. For those not yet swept away in the RAG rage, RAG works in two phases:  

è¯­å¢ƒé•¿åº¦å¯¹äº RAGï¼ˆRetrieval Augmented Generationï¼‰ï¼ˆåˆ˜æ˜“æ–¯ç­‰äººï¼Œ2020 å¹´ï¼‰å°¤ä¸ºé‡è¦ï¼ŒRAG å·²æˆä¸º LLM è¡Œä¸šç”¨ä¾‹çš„ä¸»è¦æ¨¡å¼ã€‚å¯¹äºé‚£äº›å°šæœªè¢« RAG ç‹‚æ½®å¸­å·çš„äººæ¥è¯´ï¼ŒRAG çš„å·¥ä½œåˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼š

Phase 1: chunking (also known as indexing)  

ç¬¬ 1 é˜¶æ®µï¼šåˆ†å—ï¼ˆåˆç§°ç´¢å¼•ç¼–åˆ¶ï¼‰

1.  Gather all the documents you want your LLM to use  
    
    æ”¶é›†æ‚¨å¸Œæœ›æ³•å¾‹ç¡•å£«ä½¿ç”¨çš„æ‰€æœ‰æ–‡ä»¶
2.  Divide these documents into chunks that can be fed into your LLM to generate embeddings and store these embeddings in a vector database.  
    
    å°†è¿™äº›æ–‡æ¡£åˆ†æˆè‹¥å¹²å—ï¼Œç„¶åè¾“å…¥ LLM ç”ŸæˆåµŒå…¥å¼ï¼Œå¹¶å°†è¿™äº›åµŒå…¥å¼å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“ä¸­ã€‚

Phase 2: queryingÂ ç¬¬ 2 é˜¶æ®µï¼šæŸ¥è¯¢

1.  When user sends a query, like â€œ_Does my insurance policy pay for this drug X_â€, your LLM converts this query into an embedding, letâ€™s call it QUERY\_EMBEDDING  
    
    å½“ç”¨æˆ·å‘é€æŸ¥è¯¢ï¼Œå¦‚ "æˆ‘çš„ä¿é™©å•æ˜¯å¦æ”¯ä»˜è¿™ç§è¯ç‰© X "æ—¶ï¼Œæ‚¨çš„ LLM ä¼šå°†æ­¤æŸ¥è¯¢è½¬æ¢ä¸ºåµŒå…¥ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸º QUERY\_EMBEDDING
2.  Your vector database fetches the chunks whose embeddings are the most similar to QUERY\_EMBEDDING  
    
    æ‚¨çš„çŸ¢é‡æ•°æ®åº“ä¼šè·å–åµŒå…¥ä¸ QUERY\_EMBEDDING æœ€ä¸ºç›¸ä¼¼çš„æ•°æ®å—ã€‚

Screenshot from [Jerry Liuâ€™s talk on LlamaIndex](https://www.youtube.com/watch?v=njzB6fm0U8g) (2023)  

Jerry Liu å…³äº LlamaIndex çš„æ¼”è®²æˆªå›¾ï¼ˆ2023 å¹´ï¼‰

![Context needed for a customer support query](2-rag.jpg)

The longer the context length, the more chunks we can squeeze into the context. The more information the model has access to, the better its response will be, right?  

ä¸Šä¸‹æ–‡é•¿åº¦è¶Šé•¿ï¼Œæˆ‘ä»¬å°±èƒ½åœ¨ä¸Šä¸‹æ–‡ä¸­æŒ¤å‡ºè¶Šå¤šçš„ä¿¡æ¯å—ã€‚æ¨¡å‹è·å–çš„ä¿¡æ¯è¶Šå¤šï¼Œå®ƒçš„å“åº”å°±è¶Šå¥½ï¼Œä¸æ˜¯å—ï¼Ÿ

Not always. How much context a model can use and how efficiently that model will use it are two different questions.  

å¹¶éæ€»æ˜¯å¦‚æ­¤ã€‚ä¸€ä¸ªæ¨¡å‹å¯ä»¥ä½¿ç”¨å¤šå°‘ä¸Šä¸‹æ–‡ï¼Œä»¥åŠè¯¥æ¨¡å‹ä½¿ç”¨ä¸Šä¸‹æ–‡çš„æ•ˆç‡å¦‚ä½•ï¼Œè¿™æ˜¯ä¸¤ä¸ªä¸åŒçš„é—®é¢˜ã€‚  

In parallel with the effort to increase model context length is the effort to make the context more efficient. Some people call it â€œprompt engineeringâ€ or â€œprompt constructionâ€.  

åœ¨åŠªåŠ›å¢åŠ æ¨¡å‹ä¸Šä¸‹æ–‡é•¿åº¦çš„åŒæ—¶ï¼Œæˆ‘ä»¬ä¹Ÿåœ¨åŠªåŠ›æé«˜ä¸Šä¸‹æ–‡çš„æ•ˆç‡ã€‚æœ‰äººç§°ä¹‹ä¸º "å¿«é€Ÿå·¥ç¨‹ "æˆ– "å¿«é€Ÿæ„å»º"ã€‚  

For example, a paper that has made the rounds recently is about how models are much better at understanding information at the beginning and the end of the index rather than in the middle of it â€“ [Lost in the Middle: How Language Models Use Long Contexts](https://arxiv.org/abs/2307.03172) (Liu et al., 2023).  

ä¾‹å¦‚ï¼Œæœ€è¿‘æœ‰ä¸€ç¯‡è®ºæ–‡è°ˆåˆ°äº†æ¨¡å‹å¦‚ä½•æ›´å¥½åœ°ç†è§£ç´¢å¼•å¼€å¤´å’Œç»“å°¾çš„ä¿¡æ¯ï¼Œè€Œä¸æ˜¯ä¸­é—´çš„ä¿¡æ¯--ã€Šè¿·å¤±åœ¨ä¸­é—´ï¼šè¯­è¨€æ¨¡å‹å¦‚ä½•ä½¿ç”¨é•¿è¯­å¢ƒã€‹ï¼ˆLiu et al.ï¼‰

## 3\. Incorporate other data modalities  

3.çº³å…¥å…¶ä»–æ•°æ®æ¨¡å¼

Multimodality, IMO, is so powerful and yet so underrated. There are many reasons for multimodality.  

åœ¨æˆ‘çœ‹æ¥ï¼Œå¤šæ¨¡æ€æ˜¯å¦‚æ­¤å¼ºå¤§ï¼Œå´åˆå¦‚æ­¤è¢«ä½ä¼°ã€‚é‡‡ç”¨å¤šæ¨¡å¼æœ‰å¾ˆå¤šåŸå› ã€‚

First, there are many use cases where multimodal data is required, especially in industries that deal with a mixture of data modalities such as healthcare, robotics, e-commerce, retail, gaming, entertainment, etc.  

é¦–å…ˆï¼Œè®¸å¤šä½¿ç”¨æ¡ˆä¾‹éƒ½éœ€è¦å¤šæ¨¡æ€æ•°æ®ï¼Œå°¤å…¶æ˜¯åœ¨åŒ»ç–—ä¿å¥ã€æœºå™¨äººã€ç”µå­å•†åŠ¡ã€é›¶å”®ã€æ¸¸æˆã€å¨±ä¹ç­‰æ··åˆæ•°æ®æ¨¡æ€çš„è¡Œä¸šã€‚  

Examples:Â ä¾‹å¦‚

-   Oftentimes, medical predictions require both text (e.g. doctorâ€™s notes, patientsâ€™ questionnaires) and images (e.g. CT, X-ray, MRI scans).  
    
    é€šå¸¸ï¼ŒåŒ»å­¦é¢„æµ‹éœ€è¦æ–‡æœ¬ï¼ˆå¦‚åŒ»ç”Ÿç¬”è®°ã€æ‚£è€…é—®å·ï¼‰å’Œå›¾åƒï¼ˆå¦‚ CTã€X å…‰ã€æ ¸ç£å…±æŒ¯æˆåƒæ‰«æï¼‰ã€‚
-   Product metadata often contains images, videos, descriptions, and even tabular data (e.g. production date, weight, color).  
    
    äº§å“å…ƒæ•°æ®é€šå¸¸åŒ…å«å›¾ç‰‡ã€è§†é¢‘ã€æè¿°ï¼Œç”šè‡³è¡¨æ ¼æ•°æ®ï¼ˆå¦‚ç”Ÿäº§æ—¥æœŸã€é‡é‡ã€é¢œè‰²ï¼‰ã€‚  
    
    You might want to automatically fill in missing product information based on usersâ€™ reviews or product photos.  
    
    æ‚¨å¯èƒ½å¸Œæœ›æ ¹æ®ç”¨æˆ·çš„è¯„è®ºæˆ–äº§å“ç…§ç‰‡è‡ªåŠ¨å¡«å†™ç¼ºå¤±çš„äº§å“ä¿¡æ¯ã€‚  
    
    You might want to enable users to search for products using visual information, like shape or color.  
    
    æ‚¨å¯èƒ½å¸Œæœ›è®©ç”¨æˆ·èƒ½å¤Ÿä½¿ç”¨è§†è§‰ä¿¡æ¯ï¼ˆå¦‚å½¢çŠ¶æˆ–é¢œè‰²ï¼‰æœç´¢äº§å“ã€‚

Second, multimodality promises a big boost in model performance.  

å…¶æ¬¡ï¼Œå¤šæ¨¡æ€æŠ€æœ¯æœ‰æœ›å¤§å¹…æå‡æ¨¡å‹æ€§èƒ½ã€‚  

Shouldnâ€™t a model that can understand both text and images perform better than a model that can only understand text?  

ä¸€ä¸ªæ—¢èƒ½ç†è§£æ–‡å­—åˆèƒ½ç†è§£å›¾åƒçš„æ¨¡å‹ï¼Œéš¾é“ä¸åº”è¯¥æ¯”ä¸€ä¸ªåªèƒ½ç†è§£æ–‡å­—çš„æ¨¡å‹è¡¨ç°æ›´å¥½å—ï¼Ÿ  

Text-based models require so much text that thereâ€™s a realistic concern that [weâ€™ll soon run out of Internet data to train text-based models](https://huyenchip.com/2023/05/02/rlhf.html#data_bottleneck_for_pretraining). Once we run out of text, weâ€™d need to leverage other data modalities.  

åŸºäºæ–‡æœ¬çš„æ¨¡å‹éœ€è¦å¤§é‡æ–‡æœ¬ï¼Œä»¥è‡³äºæˆ‘ä»¬æ‹…å¿ƒå¾ˆå¿«å°±ä¼šç”¨å®Œäº’è”ç½‘æ•°æ®æ¥è®­ç»ƒåŸºäºæ–‡æœ¬çš„æ¨¡å‹ã€‚ä¸€æ—¦æ–‡æœ¬è€—å°½ï¼Œæˆ‘ä»¬å°±éœ€è¦åˆ©ç”¨å…¶ä»–æ•°æ®æ¨¡å¼ã€‚

![Multimodal Flamingo's architecture](3-flamingo.png)

Flamingo architecture (Alayrac et al., 2022)  

ç«çƒˆé¸Ÿå»ºç­‘ï¼ˆAlayrac ç­‰äººï¼Œ2022 å¹´ï¼‰

One use case Iâ€™m especially excited about is that multimodality can enable visually impaired people to browse the Internet and navigate the real world.  

ä»¤æˆ‘ç‰¹åˆ«å…´å¥‹çš„æ˜¯ï¼Œå¤šæ¨¡æ€æŠ€æœ¯å¯ä»¥å¸®åŠ©è§†éšœäººå£«æµè§ˆäº’è”ç½‘å’Œæµè§ˆç°å®ä¸–ç•Œã€‚

Cool multimodal work:Â å¾ˆé…·çš„å¤šæ¨¡å¼ä½œå“

-   [\[CLIP\] Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/abs/2103.00020) (OpenAI, 2021)  
    
    \[CLIP\] ä»è‡ªç„¶è¯­è¨€ç›‘ç£ä¸­å­¦ä¹ å¯è½¬ç§»çš„è§†è§‰æ¨¡å‹ï¼ˆOpenAIï¼Œ2021 å¹´ï¼‰
-   [Flamingo: a Visual Language Model for Few-Shot Learning](https://arxiv.org/abs/2204.14198) (DeepMind, 2022)  
    
    ç«çƒˆé¸Ÿï¼šç”¨äºå¿«é€Ÿå­¦ä¹ çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆDeepMindï¼Œ2022 å¹´ï¼‰
-   [BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models](https://arxiv.org/abs/2301.12597) (Salesforce, 2023)  
    
    BLIP-2ï¼šä½¿ç”¨å†»ç»“å›¾åƒç¼–ç å™¨å’Œå¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œè¯­è¨€å›¾åƒé¢„è®­ç»ƒå¼•å¯¼ï¼ˆSalesforceï¼Œ2023 å¹´ï¼‰
-   [KOSMOS-1: Language Is Not All You Need: Aligning Perception with Language Models](https://arxiv.org/abs/2302.14045) (Microsoft, 2023)  
    
    KOSMOS-1ï¼šè¯­è¨€å¹¶éä½ æ‰€éœ€è¦çš„å…¨éƒ¨ï¼šå°†æ„ŸçŸ¥ä¸è¯­è¨€æ¨¡å‹ç›¸ç»“åˆï¼ˆå¾®è½¯ï¼Œ2023 å¹´ï¼‰
-   [PaLM-E: An embodied multimodal language model](https://ai.googleblog.com/2023/03/palm-e-embodied-multimodal-language.html) (Google, 2023)  
    
    PaLM-Eï¼šå…·èº«å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ï¼ˆè°·æ­Œï¼Œ2023 å¹´ï¼‰
-   [LLaVA: Visual Instruction Tuning](https://arxiv.org/abs/2304.08485) (Liu et al., 2023)  
    
    LLaVAï¼šè§†è§‰æŒ‡ä»¤è°ƒæ•´ï¼ˆLiu ç­‰äººï¼Œ2023 å¹´ï¼‰
-   [NeVA: NeMo Vision and Language Assistant](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/playground/models/neva) (NVIDIA, 2023)  
    
    NeVAï¼šNeMo è§†è§‰å’Œè¯­è¨€åŠ©æ‰‹ï¼ˆè‹±ä¼Ÿè¾¾ï¼Œ2023 å¹´ï¼‰

Iâ€™ve been working on a post on multimodality that hopefully I can share soon!  

æˆ‘ä¸€ç›´åœ¨å†™ä¸€ç¯‡å…³äºå¤šæ¨¡æ€çš„æ–‡ç« ï¼Œå¸Œæœ›èƒ½å°½å¿«ä¸å¤§å®¶åˆ†äº«ï¼

## 4\. Make LLMs faster and cheaper  

4.è®©æ³•å¾‹ç¡•å£«æ›´å¿«ã€æ›´ä¾¿å®œ

When GPT-3.5 first came out in late November 2022, many people had concerns about latency and cost of using it in production.  

å½“ GPT-3.5 äº 2022 å¹´ 11 æœˆåº•é¦–æ¬¡å‘å¸ƒæ—¶ï¼Œå¾ˆå¤šäººéƒ½å¯¹åœ¨ç”Ÿäº§ä¸­ä½¿ç”¨å®ƒçš„å»¶è¿Ÿå’Œæˆæœ¬è¡¨ç¤ºæ‹…å¿§ã€‚  

However, latency/cost analysis has changed rapidly since then.  

ç„¶è€Œï¼Œä»é‚£æ—¶èµ·ï¼Œå»¶è¿Ÿ/æˆæœ¬åˆ†æå·²ç»å‘ç”Ÿäº†è¿…é€Ÿå˜åŒ–ã€‚  

Within half a year, the community found a way to create a model that came pretty close to GPT-3.5 in terms of performance, yet required just under 2% of GPT-3.5â€™s memory footprint.  

ä¸åˆ°åŠå¹´æ—¶é—´ï¼Œç¤¾åŒºå°±æ‰¾åˆ°äº†ä¸€ç§æ–¹æ³•ï¼Œåˆ›å»ºäº†ä¸€ç§åœ¨æ€§èƒ½ä¸Šéå¸¸æ¥è¿‘ GPT-3.5 çš„æ¨¡å‹ï¼Œä½†æ‰€éœ€å†…å­˜å ç”¨ä»…ä¸º GPT-3.5 çš„ 2%ã€‚

My takeaway: if you create something good enough, people will figure out a way to make it fast and cheap.  

æˆ‘çš„å¯ç¤ºæ˜¯ï¼šå¦‚æœä½ åˆ›é€ çš„ä¸œè¥¿è¶³å¤Ÿå¥½ï¼Œäººä»¬å°±ä¼šæƒ³å‡ºåŠæ³•æ¥å¿«é€Ÿã€å»‰ä»·åœ°åˆ¶é€ å®ƒã€‚

<table data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75"><tbody data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75"><tr data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75"><td data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75"><strong data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75">Date<span lang="zh-CN" data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">æ—¥æœŸ</span></span></span></strong></td><td data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75"><strong data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75">Model<span lang="zh-CN" data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">æ¨¡å‹</span></span></span></strong></td><td data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75"><strong data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75"># params<span lang="zh-CN" data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1"># å‚æ•°</span></span></span></strong></td><td data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75"><strong data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75">Quantization<span lang="zh-CN" data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">é‡åŒ–</span></span></span></strong></td><td data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75"><strong data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75">Memory to finetune<span lang="zh-CN" data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">å†…å­˜å¾®è°ƒ</span></span></span></strong></td><td data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75"><strong data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75">Can be trained on<span lang="zh-CN" data-immersive-translate-translation-element-mark="1"><br><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">å¯åœ¨ä»¥ä¸‹æ–¹é¢è¿›è¡ŒåŸ¹è®­</span></span></span></strong></td></tr><tr data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75"><td data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75">Nov 2022 <span lang="zh-CN" data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">2022 å¹´ 11 æœˆ</span></span></span></td><td data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75">GPT-3.5</td><td data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75">175B</td><td data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75">16-bit <span lang="zh-CN" data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">16 ä½</span></span></span></td><td data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75">375GB</td><td data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75">Many, many machines <span lang="zh-CN" data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">è®¸è®¸å¤šå¤šçš„æœºå™¨</span></span></span></td></tr><tr data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75"><td data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75">Mar 2023 <span lang="zh-CN" data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">2023 å¹´ 3 æœˆ</span></span></span></td><td data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75"><a href="https://crfm.stanford.edu/2023/03/13/alpaca.html" data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75">Alpaca 7B<span lang="zh-CN" data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">ç¾Šé©¼ 7B</span></span></span></a></td><td data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75">7B</td><td data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75">16-bit <span lang="zh-CN" data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">16 ä½</span></span></span></td><td data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75">15GB</td><td data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75">Gaming desktop <span lang="zh-CN" data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">æ¸¸æˆå°å¼æœº</span></span></span></td></tr><tr data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75"><td data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75">May 2023 <span lang="zh-CN" data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">2023 å¹´ 5 æœˆ</span></span></span></td><td data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75"><a href="https://arxiv.org/abs/2305.14314" data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75">Guanaco 7B<span lang="zh-CN" data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">Guanaco 7B</span></span></span></a></td><td data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75">7B</td><td data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75">4-bit <span lang="zh-CN" data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">4 ä½</span></span></span></td><td data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75">6GB</td><td data-immersive-translate-effect="1" data-immersive_translate_walked="1aad5c6d-c570-4676-a11e-2c443bef0a75">Any Macbook <span lang="zh-CN" data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">&nbsp;</span><span data-immersive-translate-translation-element-mark="1"><span data-immersive-translate-translation-element-mark="1">ä»»ä½• Macbook</span></span></span></td></tr></tbody></table>

Below is Guanaco 7Bâ€™s performance compared to ChatGPT GPT-3.5 and GPT-4, as reported in the Guanco paper. Caveat: in general, the performance comparison is far from perfect.  

ä»¥ä¸‹æ˜¯ Guanaco 7B çš„æ€§èƒ½ä¸ ChatGPT GPT-3.5 å’Œ GPT-4 çš„æ¯”è¾ƒï¼Œå¦‚ Guanco è®ºæ–‡ä¸­æ‰€è¿°ã€‚æ³¨æ„ï¼šæ€»çš„æ¥è¯´ï¼Œæ€§èƒ½æ¯”è¾ƒè¿œéå®Œç¾ã€‚  

LLM evaluation is very, very hard.  

æ³•å¾‹ç¡•å£«è¯„ä¼°éå¸¸éå¸¸å›°éš¾ã€‚

![Guanaco 7B's performance compared to ChatGPT GPT-3.5 and GPT-4](4-llm-optimization.png)

Four years ago, when I started working on the notes that would later become the section **[Model Compression](https://learning.oreilly.com/library/view/designing-machine-learning/9781098107956/ch07.html#model_compression)** for the book [**Designing Machine Learning Systems**](https://www.amazon.com/Designing-Machine-Learning-Systems-Production-Ready/dp/1098107969), I wrote about four major techniques for model optimization/compression:  

å››å¹´å‰ï¼Œå½“æˆ‘å¼€å§‹ä¸ºã€Šè®¾è®¡æœºå™¨å­¦ä¹ ç³»ç»Ÿã€‹ä¸€ä¹¦æ’°å†™åæ¥æˆä¸º "æ¨¡å‹å‹ç¼© "éƒ¨åˆ†çš„ç¬”è®°æ—¶ï¼Œæˆ‘å†™ä¸‹äº†å››ç§ä¸»è¦çš„æ¨¡å‹ä¼˜åŒ–/å‹ç¼©æŠ€æœ¯ï¼š

1.  **Quantization**: by far the most general model optimization method. Quantization reduces a modelâ€™s size by using fewer bits to represent its parameters, e.g.  
    
    é‡åŒ–ï¼šè¿„ä»Šä¸ºæ­¢æœ€é€šç”¨çš„æ¨¡å‹ä¼˜åŒ–æ–¹æ³•ã€‚é‡åŒ–é€šè¿‡ä½¿ç”¨è¾ƒå°‘çš„æ¯”ç‰¹æ¥è¡¨ç¤ºæ¨¡å‹çš„å‚æ•°ï¼Œä»è€Œå‡å°æ¨¡å‹çš„å¤§å°ï¼Œä¾‹å¦‚  
    
    instead of using 32 bits to represent a float, use only 16 bits, or even 4 bits.  
    
    ä¸å…¶ç”¨ 32 ä½æ¥è¡¨ç¤ºæµ®ç‚¹æ•°ï¼Œä¸å¦‚åªç”¨ 16 ä½ï¼Œç”šè‡³ 4 ä½ã€‚
2.  **Knowledge distillation**: a method in which a small model (student) is trained to mimic a larger model or ensemble of models (teacher).  
    
    çŸ¥è¯†æç‚¼ï¼šä¸€ç§è®­ç»ƒå°æ¨¡å‹ï¼ˆå­¦ç”Ÿï¼‰æ¨¡ä»¿å¤§æ¨¡å‹æˆ–æ¨¡å‹ç»„åˆï¼ˆæ•™å¸ˆï¼‰çš„æ–¹æ³•ã€‚
3.  **Low-rank factorization**: the key idea here is to replace high-dimensional tensors with lower-dimensional tensors to reduce the number of parameters.  
    
    ä½é˜¶å› å¼åˆ†è§£ï¼šè¿™é‡Œçš„å…³é”®æ€è·¯æ˜¯ç”¨ä½ç»´å¼ é‡ä»£æ›¿é«˜ç»´å¼ é‡ï¼Œä»¥å‡å°‘å‚æ•°æ•°é‡ã€‚  
    
    For example, you can decompose a 3x3 tensor into the product of a 3x1 and a 1x3 tensor, so that instead of having 9 parameters, you have only 6 parameters.  
    
    ä¾‹å¦‚ï¼Œå¯ä»¥å°† 3x3 å¼ é‡åˆ†è§£ä¸º 3x1 å’Œ 1x3 å¼ é‡çš„ä¹˜ç§¯ï¼Œè¿™æ ·å°±ä¸å†éœ€è¦ 9 ä¸ªå‚æ•°ï¼Œè€Œåªéœ€è¦ 6 ä¸ªå‚æ•°ã€‚
4.  **PruningÂ ä¿®å‰ª**

All these four techniques are still relevant and popular today. Alpaca was trained using knowledge distillation.  

æ‰€æœ‰è¿™å››ç§æŠ€æœ¯åœ¨ä»Šå¤©ä»ç„¶é€‚ç”¨å’Œæµè¡Œã€‚ç¾Šé©¼æ˜¯ç”¨çŸ¥è¯†æç‚¼æ³•è®­ç»ƒå‡ºæ¥çš„ã€‚  

QLoRA used a combination of low-rank factorization and quantization.  

QLoRA ç»“åˆä½¿ç”¨äº†ä½é˜¶å› å¼åˆ†è§£å’Œé‡åŒ–æŠ€æœ¯ã€‚

## 5\. Design a new model architecture  

5.è®¾è®¡æ–°çš„æ¨¡å‹æ¶æ„

Since AlexNet in 2012, weâ€™ve seen many architectures go in and out of fashion, including LSTM, seq2seq. Compared to those, Transformer is incredibly sticky.  

è‡ª 2012 å¹´çš„ AlexNet ä»¥æ¥ï¼Œæˆ‘ä»¬ç›®ç¹äº†è®¸å¤šæ¶æ„çš„å…´è¡°ï¼ŒåŒ…æ‹¬ LSTMã€seq2seq ç­‰ã€‚ä¸ä¹‹ç›¸æ¯”ï¼ŒTransformer çš„ç²˜æ€§ä»¤äººéš¾ä»¥ç½®ä¿¡ã€‚  

Itâ€™s been around since 2017. Itâ€™s a big question mark how much longer this architecture will be in vogue.  

å®ƒä» 2017 å¹´å°±å¼€å§‹æµè¡Œäº†ã€‚è¿™ç§å»ºç­‘è¿˜èƒ½æµè¡Œå¤šä¹…ï¼Œè¿˜æ˜¯ä¸ªå¤§é—®å·ã€‚

Developing a new architecture to outperform Transformer isnâ€™t easy. Transformer has been so heavily optimized over the last 6 years.  

å¼€å‘ä¸€ç§æ–°çš„æ¶æ„æ¥è¶…è¶Š Transformer å¹¶ä¸å®¹æ˜“ã€‚åœ¨è¿‡å»çš„ 6 å¹´ä¸­ï¼ŒTransformer å·²ç»è¿›è¡Œäº†å¤§é‡ä¼˜åŒ–ã€‚  

This new architecture has to be performing at the scale that people care about today, on the hardware that people care about. Side note: [Transformer was originally designed by Google to run fast on TPUs](https://timdettmers.com/2018/10/17/tpus-vs-gpus-for-transformers-bert/), and only later optimized on GPUs.  

è¿™ç§æ–°æ¶æ„å¿…é¡»åœ¨äººä»¬å…³å¿ƒçš„ç¡¬ä»¶ä¸Šä»¥äººä»¬ç›®å‰å…³å¿ƒçš„è§„æ¨¡è¿è¡Œã€‚é¢˜å¤–è¯ï¼šTransformer æœ€åˆæ˜¯è°·æ­Œä¸ºåœ¨ TPU ä¸Šå¿«é€Ÿè¿è¡Œè€Œè®¾è®¡çš„ï¼Œåæ¥æ‰åœ¨ GPU ä¸Šè¿›è¡Œäº†ä¼˜åŒ–ã€‚

There was a lot of excitement in 2021 around S4 from Chris RÃ©â€™s lab â€“ see [Efficiently Modeling Long Sequences with Structured State Spaces](https://arxiv.org/abs/2111.00396) (Gu et al., 2021). Iâ€™m not quite sure what happened to it. Chris RÃ©â€™s lab is still very invested in developing new architecture, most recently with their architecture [Monarch Mixer](https://together.ai/blog/monarch-mixer) (Fu et al., 2023) in collaboration with the startup [Together](https://together.ai/blog/monarch-mixer).  

2021å¹´ï¼Œå…‹é‡Œæ–¯-é›·ï¼ˆChris RÃ©ï¼‰å®éªŒå®¤çš„S4ç ”ç©¶æ›¾å¼•èµ·äº†å¾ˆå¤§çš„è½°åŠ¨--è§ã€Šåˆ©ç”¨ç»“æ„åŒ–çŠ¶æ€ç©ºé—´é«˜æ•ˆå»ºæ¨¡é•¿åºåˆ—ã€‹ï¼ˆGuç­‰äººï¼Œ2021å¹´ï¼‰ã€‚æˆ‘ä¸å¤ªæ¸…æ¥šåæ¥å‘ç”Ÿäº†ä»€ä¹ˆã€‚å…‹é‡Œæ–¯-é›·çš„å®éªŒå®¤ä»ç„¶è‡´åŠ›äºå¼€å‘æ–°çš„æ¶æ„ï¼Œæœ€è¿‘ä¸åˆåˆ›å…¬å¸ Together åˆä½œå¼€å‘çš„æ¶æ„ Monarch Mixerï¼ˆFu ç­‰äººï¼Œ2023 å¹´ï¼‰å°±æ˜¯å…¶ä¸­ä¹‹ä¸€ã€‚

Their key idea is that for the existing Transformer architecture, the complexity of attention is quadratic in sequence length and the complexity of an MLP is quadratic in model dimension.  

ä»–ä»¬çš„ä¸»è¦æƒ³æ³•æ˜¯ï¼Œå¯¹äºç°æœ‰çš„ Transformer æ¶æ„ï¼Œæ³¨æ„åŠ›çš„å¤æ‚åº¦æ˜¯åºåˆ—é•¿åº¦çš„äºŒæ¬¡æ–¹ï¼Œè€Œ MLP çš„å¤æ‚åº¦æ˜¯æ¨¡å‹ç»´åº¦çš„äºŒæ¬¡æ–¹ã€‚  

An architecture with subquadratic complexity would be more efficient.  

å…·æœ‰äºšäºŒæ¬¡æ–¹å¤æ‚æ€§çš„æ¶æ„å°†æ›´åŠ é«˜æ•ˆã€‚

![Monarch Mixer architecture](5-monarch-mixer.png)

Iâ€™m sure many other labs are working on this idea, though Iâ€™m not aware of any attempt that has been made public. If you know of any, please let me know!  

æˆ‘ç›¸ä¿¡è®¸å¤šå…¶ä»–å®éªŒå®¤ä¹Ÿåœ¨ç ”ç©¶è¿™ä¸ªæƒ³æ³•ï¼Œä¸è¿‡æˆ‘è¿˜ä¸çŸ¥é“æœ‰ä»»ä½•å…¬å¼€çš„å°è¯•ã€‚å¦‚æœä½ çŸ¥é“ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼

## 6\. Develop GPU alternatives  

6.å¼€å‘ GPU æ›¿ä»£æ–¹æ¡ˆ

GPU has been the dominating hardware for deep learning ever since AlexNet in 2012. In fact, one commonly acknowledged reason for AlexNetâ€™s popularity is that it was the first paper to successfully use GPUs to train neural networks.  

è‡ª 2012 å¹´çš„ AlexNet ä»¥æ¥ï¼ŒGPU ä¸€ç›´æ˜¯æ·±åº¦å­¦ä¹ çš„ä¸»æµç¡¬ä»¶ã€‚äº‹å®ä¸Šï¼ŒAlexNet å¹¿å—æ¬¢è¿çš„ä¸€ä¸ªå…¬è®¤åŸå› æ˜¯ï¼Œå®ƒæ˜¯ç¬¬ä¸€ç¯‡æˆåŠŸä½¿ç”¨ GPU è®­ç»ƒç¥ç»ç½‘ç»œçš„è®ºæ–‡ã€‚  

Before GPUs, if you wanted to train a model at AlexNetâ€™s scale, youâ€™d have to use thousands of CPUs, like the one [Google released just a few months before AlexNet](https://www.nytimes.com/2012/06/26/technology/in-a-big-network-of-computers-evidence-of-machine-learning.html). Compared to thousands of CPUs, a couple of GPUs were a lot more accessible to Ph.D. students and researchers, setting off the deep learning research boom.  

åœ¨ä½¿ç”¨ GPU ä¹‹å‰ï¼Œå¦‚æœè¦è®­ç»ƒä¸€ä¸ªä¸ AlexNet è§„æ¨¡ç›¸å½“çš„æ¨¡å‹ï¼Œå°±å¿…é¡»ä½¿ç”¨æˆåƒä¸Šä¸‡çš„ CPUï¼Œæ¯”å¦‚è°·æ­Œåœ¨ AlexNet å‘å¸ƒå‰å‡ ä¸ªæœˆåˆšåˆšå‘å¸ƒçš„ CPUã€‚ä¸æ•°ä»¥åƒè®¡çš„ CPU ç›¸æ¯”ï¼Œå‡ ä¸ª GPU å¯¹åšå£«ç”Ÿå’Œç ”ç©¶äººå‘˜æ¥è¯´æ›´å®¹æ˜“è·å¾—ï¼Œä»è€Œæ€èµ·äº†æ·±åº¦å­¦ä¹ ç ”ç©¶çš„çƒ­æ½®ã€‚

In the last decade, many, many companies, both big corporations, and startups, have attempted to create new hardware for AI. The most notable attempts are Googleâ€™s [TPUs](https://cloud.google.com/tpu/docs/intro-to-tpu), Graphcoreâ€™s [IPUs](https://www.graphcore.ai/products/ipu) (whatâ€™s happening with IPUs?), and [Cerebras](https://www.eetimes.com/cerebras-sells-100-million-ai-supercomputer-plans-8-more/). SambaNova raised over [a billion dollars to develop new AI chips](https://spectrum.ieee.org/sambanova-ceo-ai-interview) but seems to have pivoted to being a generative AI platform.  

åœ¨è¿‡å»çš„åå¹´ä¸­ï¼Œæœ‰å¾ˆå¤šå¾ˆå¤šçš„å…¬å¸ï¼Œæ— è®ºæ˜¯å¤§å…¬å¸è¿˜æ˜¯åˆåˆ›ä¼ä¸šï¼Œéƒ½åœ¨å°è¯•ä¸ºäººå·¥æ™ºèƒ½åˆ›é€ æ–°çš„ç¡¬ä»¶ã€‚æœ€æ˜¾è‘—çš„å°è¯•æ˜¯è°·æ­Œçš„ TPUã€Graphcore çš„ IPUï¼ˆIPU å‘ç”Ÿäº†ä»€ä¹ˆï¼ŸSambaNova ç­¹é›†äº†è¶…è¿‡ 10 äº¿ç¾å…ƒçš„èµ„é‡‘æ¥å¼€å‘æ–°çš„äººå·¥æ™ºèƒ½èŠ¯ç‰‡ï¼Œä½†ä¼¼ä¹å·²è½¬å‘æˆä¸ºä¸€ä¸ªç”Ÿæˆå¼äººå·¥æ™ºèƒ½å¹³å°ã€‚

For a while, there has been a lot of anticipation around quantum computing, with key players being:  

ä¸€æ®µæ—¶é—´ä»¥æ¥ï¼Œäººä»¬å¯¹é‡å­è®¡ç®—å……æ»¡äº†æœŸå¾…ï¼Œå…¶ä¸­çš„ä¸»è¦å‚ä¸è€…åŒ…æ‹¬ï¼š

-   [IBMâ€™s QPUÂ IBM çš„ QPU](https://www.ibm.com/quantum)
-   Googleâ€™s Quantum computer reported [a major milestone in quantum error reduction](https://www.nature.com/articles/d41586-023-00536-w) earlier this year in Nature. Its quantum virtual machine is publicly accessible via [Google Colab](https://quantumai.google/quantum-virtual-machine)  
    
    è°·æ­Œçš„é‡å­è®¡ç®—æœºä»Šå¹´æ—©äº›æ—¶å€™åœ¨ã€Šè‡ªç„¶ã€‹æ‚å¿—ä¸ŠæŠ¥å‘Šäº†é‡å­é”™è¯¯å‡å°‘æ–¹é¢çš„ä¸€ä¸ªé‡è¦é‡Œç¨‹ç¢‘ã€‚å…¶é‡å­è™šæ‹Ÿæœºå¯é€šè¿‡è°·æ­Œå®éªŒå®¤ï¼ˆGoogle Colabï¼‰å…¬å¼€è®¿é—®ã€‚
-   Research labs such as [MIT Center for Quantum Engineering](https://cqe.mit.edu/), [Max Planck Institute of Quantum Optics](https://www.mpq.mpg.de/en), [Chicago Quantum Exchange](https://chicagoquantum.org/), [Oak Ridge National Laboratory](https://quantum-roadmap.ornl.gov/), etc.  
    
    éº»çœç†å·¥å­¦é™¢é‡å­å·¥ç¨‹ä¸­å¿ƒã€é©¬å…‹æ–¯-æ™®æœ—å…‹é‡å­å…‰å­¦ç ”ç©¶æ‰€ã€èŠåŠ å“¥é‡å­äº¤æ˜“æ‰€ã€æ©¡æ ‘å²­å›½å®¶å®éªŒå®¤ç­‰ç ”ç©¶å®éªŒå®¤ã€‚

Another direction that is also super exciting is photonic chips. This is the direciton I know the least about â€“ so please correct me if Iâ€™m wrong.  

å¦ä¸€ä¸ªä»¤äººå…´å¥‹çš„æ–¹å‘æ˜¯å…‰å­èŠ¯ç‰‡ã€‚è¿™æ˜¯æˆ‘æœ€ä¸äº†è§£çš„æ–¹å‘--å¦‚æœæˆ‘è¯´é”™äº†ï¼Œè¯·æŒ‡æ­£ã€‚  

Existing chips today use electricity to move data, which consumes a lot of power and also incurs latency.  

å¦‚ä»Šï¼Œç°æœ‰çš„èŠ¯ç‰‡ä½¿ç”¨ç”µåŠ›æ¥ä¼ è¾“æ•°æ®ï¼Œä¸ä»…è€—ç”µé‡å¤§ï¼Œè¿˜ä¼šäº§ç”Ÿå»¶è¿Ÿã€‚  

Photonic chips use photons to move data, harnessing the speed of light for faster and more efficient compute.  

å…‰å­èŠ¯ç‰‡ä½¿ç”¨å…‰å­æ¥ç§»åŠ¨æ•°æ®ï¼Œåˆ©ç”¨å…‰é€Ÿå®ç°æ›´å¿«ã€æ›´é«˜æ•ˆçš„è®¡ç®—ã€‚  

Various startups in this space have raised hundreds of millions of dollars, including [Lightmatter](https://lightmatter.co/) ($270M), [Ayar Labs](https://ayarlabs.com/) ($220M), [Lightelligence](https://www.lightelligence.ai/) ($200M+), and [Luminous Computing](https://www.luminous.com/) ($115M).  

è¯¥é¢†åŸŸçš„å¤šå®¶åˆåˆ›å…¬å¸å·²èèµ„æ•°äº¿ç¾å…ƒï¼ŒåŒ…æ‹¬ Lightmatterï¼ˆ2.7 äº¿ç¾å…ƒï¼‰ã€Ayar Labsï¼ˆ2.2 äº¿ç¾å…ƒï¼‰ã€Lightelligenceï¼ˆ2 äº¿å¤šç¾å…ƒï¼‰å’Œ Luminous Computingï¼ˆ1.15 äº¿ç¾å…ƒï¼‰ã€‚

Below is the timeline of advances of the three major methods in photonic matrix computation, from the paper [Photonic matrix multiplication lights up photonic accelerator and beyond](https://www.nature.com/articles/s41377-022-00717-8) (Zhou et al., Nature 2022). The three different methods are plane light conversion (PLC), Machâ€“Zehnder interferometer (MZI), and wavelength division multiplexing (WDM).  

ä»¥ä¸‹æ˜¯å…‰å­çŸ©é˜µè®¡ç®—ä¸‰ç§ä¸»è¦æ–¹æ³•çš„è¿›å±•æ—¶é—´è¡¨ï¼Œæ‘˜è‡ªè®ºæ–‡ã€Šå…‰å­çŸ©é˜µä¹˜æ³•ç‚¹äº®å…‰å­åŠ é€Ÿå™¨åŠå…¶ä»–ã€‹ï¼ˆZhou ç­‰ï¼Œã€Šè‡ªç„¶ã€‹ï¼Œ2022 å¹´ï¼‰ã€‚è¿™ä¸‰ç§ä¸åŒçš„æ–¹æ³•æ˜¯å¹³é¢å…‰è½¬æ¢ï¼ˆPLCï¼‰ã€é©¬èµ«-æ³½æ©å¾·å¹²æ¶‰ä»ªï¼ˆMZIï¼‰å’Œæ³¢åˆ†å¤ç”¨ï¼ˆWDMï¼‰ã€‚

![Timeline of advances of the three major methods in photonic matrix multiplication](6-photonic-matrix-multiplication.png)

## 7\. Make agents usable  

7.ä½¿ä»£ç†å¯ç”¨

Agents are LLMs that can take actions, like browsing the Internet, sending emails, making reservations, etc.  

ä»£ç†æ˜¯å¯ä»¥é‡‡å–è¡ŒåŠ¨çš„ LLMï¼Œå¦‚æµè§ˆäº’è”ç½‘ã€å‘é€ç”µå­é‚®ä»¶ã€é¢„è®¢æˆ¿é—´ç­‰ã€‚  

Compared to other research directions in this post, this might be the youngest direction.  

ä¸æœ¬èŒä½çš„å…¶ä»–ç ”ç©¶æ–¹å‘ç›¸æ¯”ï¼Œè¿™å¯èƒ½æ˜¯æœ€å¹´è½»çš„æ–¹å‘ã€‚

Because of the novelty and the massive potential, thereâ€™s a feverish obsession with agents. [Auto-GPT](https://github.com/Significant-Gravitas/Auto-GPT) is now the 25th most popular GitHub repo ever by the number of stars. [GPT-Engineering](https://github.com/AntonOsika/gpt-engineer) is another popular repo.  

ç”±äºå…¶æ–°é¢–æ€§å’Œå·¨å¤§æ½œåŠ›ï¼Œäººä»¬å¯¹ä»£ç†äº§ç”Ÿäº†ç‹‚çƒ­çš„ç—´è¿·ã€‚æ ¹æ®æ˜Ÿçº§æ•°é‡ï¼ŒAuto-GPT ç°åœ¨æ˜¯ GitHub æœ‰å²ä»¥æ¥ç¬¬ 25 æœ€å—æ¬¢è¿çš„è½¯ä»¶ä»“åº“ã€‚GPT-Engineering æ˜¯å¦ä¸€ä¸ªçƒ­é—¨è½¯ä»¶ä»“åº“ã€‚

Despite the excitement, there is still doubt about whether LLMs are reliable and performant enough to be entrusted with the power to act.  

å°½ç®¡ä»¤äººå…´å¥‹ï¼Œä½†äººä»¬ä»ç„¶æ€€ç–‘æ³•å¾‹ç¡•å£«æ˜¯å¦è¶³å¤Ÿå¯é ï¼Œæ˜¯å¦æœ‰è¶³å¤Ÿçš„èƒ½åŠ›è¢«èµ‹äºˆé‡‡å–è¡ŒåŠ¨çš„æƒåŠ›ã€‚

One use case that has emerged though is the use of agents for social studies, like the famous Stanford experiment that shows that a small society of generative agents produces emergent social behaviors: _for example, starting with only a single user-specified notion that one agent wants to throw a Valentineâ€™s Day party, the agents autonomously spread invitations to the party over the next two days, make new acquaintances, ask each other out on dates to the party â€¦_ ([Generative Agents: Interactive Simulacra of Human Behavior](https://arxiv.org/abs/2304.03442), Park et al., 2023)  

ä¸è¿‡ï¼Œå·²ç»å‡ºç°çš„ä¸€ä¸ªåº”ç”¨æ¡ˆä¾‹æ˜¯å°†ä»£ç†ç”¨äºç¤¾ä¼šç ”ç©¶ï¼Œæ¯”å¦‚è‘—åçš„æ–¯å¦ç¦å®éªŒå°±è¡¨æ˜ï¼Œä¸€ä¸ªç”±ç”Ÿæˆä»£ç†ç»„æˆçš„å°å‹ç¤¾ä¼šä¼šäº§ç”Ÿæ–°å…´çš„ç¤¾ä¼šè¡Œä¸ºï¼šä¾‹å¦‚ï¼Œä»ç”¨æˆ·æŒ‡å®šçš„ä¸€ä¸ªä»£ç†æƒ³è¦ä¸¾åŠæƒ…äººèŠ‚æ´¾å¯¹çš„å•ä¸€æ¦‚å¿µå¼€å§‹ï¼Œä»£ç†ä»¬ä¼šåœ¨æ¥ä¸‹æ¥çš„ä¸¤å¤©é‡Œè‡ªä¸»ä¼ æ’­æ´¾å¯¹é‚€è¯·å‡½ã€ç»“è¯†æ–°æœ‹å‹ã€ç›¸äº’çº¦ä¼šå‚åŠ æ´¾å¯¹......ï¼ˆã€Šç”Ÿæˆä»£ç†ï¼šäººç±»è¡Œä¸ºçš„äº¤äº’å¼æ¨¡æ‹Ÿã€‹ï¼ŒPark ç­‰äººï¼Œ2023 å¹´ï¼‰ï¼šäººç±»è¡Œä¸ºçš„äº’åŠ¨æ¨¡æ‹Ÿã€‹ï¼ŒPark ç­‰äººï¼Œ2023 å¹´)

The most notable startup in this area is perhaps Adept, founded by two Transformer co-authors (though [both already left](https://www.theinformation.com/briefings/two-co-founders-of-adept-an-openai-rival-suddenly-left-to-start-another-company)) and an ex-OpenAI VP, and has raised almost half a billion dollars to date.  

è¯¥é¢†åŸŸæœ€è‘—åçš„åˆåˆ›å…¬å¸å¯èƒ½æ˜¯ Adeptï¼Œå®ƒç”±ä¸¤ä½ã€Šå˜å½¢é‡‘åˆšã€‹çš„å…±åŒä½œè€…ï¼ˆè™½ç„¶ä¸¤äººéƒ½å·²ç¦»èŒï¼‰å’Œä¸€ä½å‰ OpenAI å‰¯æ€»è£åˆ›ç«‹ï¼Œè¿„ä»Šå·²èèµ„è¿‘ 5 äº¿ç¾å…ƒã€‚  

Last year, they had a demo showing their agent browsing the Internet and adding a new account to Salesforce. Iâ€™m looking forward to seeing their new demos ğŸ™‚  

å»å¹´ï¼Œä»–ä»¬æœ‰ä¸€ä¸ªæ¼”ç¤ºï¼Œå±•ç¤ºäº†ä»–ä»¬çš„ä»£ç†æµè§ˆäº’è”ç½‘å¹¶å‘ Salesforce æ·»åŠ æ–°è´¦æˆ·çš„è¿‡ç¨‹ã€‚æˆ‘å¾ˆæœŸå¾…çœ‹åˆ°ä»–ä»¬çš„æ–°æ¼”ç¤º ğŸ™‚

<iframe width="560" height="315" src="https://www.youtube.com/embed/a7CXIE_Gyy8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

## 8\. Improve learning from human preference  

8.æ”¹è¿›å¯¹äººç±»åå¥½çš„å­¦ä¹ 

[RLHF, Reinforcement Learning from Human Preference](https://huyenchip.com/2023/05/02/rlhf.html), is cool but kinda hacky. I wouldnâ€™t be surprised if people figure out a better way to train LLMs. There are many open questions for RLHF, such as:  

RLHFï¼Œå³ "ä»äººç±»åå¥½å¼ºåŒ–å­¦ä¹ "ï¼ˆReinforcement Learning from Human Preferenceï¼‰ï¼Œå¾ˆé…·ï¼Œä½†æœ‰ç‚¹ç¬¨ã€‚å¦‚æœäººä»¬èƒ½æ‰¾åˆ°æ›´å¥½çš„æ–¹æ³•æ¥è®­ç»ƒ LLMï¼Œæˆ‘ä¹Ÿä¸ä¼šæ„Ÿåˆ°æƒŠè®¶ã€‚RLHF è¿˜æœ‰å¾ˆå¤šé—®é¢˜æœ‰å¾…è§£å†³ï¼Œæ¯”å¦‚ï¼š

**1\. How to mathematically represent human preference?  

1.å¦‚ä½•ç”¨æ•°å­¦æ–¹æ³•è¡¨ç¤ºäººç±»çš„åå¥½ï¼Ÿ**

Currently, human preference is determined by comparison: human labeler determines if response A is better than response B.  

ç›®å‰ï¼Œäººç±»çš„åå¥½æ˜¯é€šè¿‡æ¯”è¾ƒæ¥ç¡®å®šçš„ï¼šäººç±»æ ‡ç­¾å‘˜ç¡®å®š A ååº”æ˜¯å¦ä¼˜äº B ååº”ã€‚  

However, it doesnâ€™t take into account how much better response A is than response B.  

ç„¶è€Œï¼Œè¿™å¹¶æ²¡æœ‰è€ƒè™‘åˆ° A ååº”æ¯” B ååº”å¥½å¤šå°‘ã€‚

**2\. Whatâ€™s human preference?  

2.äººç±»çš„åå¥½æ˜¯ä»€ä¹ˆï¼Ÿ**

Anthropic measured the quality of their modelâ€™s responses along the three axes: helpful, honest, and harmless. See [Constitutional AI: Harmlessness from AI Feedback](https://arxiv.org/abs/2212.08073) (Bai et al., 2022).  

Anthropicæ²¿ç€ä¸‰ä¸ªè½´çº¿è¡¡é‡äº†ä»–ä»¬æ¨¡å‹çš„å“åº”è´¨é‡ï¼šæœ‰ç›Šçš„ã€è¯šå®çš„å’Œæ— å®³çš„ã€‚å‚è§ã€Šäººå·¥æ™ºèƒ½å®ªæ³•ï¼šäººå·¥æ™ºèƒ½åé¦ˆçš„æ— å®³æ€§ã€‹ï¼ˆBai ç­‰äººï¼Œ2022 å¹´ï¼‰ã€‚

DeepMind tries to generate responses that please the most people. See [Fine-tuning language models to find agreement among humans with diverse preferences](https://www.deepmind.com/publications/fine-tuning-language-models-to-find-agreement-among-humans-with-diverse-preferences), (Bakker et al., 2022).  

DeepMind è¯•å›¾ç”Ÿæˆèƒ½å–æ‚¦æœ€å¤šäººçš„å›å¤ã€‚è¯·å‚é˜…ã€Šå¾®è°ƒè¯­è¨€æ¨¡å‹ï¼Œåœ¨å…·æœ‰ä¸åŒåå¥½çš„äººç±»ä¸­å¯»æ‰¾ä¸€è‡´ã€‹ï¼ˆBakker ç­‰äººï¼Œ2022 å¹´ï¼‰ã€‚

Also, do we want AIs that can take a stand or a vanilla AI that shies away from any potentially controversial topic?  

æ­¤å¤–ï¼Œæˆ‘ä»¬æ˜¯æƒ³è¦èƒ½è¡¨æ˜ç«‹åœºçš„äººå·¥æ™ºèƒ½ï¼Œè¿˜æ˜¯æƒ³è¦å¯¹ä»»ä½•å¯èƒ½æœ‰äº‰è®®çš„è¯é¢˜éƒ½é¿è€Œè¿œä¹‹çš„è™šæ— äººå·¥æ™ºèƒ½ï¼Ÿ

**3\. Whose preference is â€œhumanâ€ preference, taking into account the differences in cultures, religions, political leanings, etc.?  

3.è€ƒè™‘åˆ°æ–‡åŒ–ã€å®—æ•™ã€æ”¿æ²»å€¾å‘ç­‰æ–¹é¢çš„å·®å¼‚ï¼Œè°çš„åå¥½æ‰æ˜¯ "äºº "çš„åå¥½ï¼Ÿ**

There are a lot of challenges in obtaining training data that can be sufficiently representative of all the potential users.  

è¦è·å¾—èƒ½å……åˆ†ä»£è¡¨æ‰€æœ‰æ½œåœ¨ç”¨æˆ·çš„è®­ç»ƒæ•°æ®ï¼Œé¢ä¸´ç€å¾ˆå¤šæŒ‘æˆ˜ã€‚

For example, for OpenAIâ€™s InstructGPT data, there was no labeler above 65 years old. Labelers are predominantly Filipino and Bangladeshi. See [InstructGPT: Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155) (Ouyang et al., 2022).  

ä¾‹å¦‚ï¼Œåœ¨ OpenAI çš„ InstructGPT æ•°æ®ä¸­ï¼Œæ²¡æœ‰ 65 å²ä»¥ä¸Šçš„è´´æ ‡ç­¾è€…ã€‚è´´æ ‡ç­¾è€…ä¸»è¦æ˜¯è²å¾‹å®¾äººå’Œå­ŸåŠ æ‹‰å›½äººã€‚å‚è§ InstructGPTï¼šè®­ç»ƒè¯­è¨€æ¨¡å‹åœ¨äººç±»åé¦ˆä¸‹éµå¾ªæŒ‡ä»¤ï¼ˆæ¬§é˜³ç­‰äººï¼Œ2022 å¹´ï¼‰ã€‚

![Demographics of labelers for InstructGPT](8-instructgpt-demographics.png)

Community-led efforts, while admirable in their intention, can lead to biased data. For example, for the OpenAssistant dataset, 201 out of 222 (90.5%) respondents identify as male. [Jeremy Howard has a great Twitter thread on this](https://twitter.com/jeremyphoward/status/1647763133665271808/photo/1).  

ç¤¾åŒºä¸»å¯¼çš„åŠªåŠ›è™½ç„¶å…¶åˆè¡·ä»¤äººé’¦ä½©ï¼Œä½†å´å¯èƒ½å¯¼è‡´æ•°æ®çš„åå·®ã€‚ä¾‹å¦‚ï¼Œåœ¨ OpenAssistant æ•°æ®é›†ä¸­ï¼Œ222 ä½å—è®¿è€…ä¸­æœ‰ 201 ä½ï¼ˆ90.5%ï¼‰è®¤ä¸ºè‡ªå·±æ˜¯ç”·æ€§ã€‚æ°é‡Œç±³-éœåå¾·ï¼ˆJeremy Howardï¼‰åœ¨ Twitter ä¸Šæœ‰ä¸€ä¸ªå¾ˆå¥½çš„ä¸»é¢˜ã€‚

![Self-reported demographics of contributors to OpenAssistant dataset](8-openassistant-demographics.png)

## 9\. Improve the efficiency of the chat interface  

9.æé«˜èŠå¤©ç•Œé¢çš„æ•ˆç‡

Ever since ChatGPT, there have been multiple discussions on whether chat is a suitable interface for a wide range of tasks.  

è‡ª ChatGPT ä»¥æ¥ï¼Œäººä»¬ä¸€ç›´åœ¨è®¨è®ºèŠå¤©æ˜¯å¦æ˜¯ä¸€ä¸ªé€‚åˆå„ç§ä»»åŠ¡çš„ç•Œé¢ã€‚

-   [Natural language is the lazy user interface](https://austinhenley.com/blog/naturallanguageui.html) (Austin Z. Henley, 2023)  
    
    è‡ªç„¶è¯­è¨€æ˜¯æ‡’æƒ°çš„ç”¨æˆ·ç•Œé¢ï¼ˆAustin Z. Henleyï¼Œ2023 å¹´ï¼‰
-   [Why Chatbots Are Not the Future](https://wattenberger.com/thoughts/boo-chatbots) (Amelia Wattenberger, 2023)  
    
    ä¸ºä»€ä¹ˆèŠå¤©æœºå™¨äººä¸æ˜¯æœªæ¥ï¼ˆAmelia Wattenbergerï¼Œ2023 å¹´ï¼‰
-   [What Types of Questions Require Conversation to Answer? A Case Study of AskReddit Questions](https://arxiv.org/abs/2303.17710) (Huang et al., 2023)  
    
    å“ªç±»é—®é¢˜éœ€è¦å¯¹è¯æ‰èƒ½å›ç­”ï¼ŸAskReddit é—®é¢˜æ¡ˆä¾‹ç ”ç©¶ã€‹ï¼ˆHuang ç­‰äººï¼Œ2023 å¹´ï¼‰
-   [AI chat interfaces could become the primary user interface to read documentation](https://idratherbewriting.com/blog/ai-chat-interfaces-are-the-new-user-interface-for-docs) (Tom Johnson, 2023)  
    
    äººå·¥æ™ºèƒ½èŠå¤©ç•Œé¢å¯èƒ½æˆä¸ºé˜…è¯»æ–‡æ¡£çš„ä¸»è¦ç”¨æˆ·ç•Œé¢ï¼ˆæ±¤å§†-çº¦ç¿°é€Šï¼Œ2023 å¹´ï¼‰
-   [Interacting with LLMs with Minimal Chat](https://eugeneyan.com/writing/llm-ux/) (Eugene Yan, 2023)  
    
    ç”¨æœ€å°‘çš„èŠå¤©ä¸æ³•å­¦ç¡•å£«äº’åŠ¨ï¼ˆEugene Yanï¼Œ2023 å¹´ï¼‰

However, this is not a new discussion. In many countries, especially in Asia, chat has been used as the interface for super apps for about a decade. [Dan Grover had this discussion back in 2014](http://dangrover.com/blog/2014/12/01/chinese-mobile-app-ui-trends.html).  

ç„¶è€Œï¼Œè¿™å¹¶ä¸æ˜¯ä¸€ä¸ªæ–°çš„è®¨è®ºã€‚åœ¨è®¸å¤šå›½å®¶ï¼Œå°¤å…¶æ˜¯äºšæ´²ï¼ŒèŠå¤©ä½œä¸ºè¶…çº§åº”ç”¨ç¨‹åºçš„ç•Œé¢å·²ç»ä½¿ç”¨äº†å¤§çº¦åå¹´ã€‚ä¸¹-æ ¼ç½—å¼—æ—©åœ¨ 2014 å¹´å°±è¿›è¡Œè¿‡è¿™æ ·çš„è®¨è®ºã€‚

![Chat has been used as the universal interface for superapps in China for over a decade](9-superapp-chat-interface.png)

Chat as a universal interface for Chinese apps (Dan Grover, 2014)  

èŠå¤©ä½œä¸ºä¸­å›½åº”ç”¨ç¨‹åºçš„é€šç”¨ç•Œé¢ï¼ˆä¸¹-æ ¼ç½—å¼—ï¼Œ2014å¹´ï¼‰

The discussion again got tense in 2016, when many people thought apps were dead and chatbots would be the future.  

2016 å¹´ï¼Œå½“è®¸å¤šäººè®¤ä¸ºåº”ç”¨ç¨‹åºå·²æ­»ã€èŠå¤©æœºå™¨äººå°†æˆä¸ºæœªæ¥æ—¶ï¼Œè®¨è®ºå†æ¬¡å˜å¾—ç´§å¼ èµ·æ¥ã€‚

-   [On chat as interface](https://acroll.medium.com/on-chat-as-interface-92a68d2bf854) (Alistair Croll, 2016)  
    
    å…³äºä½œä¸ºç•Œé¢çš„èŠå¤©ï¼ˆé˜¿åˆ©æ–¯æ³°å°”-å…‹ç½—å°”ï¼Œ2016 å¹´ï¼‰
-   [Is the Chatbot Trend One Big Misunderstanding?](https://www.technologyreview.com/2016/04/25/8510/is-the-chatbot-trend-one-big-misunderstanding/) (Will Knight, 2016)  
    
    èŠå¤©æœºå™¨äººè¶‹åŠ¿æ˜¯ä¸€ä¸ªå¤§è¯¯åŒºå—ï¼Ÿ å¨å°”-å¥ˆç‰¹ï¼Œ2016å¹´
-   [Bots wonâ€™t replace apps. Better apps will replace apps](http://dangrover.com/blog/2016/04/20/bots-wont-replace-apps.html) (Dan Grover, 2016)  
    
    æœºå™¨äººä¸ä¼šå–ä»£åº”ç”¨ç¨‹åºã€‚æ›´å¥½çš„åº”ç”¨ç¨‹åºå°†å–ä»£åº”ç”¨ç¨‹åºï¼ˆDan Groverï¼Œ2016 å¹´ï¼‰

Personally, I love the chat interface because of the following reasons:  

æˆ‘ä¸ªäººéå¸¸å–œæ¬¢èŠå¤©ç•Œé¢ï¼ŒåŸå› å¦‚ä¸‹ï¼š

1.  Chat is an interface that everyone, even people without previous exposure to computers or the Internet, can learn to use quickly.  
    
    èŠå¤©æ˜¯ä¸€ç§äººäººéƒ½èƒ½å¿«é€Ÿå­¦ä¼šä½¿ç”¨çš„ç•Œé¢ï¼Œå³ä½¿æ˜¯ä»¥å‰æ²¡æœ‰æ¥è§¦è¿‡ç”µè„‘æˆ–äº’è”ç½‘çš„äººä¹Ÿå¯ä»¥ä½¿ç”¨ã€‚  
    
    When I volunteered at a low-income residential neighborhood (are we allowed to say slum?) in Kenya in the early 2010s, I was blown away by how comfortable everyone there was with doing banking on their phone, via texts.  
    
    2010 å¹´ä»£åˆï¼Œæˆ‘åœ¨è‚¯å°¼äºšçš„ä¸€ä¸ªä½æ”¶å…¥ä½å®…åŒºï¼ˆæˆ‘ä»¬å¯ä»¥è¯´æ˜¯è´«æ°‘çªŸå—ï¼Ÿï¼‰åšå¿—æ„¿è€…æ—¶ï¼Œé‚£é‡Œçš„æ¯ä¸ªäººéƒ½èƒ½è‡ªå¦‚åœ°é€šè¿‡æ‰‹æœºçŸ­ä¿¡åŠç†é“¶è¡Œä¸šåŠ¡ï¼Œè¿™è®©æˆ‘å¤§åƒä¸€æƒŠã€‚  
    
    No one in that neighborhood had a computer.  
    
    é‚£é™„è¿‘æ²¡æœ‰äººæœ‰ç”µè„‘ã€‚
2.  Chat interface is accessible. You can use voice instead of text if your hands are busy.  
    
    èŠå¤©ç•Œé¢æ— éšœç¢ã€‚å¦‚æœæ‰‹å¿™è„šä¹±ï¼Œå¯ä»¥ç”¨è¯­éŸ³ä»£æ›¿æ–‡å­—ã€‚
3.  Chat is also an incredibly robust interface â€“ you can give it any request and itâ€™ll give back a response, even if the response isnâ€™t good.  
    
    èŠå¤©ä¹Ÿæ˜¯ä¸€ä¸ªéå¸¸å¼ºå¤§çš„ç•Œé¢--ä½ å¯ä»¥å‘å®ƒæå‡ºä»»ä½•è¯·æ±‚ï¼Œå®ƒéƒ½ä¼šåšå‡ºå›åº”ï¼Œå³ä½¿å›åº”å¹¶ä¸å¥½ã€‚

However, there are certain areas that I think the chat interface can be improved upon.  

ä¸è¿‡ï¼Œæˆ‘è®¤ä¸ºèŠå¤©ç•Œé¢åœ¨æŸäº›æ–¹é¢è¿˜æœ‰å¾…æ”¹è¿›ã€‚

1.  Multiple messages per turn  
    
    æ¯è½®å¤šæ¡ä¿¡æ¯
    
    Currently, we pretty much assume one message per turn. This is not how my friends and I text.  
    
    ç›®å‰ï¼Œæˆ‘ä»¬å‡ ä¹æ˜¯æ¯è½®åªå‘ä¸€æ¡ä¿¡æ¯ã€‚æˆ‘å’Œæˆ‘çš„æœ‹å‹ä»¬å¯ä¸æ˜¯è¿™æ ·å‘çŸ­ä¿¡çš„ã€‚  
    
    Often, I need multiple messages to complete my thought, because I need to insert different data (e.g.  
    
    é€šå¸¸æƒ…å†µä¸‹ï¼Œæˆ‘éœ€è¦å¤šæ¡ä¿¡æ¯æ‰èƒ½å®Œæˆæˆ‘çš„æƒ³æ³•ï¼Œå› ä¸ºæˆ‘éœ€è¦æ’å…¥ä¸åŒçš„æ•°æ®ï¼ˆä¾‹å¦‚  
    
    images, locations, links), I forgot something in the previous messages, or I just donâ€™t feel like putting everything into a massive paragraph.  
    
    å›¾ç‰‡ã€åœ°ç‚¹ã€é“¾æ¥ï¼‰ï¼Œæˆ‘åœ¨ä¹‹å‰çš„ä¿¡æ¯ä¸­å¿˜è®°äº†ä¸€äº›ä¸œè¥¿ï¼Œæˆ–è€…æˆ‘åªæ˜¯ä¸æƒ³æŠŠæ‰€æœ‰ä¸œè¥¿éƒ½å†™è¿›ä¸€å¤§æ®µè¯é‡Œã€‚
    
2.  Multimodal inputÂ å¤šæ¨¡å¼è¾“å…¥
    
    In the realm of multimodal applications, most energy is spent on building better models, and very little on building better interfaces. Take [Nvidiaâ€™s NeVA chatbot](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/playground/models/neva). Iâ€™m not a UX expert, but I suspect there might be room for UX improvement here.  
    
    åœ¨å¤šæ¨¡æ€åº”ç”¨é¢†åŸŸï¼Œå¤§éƒ¨åˆ†ç²¾åŠ›éƒ½èŠ±åœ¨å»ºç«‹æ›´å¥½çš„æ¨¡å‹ä¸Šï¼Œè€Œå¾ˆå°‘èŠ±åœ¨å»ºç«‹æ›´å¥½çš„ç•Œé¢ä¸Šã€‚å°±æ‹¿ Nvidia çš„ NeVA èŠå¤©æœºå™¨äººæ¥è¯´å§ã€‚æˆ‘ä¸æ˜¯ç”¨æˆ·ä½“éªŒä¸“å®¶ï¼Œä½†æˆ‘è®¤ä¸ºè¿™é‡Œçš„ç”¨æˆ·ä½“éªŒå¯èƒ½è¿˜æœ‰æ”¹è¿›çš„ä½™åœ°ã€‚
    
    P.S. Sorry the NeVA team for calling you out. Even with this interface, your work is super cool!  
    
    é™„æ³¨ï¼šæŠ±æ­‰ï¼ŒNeVA å›¢é˜ŸæŠŠä½ å«å‡ºæ¥äº†ã€‚å³ä½¿æ˜¯è¿™æ ·çš„ç•Œé¢ï¼Œä½ çš„ä½œå“è¿˜æ˜¯è¶…é…·çš„ï¼
    
    ![NVIDIA's NeVA interface](9-neva.png)
    
3.  Incorporating generative AI into your workflows  
    
    å°†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½èå…¥å·¥ä½œæµç¨‹
    
    Linus Lee covered this point well in his talk [Generative AI interface beyond chats](https://www.youtube.com/watch?v=rd-J3hmycQs). For example, if you want to ask a question about a column of a chart youâ€™re working on, you should be able just point to that column and ask a question.  
    
    Linus Lee åœ¨ä»–çš„æ¼”è®² "èŠå¤©ä¹‹å¤–çš„äººå·¥æ™ºèƒ½ç”Ÿæˆç•Œé¢ "ä¸­å¾ˆå¥½åœ°é˜è¿°äº†è¿™ä¸€ç‚¹ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ æƒ³å°±æ­£åœ¨åˆ¶ä½œçš„å›¾è¡¨ä¸­çš„æŸä¸€åˆ—æé—®ï¼Œä½ åº”è¯¥å¯ä»¥ç›´æ¥æŒ‡å‘è¯¥åˆ—å¹¶æé—®ã€‚
    
4.  Editing and deletion of messages  
    
    ç¼–è¾‘å’Œåˆ é™¤ä¿¡æ¯
    
    How would editing or deletion of a user input change the conversation flow with the chatbot?  
    
    ç¼–è¾‘æˆ–åˆ é™¤ç”¨æˆ·è¾“å…¥ä¼šå¦‚ä½•æ”¹å˜ä¸èŠå¤©æœºå™¨äººçš„å¯¹è¯æµç¨‹ï¼Ÿ
    

## 10\. Build LLMs for non-English languages  

10.ä¸ºéè‹±è¯­è¯­è¨€å»ºç«‹ LLM

We know that current English-first LLMs donâ€™t work well for many other languages, both in terms of performance, latency, and speed. See:  

æˆ‘ä»¬çŸ¥é“ï¼Œç›®å‰ä»¥è‹±è¯­ä¸ºç¬¬ä¸€è¯­è¨€çš„ LLM åœ¨æ€§èƒ½ã€å»¶è¿Ÿå’Œé€Ÿåº¦æ–¹é¢éƒ½ä¸èƒ½å¾ˆå¥½åœ°é€‚ç”¨äºè®¸å¤šå…¶ä»–è¯­è¨€ã€‚è¯·çœ‹

-   [ChatGPT Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning](https://arxiv.org/abs/2304.05613) (Lai et al., 2023)  
    
    ChatGPT è¶…è¶Šè‹±è¯­ï¼šåœ¨å¤šè¯­è¨€å­¦ä¹ ä¸­å…¨é¢è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLai ç­‰äººï¼Œ2023 å¹´ï¼‰
-   [All languages are NOT created (tokenized) equal](https://blog.yenniejun.com/p/all-languages-are-not-created-tokenized) (Yennie Jun, 2023)  
    
    æ‰€æœ‰è¯­è¨€çš„åˆ›å»ºï¼ˆæ ‡è®°åŒ–ï¼‰å¹¶ä¸å¹³ç­‰ï¼ˆYennie Junï¼Œ2023 å¹´ï¼‰

![Tokenization for non-English languages](10-non-english-tokens.png)

Iâ€™m only aware of the effort to train Vietnamese ChatGPT ([Symato](https://discord.gg/a2PCzB4AdE) might be the biggest community effort). If youâ€™re aware of community initiatives in other languages, Iâ€™d be happy to include them here.  

æˆ‘åªçŸ¥é“åŸ¹è®­è¶Šå—è¯­ ChatGPT çš„åŠªåŠ›ï¼ˆSymato å¯èƒ½æ˜¯æœ€å¤§çš„ç¤¾åŒºåŠªåŠ›ï¼‰ã€‚å¦‚æœæ‚¨çŸ¥é“å…¶ä»–è¯­è¨€çš„ç¤¾åŒºæ´»åŠ¨ï¼Œæˆ‘å¾ˆä¹æ„åœ¨æ­¤ä»‹ç»ã€‚

Several early readers of this post told me they donâ€™t think I should include this direction for two reasons.  

è¿™ç¯‡æ–‡ç« çš„å‡ ä½æ—©æœŸè¯»è€…å‘Šè¯‰æˆ‘ï¼Œä»–ä»¬è®¤ä¸ºæˆ‘ä¸åº”è¯¥æŠŠè¿™ä¸ªæ–¹å‘å†™è¿›å»ï¼ŒåŸå› æœ‰ä¸¤ä¸ªã€‚

1.  This is less of a research problem and more of a logistics problem. We already know how to do it. Someone just needs to put money and effort into it. This is not entirely true.  
    
    è¿™ä¸å…¶è¯´æ˜¯ä¸€ä¸ªç ”ç©¶é—®é¢˜ï¼Œä¸å¦‚è¯´æ˜¯ä¸€ä¸ªåå‹¤é—®é¢˜ã€‚æˆ‘ä»¬å·²ç»çŸ¥é“å¦‚ä½•å»åšã€‚åªæ˜¯éœ€è¦æœ‰äººæŠ•å…¥èµ„é‡‘å’Œç²¾åŠ›ã€‚è¿™å¹¶ä¸å®Œå…¨æ­£ç¡®ã€‚  
    
    Most languages are considered low-resource, e.g.  
    
    å¤§å¤šæ•°è¯­è¨€è¢«è®¤ä¸ºæ˜¯ä½èµ„æºè¯­è¨€ï¼Œä¾‹å¦‚  
    
    they have far fewer high-quality data compared to English or Chinese, and might require different techniques to train a large language model. See:  
    
    ä¸è‹±è¯­æˆ–ä¸­æ–‡ç›¸æ¯”ï¼Œå®ƒä»¬çš„é«˜è´¨é‡æ•°æ®è¦å°‘å¾—å¤šï¼Œå¯èƒ½éœ€è¦ä¸åŒçš„æŠ€æœ¯æ¥è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ã€‚è¯·å‚è§
    
    -   [Low-resource Languages: A Review of Past Work and Future Challenges](https://arxiv.org/abs/2006.07264) (Magueresse et al., 2020)  
        
        ä½èµ„æºè¯­è¨€ï¼šè¿‡å»å·¥ä½œå›é¡¾ä¸æœªæ¥æŒ‘æˆ˜ã€‹ï¼ˆMagueresse ç­‰äººï¼Œ2020 å¹´ï¼‰
    -   [JW300: A Wide-Coverage Parallel Corpus for Low-Resource Languages](https://aclanthology.org/P19-1310/) (AgiÄ‡ et al., 2019)  
        
        JW300ï¼šä½èµ„æºè¯­è¨€çš„å¹¿è¦†ç›–å¹¶è¡Œè¯­æ–™åº“ï¼ˆAgiÄ‡ ç­‰äººï¼Œ2019 å¹´ï¼‰
2.  Those more pessimistic think that in the future, many languages will die out, and the Internet will consist of two universes in two languages: English and Mandarin.  
    
    æ›´æ‚²è§‚çš„äººè®¤ä¸ºï¼Œæœªæ¥è®¸å¤šè¯­è¨€å°†æ¶ˆäº¡ï¼Œäº’è”ç½‘å°†ç”±ä¸¤ç§è¯­è¨€çš„ä¸¤ä¸ªä¸–ç•Œç»„æˆï¼šè‹±è¯­å’Œæ™®é€šè¯ã€‚  
    
    This school of thought isnâ€™t new â€“ anyone remembers Esperando?  
    
    è¿™ç§è§‚ç‚¹å¹¶ä¸æ–°é²œï¼Œæœ‰äººè¿˜è®°å¾— Esperando å—ï¼Ÿ
    

The impact of AI tools, e.g. machine translation and chatbots, on language learning is still unclear.  

äººå·¥æ™ºèƒ½å·¥å…·ï¼ˆå¦‚æœºå™¨ç¿»è¯‘å’ŒèŠå¤©æœºå™¨äººï¼‰å¯¹è¯­è¨€å­¦ä¹ çš„å½±å“å°šä¸æ˜ç¡®ã€‚  

Will they help people learn new languages faster, or will they eliminate the need of learning new languages altogether?  

å®ƒä»¬ä¼šå¸®åŠ©äººä»¬æ›´å¿«åœ°å­¦ä¹ æ–°è¯­è¨€ï¼Œè¿˜æ˜¯ä¼šå®Œå…¨æ¶ˆé™¤å­¦ä¹ æ–°è¯­è¨€çš„éœ€è¦ï¼Ÿ

## ConclusionÂ ç»“è®º

Phew, that was a lot of papers to reference, and I have no doubt that I still missed a ton. If thereâ€™s something you think I missed, please let me know.  

å‘¼ï¼Œè¦å‚è€ƒçš„è®ºæ–‡è¿˜çœŸä¸å°‘ï¼Œæ¯«æ— ç–‘é—®ï¼Œæˆ‘è¿˜æœ‰å¾ˆå¤šé—æ¼ã€‚å¦‚æœä½ è®¤ä¸ºæˆ‘é—æ¼äº†ä»€ä¹ˆï¼Œè¯·å‘Šè¯‰æˆ‘ã€‚

For another perspective, check out this comprehsive paper [Challenges and Applications of Large Language Models](https://arxiv.org/abs/2307.10169) (Kaddour et al., 2023).  

ä»å¦ä¸€ä¸ªè§’åº¦æ¥çœ‹ï¼Œè¯·æŸ¥çœ‹è¿™ç¯‡ç»¼åˆæ€§è®ºæ–‡ã€Šå¤§å‹è¯­è¨€æ¨¡å‹çš„æŒ‘æˆ˜ä¸åº”ç”¨ã€‹ï¼ˆKaddour ç­‰äººï¼Œ2023 å¹´ï¼‰ã€‚

Some of the problems mentioned above are harder than others.  

ä¸Šè¿°æœ‰äº›é—®é¢˜æ¯”å…¶ä»–é—®é¢˜æ›´éš¾è§£å†³ã€‚  

For example, I think that number 10, building LLMs for non-English languages, is more straightforward with enough time and resources.  

ä¾‹å¦‚ï¼Œæˆ‘è®¤ä¸ºç¬¬ 10 é¡¹ï¼Œå³ä¸ºéè‹± è¯­è¯­è¨€å»ºç«‹ LLMï¼Œåªè¦æœ‰è¶³å¤Ÿçš„æ—¶é—´å’Œèµ„æºï¼Œå°±ä¼šæ¯”è¾ƒç®€å•ã€‚

Number 1, reducing hallucination, will be much harder, since hallucination is just LLMs doing their probabilistic thing.  

ç¬¬ 1 é¡¹æ˜¯å‡å°‘å¹»è§‰ï¼Œè¿™å°†ä¼šéš¾å¾—å¤šï¼Œå› ä¸ºå¹»è§‰åªæ˜¯ LLM åœ¨åšæ¦‚ç‡çš„äº‹æƒ…ã€‚

Number 4, making LLMs faster and cheaper, will never be completely solved.  

ç¬¬ 4 ç‚¹ï¼Œè®©æ³•å¾‹ç¡•å£«æ›´å¿«ã€æ›´ä¾¿å®œï¼Œè¿™ä¸ªé—®é¢˜æ°¸è¿œæ— æ³•å½»åº•è§£å†³ã€‚  

There is already so much progress in this area, and there will be more, but we will never run out of room for improvement.  

æˆ‘ä»¬åœ¨è¿™æ–¹é¢å·²ç»å–å¾—äº†å·¨å¤§è¿›æ­¥ï¼Œä»Šåè¿˜ä¼šæœ‰æ›´å¤šè¿›æ­¥ï¼Œä½†æˆ‘ä»¬æ°¸è¿œä¸ä¼šæ²¡æœ‰æ”¹è¿›çš„ä½™åœ°ã€‚

Number 5 and number 6, new architectures and new hardware, are very challenging, but they are inevitable with time.  

ç¬¬ 5 é¡¹å’Œç¬¬ 6 é¡¹ï¼Œå³æ–°æ¶æ„å’Œæ–°ç¡¬ä»¶ï¼Œéå¸¸å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œä½†éšç€æ—¶é—´çš„æ¨ç§»ä¸å¯é¿å…ã€‚  

Because of the symbiosis between architecture and hardware â€“ new architecture will need to be optimized for common hardware, and hardware will need to support common architecture â€“ they might be solved by the same company.  

ç”±äºæ¶æ„å’Œç¡¬ä»¶ä¹‹é—´çš„å…±ç”Ÿå…³ç³»--æ–°æ¶æ„éœ€è¦é’ˆå¯¹é€šç”¨ç¡¬ä»¶è¿›è¡Œä¼˜åŒ–ï¼Œè€Œç¡¬ä»¶éœ€è¦æ”¯æŒé€šç”¨æ¶æ„--å®ƒä»¬å¯èƒ½ç”±åŒä¸€å®¶å…¬å¸æ¥è§£å†³ã€‚

Some of these problems wonâ€™t be solved using only technical knowledge.  

æœ‰äº›é—®é¢˜ä»…é æŠ€æœ¯çŸ¥è¯†æ˜¯æ— æ³•è§£å†³çš„ã€‚  

For example, number 8, improving learning from human preference, might be more of a policy problem than a technical problem.  

ä¾‹å¦‚ï¼Œç¬¬ 8 é¡¹ "æ”¹è¿›å¯¹äººç±»åå¥½çš„å­¦ä¹  "å¯èƒ½æ›´åƒæ˜¯ä¸€ä¸ªæ”¿ç­–é—®é¢˜ï¼Œè€Œä¸æ˜¯æŠ€æœ¯é—®é¢˜ã€‚  

Number 9, improving the efficiency of the chat interface, is more of a UX problem. We need more people with non-technical backgrounds to work with us to solve these problems.  

ç¬¬ 9 ä¸ªé—®é¢˜æ˜¯æé«˜èŠå¤©ç•Œé¢çš„æ•ˆç‡ï¼Œè¿™æ›´åƒæ˜¯ä¸€ä¸ªç”¨æˆ·ä½“éªŒé—®é¢˜ã€‚æˆ‘ä»¬éœ€è¦æ›´å¤šå…·æœ‰éæŠ€æœ¯èƒŒæ™¯çš„äººå‘˜ä¸æˆ‘ä»¬ä¸€èµ·è§£å†³è¿™äº›é—®é¢˜ã€‚

What research direction are you most excited about? What are the most promising solutions you see for these problems? Iâ€™d love to hear from you.  

æ‚¨æœ€æ„Ÿå…´è¶£çš„ç ”ç©¶æ–¹å‘æ˜¯ä»€ä¹ˆï¼Ÿæ‚¨è®¤ä¸ºæœ€æœ‰å¸Œæœ›è§£å†³è¿™äº›é—®é¢˜çš„æ–¹æ¡ˆæ˜¯ä»€ä¹ˆï¼Ÿæˆ‘å¾ˆä¹æ„å¬å–æ‚¨çš„æ„è§ã€‚
