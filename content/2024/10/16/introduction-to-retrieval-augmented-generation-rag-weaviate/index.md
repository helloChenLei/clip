---
title: "RAG ç®€ä»‹e"
date: 2024-10-16T13:18:57+08:00
updated: 2024-10-16T13:18:57+08:00
taxonomies:
  tags: []
extra:
  source: https://weaviate.io/blog/introduction-to-rag
  hostname: weaviate.io
  author: Mary NewhauserMachine Learning Engineer
  original_title: "Introduction to Retrieval Augmented Generation (RAG) | Weaviate"
  original_lang: en
---

![Introduction to Retrieval Augmented Generation (RAG)](hero-e7cf1576734aaa08fc558b8f5dd4d8fd.png)

Despite the steady release of increasingly larger and smarter models, state-of-the-art generative large language models (LLMs) still have a big problem: they struggle with tasks that require specialized knowledge.  

å°½ç®¡è¶Šæ¥è¶Šå¤§ã€è¶Šæ¥è¶Šæ™ºèƒ½çš„æ¨¡å‹ç¨³æ­¥å‘å¸ƒï¼Œä½†æœ€å…ˆè¿›çš„ç”Ÿæˆå¼å¤§å‹è¯­è¨€æ¨¡å‹ ï¼ˆLLMsï¼‰ ä»ç„¶å­˜åœ¨ä¸€ä¸ªå¤§é—®é¢˜ï¼šå®ƒä»¬éš¾ä»¥å®Œæˆéœ€è¦ä¸“ä¸šçŸ¥è¯†çš„ä»»åŠ¡ã€‚  

This lack of specialized knowledge can lead to issues like hallucinations, where the model generates inaccurate or fabricated information.  

è¿™ç§ä¸“ä¸šçŸ¥è¯†çš„ç¼ºä¹ä¼šå¯¼è‡´å¹»è§‰ç­‰é—®é¢˜ï¼Œå…¶ä¸­æ¨¡å‹ç”Ÿæˆä¸å‡†ç¡®æˆ–æé€ çš„ä¿¡æ¯ã€‚  

**Retrieval-Augmented Generation (RAG)** helps mitigate this by allowing the model to pull in real-time, niche data from external sources, enhancing its ability to provide accurate and detailed responses.  

**Retrieval-Augmented Generation ï¼ˆRAGï¼‰** å…è®¸æ¨¡å‹ä»å¤–éƒ¨æ¥æºæå–å®æ—¶çš„åˆ©åŸºæ•°æ®ï¼Œä»è€Œå¢å¼ºå…¶æä¾›å‡†ç¡®å’Œè¯¦ç»†å“åº”çš„èƒ½åŠ›ï¼Œä»è€Œå¸®åŠ©ç¼“è§£è¿™ç§æƒ…å†µã€‚

Despite these limitations, generative models are impactful tools that automate mundane processes, assist us in our everyday work, and enable us to interact with data in new ways.  

å°½ç®¡å­˜åœ¨è¿™äº›é™åˆ¶ï¼Œä½†ç”Ÿæˆæ¨¡å‹æ˜¯æœ‰å½±å“åŠ›çš„å·¥å…·ï¼Œå¯ä»¥è‡ªåŠ¨åŒ–æ—¥å¸¸æµç¨‹ï¼Œå¸®åŠ©æˆ‘ä»¬å®Œæˆæ—¥å¸¸å·¥ä½œï¼Œå¹¶ä½¿æˆ‘ä»¬èƒ½å¤Ÿä»¥æ–°çš„æ–¹å¼ä¸æ•°æ®äº¤äº’ã€‚  

So how can we leverage their broad knowledge while also making them work for our specific use cases?  

é‚£ä¹ˆï¼Œæˆ‘ä»¬å¦‚ä½•åˆ©ç”¨ä»–ä»¬çš„å¹¿æ³›çŸ¥è¯†ï¼ŒåŒæ—¶è®©ä»–ä»¬ä¸ºæˆ‘ä»¬çš„ç‰¹å®šç”¨ä¾‹æœåŠ¡å‘¢ï¼Ÿ  

The answer lies in providing generative models with task-specific data.  

ç­”æ¡ˆåœ¨äºä¸ºç”Ÿæˆæ¨¡å‹æä¾›ç‰¹å®šäºä»»åŠ¡çš„æ•°æ®ã€‚

In this article, we take a deep dive into Retrieval Augmented Generation (RAG), a framework that enhances the capabilities of generative models by allowing them to reference external data.  

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æ·±å…¥æ¢è®¨äº†æ£€ç´¢å¢å¼ºç”Ÿæˆ ï¼ˆRAGï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªé€šè¿‡å…è®¸ç”Ÿæˆæ¨¡å‹å¼•ç”¨å¤–éƒ¨æ•°æ®æ¥å¢å¼ºç”Ÿæˆæ¨¡å‹åŠŸèƒ½çš„æ¡†æ¶ã€‚  

Weâ€™ll explore the limitations of generative models that led to the creation of RAG, explain how RAG works, and break down the architecture behind RAG pipelines.  

æˆ‘ä»¬å°†æ¢è®¨å¯¼è‡´ RAG åˆ›å»ºçš„ç”Ÿæˆæ¨¡å‹çš„å±€é™æ€§ï¼Œè§£é‡Š RAG çš„å·¥ä½œåŸç†ï¼Œå¹¶åˆ†è§£ RAG ç®¡é“èƒŒåçš„æ¶æ„ã€‚  

Weâ€™ll also get practical and outline some real-world RAG use cases, suggest concrete ways to implement RAG, introduce you to a few advanced RAG techniques, and discuss RAG evaluation methods.  

æˆ‘ä»¬è¿˜å°†æä¾›å®ç”¨çš„æ¦‚è¿°ï¼Œæ¦‚è¿°ä¸€äº›çœŸå®çš„ RAG ç”¨ä¾‹ï¼Œæå‡ºå®æ–½ RAG çš„å…·ä½“æ–¹æ³•ï¼Œå‘æ‚¨ä»‹ç»ä¸€äº›é«˜çº§ RAG æŠ€æœ¯ï¼Œå¹¶è®¨è®º RAG è¯„ä¼°æ–¹æ³•ã€‚

note  

æ³¨æ„

LLM is a broad term that refers to language models trained on large datasets that are capable of performing a variety of text- and language-related tasks.  

LLM æ˜¯ä¸€ä¸ªå¹¿ä¹‰æœ¯è¯­ï¼ŒæŒ‡çš„æ˜¯åœ¨å¤§å‹æ•°æ®é›†ä¸Šè®­ç»ƒçš„è¯­è¨€æ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹èƒ½å¤Ÿæ‰§è¡Œå„ç§æ–‡æœ¬å’Œè¯­è¨€ç›¸å…³ä»»åŠ¡ã€‚  

LLMs that generate novel text in response to a user prompt, like those used in chatbots, are called generative LLMs, or **generative models**. LLMs that encode text data in the semantic space are called **embedding models**.  

LLMsç”¨æˆ·æç¤ºç”Ÿæˆæ–°æ–‡æœ¬çš„ LLMï¼Œå¦‚èŠå¤©æœºå™¨äººä¸­ä½¿ç”¨çš„æ–‡æœ¬ï¼Œç§°ä¸ºç”Ÿæˆå¼ LLMs æˆ–**ç”Ÿæˆæ¨¡å‹**ã€‚LLMsè¯­ä¹‰ç©ºé—´ä¸­å¯¹æ–‡æœ¬æ•°æ®è¿›è¡Œç¼–ç çš„ LLM ç§°ä¸ºåµŒå…¥**æ¨¡å‹**ã€‚  

Thus, we use the terms generative model and embedding model to distinguish between these two types of models in this article.  

å› æ­¤ï¼Œåœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨æœ¯è¯­ ç”Ÿæˆæ¨¡å‹ å’Œ åµŒå…¥æ¨¡å‹ æ¥åŒºåˆ†è¿™ä¸¤ç§ç±»å‹çš„æ¨¡å‹ã€‚

## Limitations of generative models[](https://weaviate.io/blog/introduction-to-rag#limitations-of-generative-models "Direct link to Limitations of generative models")  

ç”Ÿæˆæ¨¡å‹çš„[](https://weaviate.io/blog/introduction-to-rag#limitations-of-generative-models "Direct link to Limitations of generative models")å±€é™æ€§

Generative models are trained on large datasets, including (but not limited to) social media posts, books, scholarly articles and scraped webpages, allowing them to acquire a sense of general knowledge.  

ç”Ÿæˆæ¨¡å‹åœ¨å¤§å‹æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼ŒåŒ…æ‹¬ï¼ˆä½†ä¸é™äºï¼‰ç¤¾äº¤åª’ä½“å¸–å­ã€ä¹¦ç±ã€å­¦æœ¯æ–‡ç« å’ŒæŠ“å–çš„ç½‘é¡µï¼Œä½¿å®ƒä»¬èƒ½å¤Ÿè·å¾—ä¸€èˆ¬çŸ¥è¯†ã€‚  

As a result, these models can generate human-like text, respond to diverse questions, and assist with tasks like answering, summarizing, and creative writing.  

å› æ­¤ï¼Œè¿™äº›æ¨¡å‹å¯ä»¥ç”Ÿæˆç±»ä¼¼äººç±»çš„æ–‡æœ¬ï¼Œå›ç­”ä¸åŒçš„é—®é¢˜ï¼Œå¹¶ååŠ©å®Œæˆå›ç­”ã€æ€»ç»“å’Œåˆ›æ„å†™ä½œç­‰ä»»åŠ¡ã€‚

However, training datasets for generative models are inevitably incomplete, as they lack information on niche topics and new developments beyond the datasetâ€™s cutoff date.  

ç„¶è€Œï¼Œç”Ÿæˆæ¨¡å‹çš„è®­ç»ƒæ•°æ®é›†ä¸å¯é¿å…åœ°æ˜¯ä¸å®Œæ•´çš„ï¼Œå› ä¸ºå®ƒä»¬ç¼ºä¹æœ‰å…³åˆ©åŸºä¸»é¢˜å’Œæ•°æ®é›†æˆªæ­¢æ—¥æœŸä¹‹åçš„æ–°å‘å±•çš„ä¿¡æ¯ã€‚  

Generative models also lack access to proprietary data from internal databases or repositories.  

ç”Ÿæˆæ¨¡å‹ä¹Ÿæ— æ³•è®¿é—®æ¥è‡ªå†…éƒ¨æ•°æ®åº“æˆ–å­˜å‚¨åº“çš„ä¸“æœ‰æ•°æ®ã€‚  

Furthermore, when these models donâ€™t know the answer to a question, they often guess, and sometimes not very well.  

æ­¤å¤–ï¼Œå½“è¿™äº›æ¨¡å‹ä¸çŸ¥é“é—®é¢˜çš„ç­”æ¡ˆæ—¶ï¼Œä»–ä»¬é€šå¸¸ä¼šçŒœæµ‹ï¼Œæœ‰æ—¶ä¸æ˜¯å¾ˆå¥½ã€‚  

This tendency to generate incorrect or fabricated information in a convincing manner is known as hallucination, and can cause real reputational damage in client-facing AI applications.  

è¿™ç§ä»¥ä»¤äººä¿¡æœçš„æ–¹å¼ç”Ÿæˆä¸æ­£ç¡®æˆ–æé€ ä¿¡æ¯çš„å€¾å‘è¢«ç§°ä¸ºå¹»è§‰ï¼Œå¯èƒ½ä¼šåœ¨é¢å‘å®¢æˆ·çš„ AI åº”ç”¨ç¨‹åºä¸­é€ æˆçœŸæ­£çš„å£°èª‰æŸå®³ã€‚

The key to enhancing performance on specialized tasks and reducing hallucinations is to provide generative models with additional information not found in their training data.  

æé«˜ä¸“ä¸šä»»åŠ¡æ€§èƒ½å’Œå‡å°‘å¹»è§‰çš„å…³é”®æ˜¯ä¸ºç”Ÿæˆæ¨¡å‹æä¾›å…¶è®­ç»ƒæ•°æ®ä¸­æœªæ‰¾åˆ°çš„é™„åŠ ä¿¡æ¯ã€‚  

This is where RAG comes in.  

è¿™å°±æ˜¯ RAG çš„ç”¨æ­¦ä¹‹åœ°ã€‚

## What is Retrieval Augmented Generation (RAG)?[](https://weaviate.io/blog/introduction-to-rag#what-is-retrieval-augmented-generation-rag "Direct link to What is Retrieval Augmented Generation (RAG)?")  

ä»€ä¹ˆæ˜¯ Retrieval Augmented Generation ï¼ˆRAGï¼‰ï¼Ÿ[](https://weaviate.io/blog/introduction-to-rag#what-is-retrieval-augmented-generation-rag "Direct link to What is Retrieval Augmented Generation (RAG)?")

[**Retrieval-Augmented Generation (RAG)**](https://arxiv.org/abs/2005.11401) is a framework that _augments_ the general knowledge of a generative LLM by providing it with additional data relevant to the task at hand _retrieved_ from an external data source.  

[**æ£€ç´¢å¢å¼ºç”Ÿæˆ ï¼ˆRAGï¼‰**](https://arxiv.org/abs/2005.11401) æ˜¯ä¸€ä¸ªæ¡†æ¶ï¼Œå®ƒé€šè¿‡å‘ç”Ÿæˆå¼ LLMä¸ä»å¤–éƒ¨æ•°æ®æº_æ£€ç´¢_çš„æ‰‹å¤´ä»»åŠ¡ç›¸å…³çš„é¢å¤–æ•°æ®æ¥å¢å¼ºç”Ÿæˆå¼ ä»£ç  id=g1001 LLM çš„ä¸€èˆ¬çŸ¥è¯†ã€‚

External data sources can include internal databases, files, and repositories, as well as publicly available data such as news articles, websites, or other online content.  

å¤–éƒ¨æ•°æ®æºå¯ä»¥åŒ…æ‹¬å†…éƒ¨æ•°æ®åº“ã€æ–‡ä»¶å’Œå­˜å‚¨åº“ï¼Œä»¥åŠå…¬å¼€å¯ç”¨çš„æ•°æ®ï¼Œä¾‹å¦‚æ–°é—»æ–‡ç« ã€ç½‘ç«™æˆ–å…¶ä»–åœ¨çº¿å†…å®¹ã€‚  

Access to this data empowers the model to respond more factually, cite its sources in its responses, and avoid â€œguessingâ€ when prompted about information not found in the modelâ€™s original training dataset.  

è®¿é—®è¿™äº›æ•°æ®ä½¿æ¨¡å‹èƒ½å¤Ÿæ›´çœŸå®åœ°åšå‡ºå“åº”ï¼Œåœ¨å“åº”ä¸­å¼•ç”¨å…¶æ¥æºï¼Œå¹¶é¿å…åœ¨æç¤ºæ¨¡å‹çš„åŸå§‹è®­ç»ƒæ•°æ®é›†ä¸­æ‰¾ä¸åˆ°çš„ä¿¡æ¯æ—¶â€œçŒœæµ‹â€ã€‚

Common use cases for RAG include retrieving up-to-date information, accessing specialized domain knowledge, and answering complex, data-driven queries.  

RAG çš„å¸¸è§ä½¿ç”¨æ¡ˆä¾‹åŒ…æ‹¬æ£€ç´¢æœ€æ–°ä¿¡æ¯ã€è®¿é—®ä¸“é—¨çš„é¢†åŸŸçŸ¥è¯†ä»¥åŠå›ç­”å¤æ‚çš„æ•°æ®é©±åŠ¨å‹æŸ¥è¯¢ã€‚

## RAG architecture[](https://weaviate.io/blog/introduction-to-rag#rag-architecture "Direct link to RAG architecture")  

RAG æ¶æ„[](https://weaviate.io/blog/introduction-to-rag#rag-architecture "Direct link to RAG architecture")

The basic parts of a RAG pipeline can be broken down into **three components**: an external knowledge source, a prompt template, and a generative model.  

RAG ç®¡é“çš„åŸºæœ¬éƒ¨åˆ†å¯ä»¥åˆ†ä¸º**ä¸‰ä¸ªéƒ¨åˆ†**ï¼šå¤–éƒ¨æ•°æ®æºã€æç¤ºæ¨¡æ¿å’Œç”Ÿæˆæ¨¡å‹ã€‚  

Together, these components enable LLM-powered applications to generate more accurate responses by leveraging valuable task-specific data.  

è¿™äº›ç»„ä»¶å…±åŒä½¿ LLM æ”¯æŒçš„åº”ç”¨ç¨‹åºèƒ½å¤Ÿåˆ©ç”¨æœ‰ä»·å€¼çš„ä»»åŠ¡ç‰¹å®šæ•°æ®ç”Ÿæˆæ›´å‡†ç¡®çš„å“åº”ã€‚

![RAG Base](rag-base-6922e1e499f305d966a0b1d6fd4694e5.png "RAG Base Diagram")

### External knowledge source[](https://weaviate.io/blog/introduction-to-rag#external-knowledge-source "Direct link to External knowledge source")  

å¤–éƒ¨çŸ¥è¯†æº[](https://weaviate.io/blog/introduction-to-rag#external-knowledge-source "Direct link to External knowledge source")

Without access to external knowledge, a generative model is limited to generating responses based only on its **parametric knowledge**, which is learned during the model training phase.  

ç”±äºæ— æ³•è®¿é—®å¤–éƒ¨çŸ¥è¯†ï¼Œç”Ÿæˆæ¨¡å‹åªèƒ½æ ¹æ®å…¶**å‚æ•°çŸ¥è¯†**ç”Ÿæˆå“åº”ï¼Œè¿™äº›çŸ¥è¯†æ˜¯åœ¨æ¨¡å‹è®­ç»ƒé˜¶æ®µå­¦ä¹ çš„ã€‚  

With RAG, we have the opportunity to incorporate **external knowledge sources**, also referred to as **non-parametric knowledge**, in our pipeline.  

å€ŸåŠ© RAGï¼Œæˆ‘ä»¬æœ‰æœºä¼šå°†**å¤–éƒ¨çŸ¥è¯†æº**ï¼ˆä¹Ÿç§°ä¸º**éå‚æ•°çŸ¥è¯†**ï¼‰æ•´åˆåˆ°æˆ‘ä»¬çš„ç®¡é“ä¸­ã€‚

External data sources are often task-specific and likely beyond the scope of the modelâ€™s original training data, or its parametric knowledge.  

å¤–éƒ¨æ•°æ®æºé€šå¸¸æ˜¯ç‰¹å®šäºä»»åŠ¡çš„ï¼Œå¹¶ä¸”å¯èƒ½è¶…å‡ºæ¨¡å‹çš„åŸå§‹è®­ç»ƒæ•°æ®æˆ–å…¶å‚æ•°çŸ¥è¯†çš„èŒƒå›´ã€‚  

Furthermore, they are often stored in vector databases and can vary widely in topic and format.  

æ­¤å¤–ï¼Œå®ƒä»¬é€šå¸¸å­˜å‚¨åœ¨çŸ¢é‡æ•°æ®åº“ä¸­ï¼Œå¹¶ä¸”åœ¨ä¸»é¢˜å’Œæ ¼å¼ä¸Šå¯èƒ½ä¼šæœ‰å¾ˆå¤§å·®å¼‚ã€‚

Popular sources of external data include internal company databases, legal codes and documents, medical and scientific literature, and scraped webpages.  

å¤–éƒ¨æ•°æ®çš„å¸¸ç”¨æ¥æºåŒ…æ‹¬å…¬å¸å†…éƒ¨æ•°æ®åº“ã€æ³•å¾‹ä»£ç å’Œæ–‡æ¡£ã€åŒ»å­¦å’Œç§‘å­¦æ–‡çŒ®ä»¥åŠæŠ“å–çš„ç½‘é¡µã€‚  

Private data sources can be used in RAG as well.  

ç§æœ‰æ•°æ®æºä¹Ÿå¯ä»¥åœ¨ RAG ä¸­ä½¿ç”¨ã€‚  

Personal AI assistants, like Microsoftâ€™s Copilot, leverage multiple sources of personal data including, emails, documents, and instant messages to provide tailored responses and automate tasks more efficiently.  

ä¸ªäºº AI åŠ©æ‰‹ï¼ˆå¦‚ Microsoft çš„ Copilotï¼‰åˆ©ç”¨å¤šä¸ªä¸ªäººæ•°æ®æ¥æºï¼ˆåŒ…æ‹¬ç”µå­é‚®ä»¶ã€æ–‡æ¡£å’Œå³æ—¶æ¶ˆæ¯ï¼‰æ¥æä¾›é‡èº«å®šåˆ¶çš„å“åº”å¹¶æ›´é«˜æ•ˆåœ°è‡ªåŠ¨æ‰§è¡Œä»»åŠ¡ã€‚

### Prompt template[](https://weaviate.io/blog/introduction-to-rag#prompt-template "Direct link to Prompt template")  

æç¤ºæ¨¡æ¿[](https://weaviate.io/blog/introduction-to-rag#prompt-template "Direct link to Prompt template")

Prompts are the tools we use to communicate our requests to generative models.  

æç¤ºæ˜¯æˆ‘ä»¬ç”¨æ¥å°†è¯·æ±‚ä¼ è¾¾ç»™ç”Ÿæˆæ¨¡å‹çš„å·¥å…·ã€‚  

Prompts may contain several elements, but generally include a query, instructions, and context that guides the model in generating a relevant response.  

æç¤ºå¯èƒ½åŒ…å«å¤šä¸ªå…ƒç´ ï¼Œä½†é€šå¸¸åŒ…æ‹¬æŒ‡å¯¼æ¨¡å‹ç”Ÿæˆç›¸å…³å“åº”çš„æŸ¥è¯¢ã€è¯´æ˜å’Œä¸Šä¸‹æ–‡ã€‚

**Prompt templates** provide a structured way to generate standardized prompts, in which various queries and contexts can be inserted.  

**æç¤ºæ¨¡æ¿**æä¾›äº†ä¸€ç§ç”Ÿæˆæ ‡å‡†åŒ–æç¤ºçš„ç»“æ„åŒ–æ–¹æ³•ï¼Œå…¶ä¸­å¯ä»¥æ’å…¥å„ç§æŸ¥è¯¢å’Œä¸Šä¸‹æ–‡ã€‚  

In a RAG pipeline, relevant data is retrieved from an external data source and inserted into prompt templates, thus augmenting the prompt.  

åœ¨ RAG ç®¡é“ä¸­ï¼Œä»å¤–éƒ¨æ•°æ®æºæ£€ç´¢ç›¸å…³æ•°æ®å¹¶å°†å…¶æ’å…¥åˆ°æç¤ºæ¨¡æ¿ä¸­ï¼Œä»è€Œå¢å¼ºæç¤ºã€‚  

Essentially, prompt templates act as the bridge between the external data and the model, providing the model with contextually relevant information during inference to generate an accurate response.  

ä»æœ¬è´¨ä¸Šè®²ï¼Œæç¤ºæ¨¡æ¿å……å½“å¤–éƒ¨æ•°æ®å’Œæ¨¡å‹ä¹‹é—´çš„æ¡¥æ¢ï¼Œåœ¨æ¨ç†è¿‡ç¨‹ä¸­ä¸ºæ¨¡å‹æä¾›ä¸Šä¸‹æ–‡ç›¸å…³ä¿¡æ¯ï¼Œä»¥ç”Ÿæˆå‡†ç¡®çš„å“åº”ã€‚

```
prompt_template = "Context information is below.\n"                  "---------------------\n"                  "{context_str}\n"                  "---------------------\n"                  "Given the context information and not prior knowledge, "                  "answer the query.\n"                  "Query: {query_str}\n"                  "Answer: "
```

### Generative large language model (LLM)[](https://weaviate.io/blog/introduction-to-rag#generative-large-language-model-llm "Direct link to Generative large language model (LLM)")  

ç”Ÿæˆå¼å¤§å‹è¯­è¨€æ¨¡å‹ ï¼ˆLLMï¼‰[](https://weaviate.io/blog/introduction-to-rag#generative-large-language-model-llm "Direct link to Generative large language model (LLM)")

The final component in RAG is the generative LLM, or generative model, which is used to generate a final response to the userâ€™s query.  

RAG ä¸­çš„æœ€åä¸€ä¸ªç»„ä»¶æ˜¯ç”Ÿæˆå¼ LLM æˆ–ç”Ÿæˆæ¨¡å‹ï¼Œç”¨äºç”Ÿæˆå¯¹ç”¨æˆ·æŸ¥è¯¢çš„æœ€ç»ˆå“åº”ã€‚  

The augmented prompt, enriched with information from the external knowledge base, is sent to the model, which generates a response that combines the model's internal knowledge with the newly retrieved data.  

å¢å¼ºçš„æç¤ºï¼ˆæ‰©å……äº†æ¥è‡ªå¤–éƒ¨çŸ¥è¯†åº“çš„ä¿¡æ¯ï¼‰å°†å‘é€åˆ°æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä¼šç”Ÿæˆä¸€ä¸ªå“åº”ï¼Œå°†æ¨¡å‹çš„å†…éƒ¨çŸ¥è¯†ä¸æ–°æ£€ç´¢çš„æ•°æ®ç›¸ç»“åˆã€‚

Now that weâ€™ve covered the RAG architecture and its key components, letâ€™s see how they come together in a RAG workflow.  

ç°åœ¨æˆ‘ä»¬å·²ç»ä»‹ç»äº† RAG æ¶æ„åŠå…¶å…³é”®ç»„ä»¶ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹å®ƒä»¬å¦‚ä½•åœ¨ RAG å·¥ä½œæµç¨‹ä¸­ç»„åˆåœ¨ä¸€èµ·ã€‚

## How does RAG work?[](https://weaviate.io/blog/introduction-to-rag#how-does-rag-work "Direct link to How does RAG work?")  

RAG å¦‚ä½•è¿ä½œï¼Ÿ[](https://weaviate.io/blog/introduction-to-rag#how-does-rag-work "Direct link to How does RAG work?")

RAG is a multi-step framework that works in two stages.  

RAG æ˜¯ä¸€ä¸ªå¤šæ­¥éª¤æ¡†æ¶ï¼Œåˆ†ä¸¤ä¸ªé˜¶æ®µå·¥ä½œã€‚  

First, the external knowledge is preprocessed and prepared for retrieval during the ingestion stage.  

é¦–å…ˆï¼Œå¯¹å¤–éƒ¨çŸ¥è¯†è¿›è¡Œé¢„å¤„ç†ï¼Œå¹¶å‡†å¤‡åœ¨æ‘„å–é˜¶æ®µè¿›è¡Œæ£€ç´¢ã€‚  

Next, during the inference stage, the model retrieves relevant data from the external knowledge base, augments it with the userâ€™s prompt, and generates a response.  

æ¥ä¸‹æ¥ï¼Œåœ¨æ¨ç†é˜¶æ®µï¼Œæ¨¡å‹ä»å¤–éƒ¨çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³æ•°æ®ï¼Œä½¿ç”¨ç”¨æˆ·çš„æç¤ºå¯¹å…¶è¿›è¡Œæ‰©å……ï¼Œå¹¶ç”Ÿæˆå“åº”ã€‚  

Now, letâ€™s take a closer look at each of these stages.  

ç°åœ¨ï¼Œè®©æˆ‘ä»¬ä»”ç»†çœ‹çœ‹è¿™äº›é˜¶æ®µä¸­çš„æ¯ä¸€ä¸ªã€‚

### Stage 1: Ingestion[](https://weaviate.io/blog/introduction-to-rag#stage-1-ingestion "Direct link to Stage 1: Ingestion")  

ç¬¬ 1 é˜¶æ®µï¼šæ‘„å…¥[](https://weaviate.io/blog/introduction-to-rag#stage-1-ingestion "Direct link to Stage 1: Ingestion")

First, the external knowledge source needs to be prepared.  

é¦–å…ˆï¼Œéœ€è¦å‡†å¤‡å¤–éƒ¨çŸ¥è¯†æºã€‚  

Essentially, the external data needs to be cleaned and transformed into a format that the model can understand.  

ä»æœ¬è´¨ä¸Šè®²ï¼Œéœ€è¦æ¸…ç†å¤–éƒ¨æ•°æ®å¹¶å°†å…¶è½¬æ¢ä¸ºæ¨¡å‹å¯ä»¥ç†è§£çš„æ ¼å¼ã€‚  

This is called the **ingestion stage**. During ingestion, text or image data is transformed from its raw format into **embeddings** through a process called **vectorization**.  

è¿™ç§°ä¸º **æ‘„å–é˜¶æ®µ**ã€‚åœ¨æ‘„å–è¿‡ç¨‹ä¸­ï¼Œæ–‡æœ¬æˆ–å›¾åƒæ•°æ®é€šè¿‡ç§°ä¸º**çŸ¢é‡åŒ–**çš„è¿‡ç¨‹ä»å…¶åŸå§‹æ ¼å¼è½¬æ¢ä¸º**åµŒå…¥**ã€‚  

Once embeddings are generated, they need to be stored in a manner that allows them to be retrieved at a later time.  

ç”ŸæˆåµŒå…¥åï¼Œéœ€è¦ä»¥å…è®¸ä»¥åæ£€ç´¢çš„æ–¹å¼å­˜å‚¨å®ƒä»¬ã€‚  

Most commonly, these embeddings are stored in a vector database, which allows for quick, efficient retrieval of the information for downstream tasks.  

æœ€å¸¸è§çš„æ˜¯ï¼Œè¿™äº›åµŒå…¥å­˜å‚¨åœ¨å‘é‡æ•°æ®åº“ä¸­ï¼Œè¿™æ ·å¯ä»¥å¿«é€Ÿã€é«˜æ•ˆåœ°æ£€ç´¢ä¸‹æ¸¸ä»»åŠ¡çš„ä¿¡æ¯ã€‚

![RAG Stages](rag-stages-45d8aee75a171f635017ba9a2d25abdb.png "RAG Stages")

### Stage 2: Inference[](https://weaviate.io/blog/introduction-to-rag#stage-2-inference "Direct link to Stage 2: Inference")  

ç¬¬ 2 é˜¶æ®µï¼šæ¨ç†[](https://weaviate.io/blog/introduction-to-rag#stage-2-inference "Direct link to Stage 2: Inference")

After external data is encoded and stored, itâ€™s ready to be retrieved during **inference**, when the model generates a response or answers a question.  

å¯¹å¤–éƒ¨æ•°æ®è¿›è¡Œç¼–ç å’Œå­˜å‚¨åï¼Œå½“æ¨¡å‹ç”Ÿæˆå“åº”æˆ–å›ç­”é—®é¢˜æ—¶ï¼Œå°±å¯ä»¥åœ¨**æ¨ç†**æœŸé—´æ£€ç´¢è¿™äº›æ•°æ®ã€‚  

Inference is broken down into three steps: retrieval, augmentation, and generation.  

æ¨ç†åˆ†ä¸ºä¸‰ä¸ªæ­¥éª¤ï¼šæ£€ç´¢ã€å¢å¼ºå’Œç”Ÿæˆã€‚

![RAG Workflow](rag-workflow-22477c7cae9124df5716d6b93b93875d.png "RAG Workflow")

#### Retrieval[](https://weaviate.io/blog/introduction-to-rag#retrieval "Direct link to Retrieval")  

æ£€ç´¢[](https://weaviate.io/blog/introduction-to-rag#retrieval "Direct link to Retrieval")

The inference stage starts with retrieval, in which data is retrieved from an external knowledge source in relation to a user query.  

æ¨ç†é˜¶æ®µä»æ£€ç´¢å¼€å§‹ï¼Œåœ¨è¯¥é˜¶æ®µï¼Œä»ä¸ç”¨æˆ·æŸ¥è¯¢ç›¸å…³çš„å¤–éƒ¨æ•°æ®æºæ£€ç´¢æ•°æ®ã€‚  

Retrieval methods vary in format and complexity, however in the naive RAG schema, in which external knowledge is embedded and stored in a vector database, similarity search is the simplest form of retrieval.  

æ£€ç´¢æ–¹æ³•çš„æ ¼å¼å’Œå¤æ‚æ€§å„ä¸ç›¸åŒï¼Œä½†æ˜¯åœ¨ç®€å•çš„ RAG æ¨¡å¼ä¸­ï¼Œå¤–éƒ¨çŸ¥è¯†è¢«åµŒå…¥å¹¶å­˜å‚¨åœ¨å‘é‡æ•°æ®åº“ä¸­ï¼Œç›¸ä¼¼æ€§æœç´¢æ˜¯æœ€ç®€å•çš„æ£€ç´¢å½¢å¼ã€‚

To perform similarity search, the user query must be first embedded in the same multi-dimensional space as the external data, which allows for direct comparison between the query and embedded external data.  

è¦æ‰§è¡Œç›¸ä¼¼æ€§æœç´¢ï¼Œå¿…é¡»é¦–å…ˆå°†ç”¨æˆ·æŸ¥è¯¢åµŒå…¥åˆ°ä¸å¤–éƒ¨æ•°æ®ç›¸åŒçš„å¤šç»´ç©ºé—´ä¸­ï¼Œè¿™æ ·å°±å¯ä»¥åœ¨æŸ¥è¯¢å’ŒåµŒå…¥çš„å¤–éƒ¨æ•°æ®ä¹‹é—´è¿›è¡Œç›´æ¥æ¯”è¾ƒã€‚  

During [**similarity search**](https://weaviate.io/developers/weaviate/search/similarity), the distance between the query and external data points is calculated, returning those with the shortest distance and completing the retrieval process.  

åœ¨[**ç›¸ä¼¼æ€§æœç´¢**](https://weaviate.io/developers/weaviate/search/similarity)æœŸé—´ï¼Œå°†è®¡ç®—æŸ¥è¯¢ä¸å¤–éƒ¨æ•°æ®ç‚¹ä¹‹é—´çš„è·ç¦»ï¼Œè¿”å›è·ç¦»æœ€çŸ­çš„æ•°æ®ç‚¹å¹¶å®Œæˆæ£€ç´¢è¿‡ç¨‹ã€‚

#### Augmentation[](https://weaviate.io/blog/introduction-to-rag#augmentation "Direct link to Augmentation")  

å¢å¤§[](https://weaviate.io/blog/introduction-to-rag#augmentation "Direct link to Augmentation")

Once the most relevant data points from the external data source have been retrieved, the augmentation process integrates this external information by inserting it into a predefined prompt template.  

ä»å¤–éƒ¨æ•°æ®æºä¸­æ£€ç´¢åˆ°æœ€ç›¸å…³çš„æ•°æ®ç‚¹åï¼Œæ‰©å……è¿‡ç¨‹ä¼šé€šè¿‡å°†æ­¤å¤–éƒ¨ä¿¡æ¯æ’å…¥åˆ°é¢„å®šä¹‰çš„æç¤ºæ¨¡æ¿ä¸­æ¥é›†æˆè¿™äº›ä¿¡æ¯ã€‚

#### Generation[](https://weaviate.io/blog/introduction-to-rag#generation "Direct link to Generation")  

ä»£[](https://weaviate.io/blog/introduction-to-rag#generation "Direct link to Generation")

After the augmented prompt is injected into the modelâ€™s context window, it proceeds to generate the final response to the userâ€™s prompt.  

å°†å¢å¼ºçš„æç¤ºæ³¨å…¥æ¨¡å‹çš„ä¸Šä¸‹æ–‡çª—å£åï¼Œå®ƒå°†ç»§ç»­ç”Ÿæˆå¯¹ç”¨æˆ·æç¤ºçš„æœ€ç»ˆå“åº”ã€‚  

In the generation phase, the model combines both its internal language understanding and the augmented external data to produce a coherent, contextually appropriate answer.  

åœ¨ç”Ÿæˆé˜¶æ®µï¼Œè¯¥æ¨¡å‹å°†å…¶å†…éƒ¨è¯­è¨€ç†è§£å’Œå¢å¼ºçš„å¤–éƒ¨æ•°æ®ç›¸ç»“åˆï¼Œä»¥ç”Ÿæˆè¿è´¯çš„ã€ä¸Šä¸‹æ–‡é€‚å½“çš„ç­”æ¡ˆã€‚

This step involves crafting the response in a fluent, natural manner while drawing on the enriched information to ensure that the output is both accurate and relevant to the user's query.  

æ­¤æ­¥éª¤æ¶‰åŠä»¥æµç•…ã€è‡ªç„¶çš„æ–¹å¼åˆ¶ä½œå“åº”ï¼ŒåŒæ—¶åˆ©ç”¨ä¸°å¯Œçš„ä¿¡æ¯ï¼Œä»¥ç¡®ä¿è¾“å‡ºå‡†ç¡®ä¸”ä¸ç”¨æˆ·çš„æŸ¥è¯¢ç›¸å…³ã€‚  

While augmentation is about incorporating external facts, generation is about transforming that combined knowledge into a well-formed, human-like output tailored to the specific request.  

å¢å¼ºæ˜¯å…³äºæ•´åˆå¤–éƒ¨äº‹å®ï¼Œè€Œç”Ÿæˆæ˜¯å°†ç»„åˆçš„çŸ¥è¯†è½¬åŒ–ä¸ºæ ¹æ®ç‰¹å®šè¯·æ±‚é‡èº«å®šåˆ¶çš„æ ¼å¼è‰¯å¥½çš„ã€ç±»ä¼¼äººç±»çš„è¾“å‡ºã€‚

## RAG use cases[](https://weaviate.io/blog/introduction-to-rag#rag-use-cases "Direct link to RAG use cases")  

RAG ä½¿ç”¨æ¡ˆä¾‹[](https://weaviate.io/blog/introduction-to-rag#rag-use-cases "Direct link to RAG use cases")

Now that weâ€™ve covered what RAG is, how it works, and its architecture, letâ€™s explore some practical use cases to see how this framework is applied in real-world scenarios.  

ç°åœ¨æˆ‘ä»¬å·²ç»ä»‹ç»äº† RAG æ˜¯ä»€ä¹ˆã€å®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ä»¥åŠå®ƒçš„æ¶æ„ï¼Œè®©æˆ‘ä»¬æ¢ç´¢ä¸€äº›å®é™…ç”¨ä¾‹ï¼Œçœ‹çœ‹è¿™ä¸ªæ¡†æ¶æ˜¯å¦‚ä½•åº”ç”¨äºå®é™…åœºæ™¯çš„ã€‚  

Augmenting generative LLMs with up-to-date, task-specific data boosts their accuracy, relevance, and ability to handle specialized tasks.  

ä½¿ç”¨æœ€æ–°çš„ç‰¹å®šäºä»»åŠ¡çš„æ•°æ®æ¥å¢å¼ºç”Ÿæˆå¼ LLMsï¼‰ å¯ä»¥æé«˜å…¶å‡†ç¡®æ€§ã€ç›¸å…³æ€§å’Œå¤„ç†ä¸“ä¸šä»»åŠ¡çš„èƒ½åŠ›ã€‚  

Consequently, RAG is widely used for real-time information retrieval, creating content recommendation systems, and building personal AI assistants.  

å› æ­¤ï¼ŒRAG å¹¿æ³›ç”¨äºå®æ—¶ä¿¡æ¯æ£€ç´¢ã€åˆ›å»ºå†…å®¹æ¨èç³»ç»Ÿå’Œæ„å»ºä¸ªäºº AI åŠ©æ‰‹ã€‚

### Real-time information retrieval[](https://weaviate.io/blog/introduction-to-rag#real-time-information-retrieval "Direct link to Real-time information retrieval")  

å®æ—¶ä¿¡æ¯æ£€ç´¢[](https://weaviate.io/blog/introduction-to-rag#real-time-information-retrieval "Direct link to Real-time information retrieval")

When used alone, generative models are limited to retrieving only information found in their training dataset.  

å•ç‹¬ä½¿ç”¨æ—¶ï¼Œç”Ÿæˆæ¨¡å‹ä»…é™äºæ£€ç´¢åœ¨å…¶è®­ç»ƒæ•°æ®é›†ä¸­æ‰¾åˆ°çš„ä¿¡æ¯ã€‚  

When used in the context of RAG, however, these models can retrieve data and information from external sources, ensuring more accurate and up-to-date responses.  

ä½†æ˜¯ï¼Œå½“åœ¨ RAG ä¸Šä¸‹æ–‡ä¸­ä½¿ç”¨æ—¶ï¼Œè¿™äº›æ¨¡å‹å¯ä»¥ä»å¤–éƒ¨æ¥æºæ£€ç´¢æ•°æ®å’Œä¿¡æ¯ï¼Œä»è€Œç¡®ä¿æ›´å‡†ç¡®å’Œæœ€æ–°çš„å“åº”ã€‚  

One such example is ChatGPT-4oâ€™s ability to access and retrieve information directly from the web in real-time.  

ä¸€ä¸ªè¿™æ ·çš„ä¾‹å­æ˜¯ ChatGPT-4o ç›´æ¥ä»ç½‘ç»œå®æ—¶è®¿é—®å’Œæ£€ç´¢ä¿¡æ¯çš„èƒ½åŠ›ã€‚  

This is an example of a RAG use case that leverages an external data source that is _not_ embedded in a vector database and can be especially useful in responding to user queries regarding the news or other current events, such as stock prices, travel advisories, and weather updates.  

è¿™æ˜¯ä¸€ä¸ª RAG ä½¿ç”¨æ¡ˆä¾‹ç¤ºä¾‹ï¼Œå®ƒåˆ©ç”¨_æœª_åµŒå…¥çŸ¢é‡æ•°æ®åº“ä¸­çš„å¤–éƒ¨æ•°æ®æºï¼Œåœ¨å“åº”ç”¨æˆ·æœ‰å…³æ–°é—»æˆ–å…¶ä»–æ—¶äº‹ï¼ˆå¦‚è‚¡ç¥¨ä»·æ ¼ã€æ—…è¡Œå»ºè®®å’Œå¤©æ°”æ›´æ–°ï¼‰çš„æŸ¥è¯¢æ—¶ç‰¹åˆ«æœ‰ç”¨ã€‚

### Content recommendation systems[](https://weaviate.io/blog/introduction-to-rag#content-recommendation-systems "Direct link to Content recommendation systems")  

å†…å®¹æ¨èç³»ç»Ÿ[](https://weaviate.io/blog/introduction-to-rag#content-recommendation-systems "Direct link to Content recommendation systems")

Content recommendation systems analyze user data and preferences to suggest relevant products or content to users.  

å†…å®¹æ¨èç³»ç»Ÿåˆ†æç”¨æˆ·æ•°æ®å’Œåå¥½ï¼Œä»¥å‘ç”¨æˆ·æ¨èç›¸å…³çš„äº§å“æˆ–å†…å®¹ã€‚  

Traditionally, these systems required sophisticated ensemble models and massive user preference datasets.  

ä¼ ç»Ÿä¸Šï¼Œè¿™äº›ç³»ç»Ÿéœ€è¦å¤æ‚çš„é›†æˆæ¨¡å‹å’Œå¤§é‡çš„ç”¨æˆ·åå¥½æ•°æ®é›†ã€‚  

RAG simplifies recommendation systems directly integrating external, contextually relevant user data with the model's general knowledge, allowing it to generate personalized recommendations.  

RAG ç®€åŒ–äº†æ¨èç³»ç»Ÿï¼Œå°†å¤–éƒ¨çš„ä¸Šä¸‹æ–‡ç›¸å…³ç”¨æˆ·æ•°æ®ä¸æ¨¡å‹çš„ä¸€èˆ¬çŸ¥è¯†ç›´æ¥é›†æˆï¼Œä½¿å…¶èƒ½å¤Ÿç”Ÿæˆä¸ªæ€§åŒ–æ¨èã€‚

### Personal AI assistants[](https://weaviate.io/blog/introduction-to-rag#personal-ai-assistants "Direct link to Personal AI assistants")  

ä¸ªäºº AI åŠ©æ‰‹[](https://weaviate.io/blog/introduction-to-rag#personal-ai-assistants "Direct link to Personal AI assistants")

Our personal data, including files, emails, Slack messages, and notes are a valuable source of data for generative models.  

æˆ‘ä»¬çš„ä¸ªäººæ•°æ®ï¼ˆåŒ…æ‹¬æ–‡ä»¶ã€ç”µå­é‚®ä»¶ã€Slack æ¶ˆæ¯å’Œç¬”è®°ï¼‰æ˜¯ç”Ÿæˆæ¨¡å‹çš„å®è´µæ•°æ®æºã€‚  

Running RAG over our personal data enables us to interact with it in a conversational way, increasing efficiency and allowing for the automation of mundane tasks.  

å¯¹æˆ‘ä»¬çš„ä¸ªäººæ•°æ®è¿è¡Œ RAG ä½¿æˆ‘ä»¬èƒ½å¤Ÿä»¥å¯¹è¯æ–¹å¼ä¸ä¹‹äº¤äº’ï¼Œä»è€Œæé«˜æ•ˆç‡å¹¶å…è®¸æ—¥å¸¸ä»»åŠ¡çš„è‡ªåŠ¨åŒ–ã€‚  

With AI assistants, such as Microsoftâ€™s Copilot and Notionâ€™s Ask AI, we can use simple prompts to search for relevant documents, write personalized emails, summarize documents and meeting notes, schedule meetings, and more.  

å€ŸåŠ© AI åŠ©æ‰‹ï¼Œä¾‹å¦‚ Microsoft çš„ Copilot å’Œ Notion çš„ Ask AIï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç®€å•çš„æç¤ºæ¥æœç´¢ç›¸å…³æ–‡æ¡£ã€ç¼–å†™ä¸ªæ€§åŒ–ç”µå­é‚®ä»¶ã€æ€»ç»“æ–‡æ¡£å’Œä¼šè®®è®°å½•ã€å®‰æ’ä¼šè®®ç­‰ã€‚

## How to implement RAG[](https://weaviate.io/blog/introduction-to-rag#how-to-implement-rag "Direct link to How to implement RAG")  

å¦‚ä½•å®æ–½ RAG[](https://weaviate.io/blog/introduction-to-rag#how-to-implement-rag "Direct link to How to implement RAG")

Now that we know how RAG works, letâ€™s explore how to build a functional RAG pipeline.  

ç°åœ¨æˆ‘ä»¬çŸ¥é“äº† RAG çš„å·¥ä½œåŸç†ï¼Œè®©æˆ‘ä»¬æ¢ç´¢å¦‚ä½•æ„å»ºåŠŸèƒ½æ€§ RAG ç®¡é“ã€‚  

RAG can be implemented through a number of different frameworks, which simplify the building process by providing pre-built tools and modules for integrating individual RAG components as well as external services like vector databases, embedding generation tools, and other APIs.  

RAG å¯ä»¥é€šè¿‡è®¸å¤šä¸åŒçš„æ¡†æ¶æ¥å®ç°ï¼Œè¿™äº›æ¡†æ¶é€šè¿‡æä¾›é¢„æ„å»ºçš„å·¥å…·å’Œæ¨¡å—æ¥é›†æˆå„ä¸ª RAG ç»„ä»¶ä»¥åŠçŸ¢é‡æ•°æ®åº“ã€åµŒå…¥ç”Ÿæˆå·¥å…·å’Œå…¶ä»– API ç­‰å¤–éƒ¨æœåŠ¡ï¼Œä»è€Œç®€åŒ–æ„å»ºè¿‡ç¨‹ã€‚

LangChain, LlamaIndex, and DSPy are all robust open source Python libraries with highly engaged communities that offer powerful tools and integrations for building and optimizing RAG pipelines and LLM applications.  

LangChainã€LlamaIndex å’Œ DSPy éƒ½æ˜¯å¼ºå¤§çš„å¼€æº Python åº“ï¼Œæ‹¥æœ‰é«˜åº¦å‚ä¸çš„ç¤¾åŒºï¼Œä¸ºæ„å»ºå’Œä¼˜åŒ– RAG ç®¡é“å’Œ LLMã€‚

-   [**LangChain**](https://www.langchain.com/) provides building blocks, components, and third-party integrations to aid in the development of LLM-powered applications.  
    
    [**LangChain**](https://www.langchain.com/) æä¾›æ„å»ºå—ã€ç»„ä»¶å’Œç¬¬ä¸‰æ–¹é›†æˆï¼Œä»¥å¸®åŠ©å¼€å‘ LLM é©±åŠ¨çš„åº”ç”¨ç¨‹åºã€‚  
    
    It can be used with [LangGraph](https://langchain-ai.github.io/langgraph/tutorials/introduction/) for building agentic RAG pipelines and [LangSmith](https://docs.smith.langchain.com/) for RAG evaluation.  
    
    å®ƒå¯ä»¥ä¸ [LangGraph](https://langchain-ai.github.io/langgraph/tutorials/introduction/) ä¸€èµ·ç”¨äºæ„å»ºä»£ç† RAG ç®¡é“ï¼Œä¸ [LangSmith](https://docs.smith.langchain.com/) ä¸€èµ·ç”¨äº RAG è¯„ä¼°ã€‚
-   [**LlamaIndex**](https://www.llamaindex.ai/) is a framework that offers tools to build LLM-powered applications integrated with external data sources.  
    
    [**LlamaIndex**](https://www.llamaindex.ai/) æ˜¯ä¸€ä¸ªæ¡†æ¶ï¼Œå®ƒæä¾›å·¥å…·æ¥æ„å»ºä¸å¤–éƒ¨æ•°æ®æºé›†æˆçš„ LLM é©±åŠ¨çš„åº”ç”¨ç¨‹åºã€‚  
    
    LlamaIndex maintains the [LlamaHub](https://llamahub.ai/), a rich repository of data loaders, agent tools, datasets, and other components, that streamline the creation of RAG pipelines.  
    
    LlamaIndex ç»´æŠ¤ [LlamaHub](https://llamahub.ai/)ï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«æ•°æ®åŠ è½½å™¨ã€ä»£ç†å·¥å…·ã€æ•°æ®é›†å’Œå…¶ä»–ç»„ä»¶çš„ä¸°å¯Œå­˜å‚¨åº“ï¼Œå¯ç®€åŒ– RAG ç®¡é“çš„åˆ›å»ºã€‚
-   [**DSPy**](https://dspy-docs.vercel.app/) is a modular framework for optimizing LLM pipelines.  
    
    [**DSPy**](https://dspy-docs.vercel.app/) æ˜¯ä¸€ä¸ªæ¨¡å—åŒ–æ¡†æ¶ï¼Œç”¨äºä¼˜åŒ– LLM ç®¡é“ã€‚  
    
    Both LLMs and RMs (Retrieval Models) can be configured within DSPy, allowing for seamless optimization of RAG pipelines.  
    
    LLMs å’Œ RMï¼ˆæ£€ç´¢æ¨¡å‹ï¼‰éƒ½å¯ä»¥åœ¨ DSPy ä¸­é…ç½®ï¼Œä»è€Œå®ç° RAG ç®¡é“çš„æ— ç¼ä¼˜åŒ–ã€‚

note  

æ³¨æ„

Weaviate provides [integrations](https://weaviate.io/developers/integrations) and [recipes](https://github.com/weaviate/recipes) for each of these frameworks.  

Weaviate ä¸ºæ¯ä¸ªæ¡†æ¶æä¾›[é›†æˆ](https://weaviate.io/developers/integrations)å’Œ[é…æ–¹](https://github.com/weaviate/recipes)ã€‚  

For specific examples, take a look at our notebooks that show how to build RAG pipelines with Weaviate and [LlamaIndex](https://github.com/weaviate/recipes/blob/main/integrations/llm-frameworks/llamaindex/retrieval-augmented-generation/naive_rag.ipynb) and [DSPy](https://github.com/weaviate/recipes/blob/main/integrations/llm-frameworks/dspy/1.Getting-Started-with-RAG-in-DSPy.ipynb).  

æœ‰å…³å…·ä½“ç¤ºä¾‹ï¼Œè¯·æŸ¥çœ‹æˆ‘ä»¬çš„ç¬”è®°æœ¬ï¼Œå…¶ä¸­å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ Weaviateã€[LlamaIndex](https://github.com/weaviate/recipes/blob/main/integrations/llm-frameworks/llamaindex/retrieval-augmented-generation/naive_rag.ipynb) å’Œ [DSPy](https://github.com/weaviate/recipes/blob/main/integrations/llm-frameworks/dspy/1.Getting-Started-with-RAG-in-DSPy.ipynb) æ„å»º RAG ç®¡é“ã€‚

If youâ€™re looking for a way to get up and running with RAG quickly, check out [**Verba**](https://github.com/weaviate/Verba), an open source out-of-the-box RAG application with a shiny, pre-built frontend.  

å¦‚æœæ‚¨æ­£åœ¨å¯»æ‰¾ä¸€ç§å¿«é€Ÿå¯åŠ¨å’Œè¿è¡Œ RAG çš„æ–¹æ³•ï¼Œè¯·æŸ¥çœ‹ [**Verba**](https://github.com/weaviate/Verba)ï¼Œè¿™æ˜¯ä¸€æ¬¾å¼€ç®±å³ç”¨çš„å¼€æº RAG åº”ç”¨ç¨‹åºï¼Œå…·æœ‰é—ªäº®çš„é¢„æ„å»ºå‰ç«¯ã€‚  

Verba enables you to visually explore datasets, extract insights, and build customizable RAG pipelines in just a few easy steps, without having to learn an entirely new framework.  

Verba ä½¿æ‚¨èƒ½å¤Ÿé€šè¿‡å‡ ä¸ªç®€å•çš„æ­¥éª¤ç›´è§‚åœ°æ¢ç´¢æ•°æ®é›†ã€æå–è§è§£å¹¶æ„å»ºå¯å®šåˆ¶çš„ RAG ç®¡é“ï¼Œè€Œæ— éœ€å­¦ä¹ å…¨æ–°çš„æ¡†æ¶ã€‚  

Verba is a multifunctional tool that can be used as a playground for testing and experimenting with RAG pipelines as well as for personal tasks like assisting with research, analyzing internal documents, and streamlining various RAG-related tasks.  

Verba æ˜¯ä¸€ç§å¤šåŠŸèƒ½å·¥å…·ï¼Œå¯ä»¥ç”¨ä½œæµ‹è¯•å’Œè¯•éªŒ RAG ç®¡é“ä»¥åŠä¸ªäººä»»åŠ¡çš„æ¸¸ä¹åœºï¼Œä¾‹å¦‚ååŠ©ç ”ç©¶ã€åˆ†æå†…éƒ¨æ–‡æ¡£å’Œç®€åŒ–å„ç§ä¸ RAG ç›¸å…³çš„ä»»åŠ¡ã€‚

Your browser does not support the video tag.  

æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒ video æ ‡ç­¾ã€‚

Out-of-the-box RAG implementation with Verba  

ä½¿ç”¨ Verba å®ç°å¼€ç®±å³ç”¨çš„ RAG

## RAG techniques[](https://weaviate.io/blog/introduction-to-rag#rag-techniques "Direct link to RAG techniques")  

RAG æŠ€æœ¯[](https://weaviate.io/blog/introduction-to-rag#rag-techniques "Direct link to RAG techniques")

The vanilla RAG workflow is generally composed of an external data source embedded in a vector database retrieved via similarity search.  

åŸç‰ˆ RAG å·¥ä½œæµé€šå¸¸ç”±åµŒå…¥åœ¨å‘é‡æ•°æ®åº“ä¸­çš„å¤–éƒ¨æ•°æ®æºç»„æˆï¼Œè¯¥æ•°æ®åº“é€šè¿‡ç›¸ä¼¼æ€§æœç´¢æ£€ç´¢ã€‚  

However, there are several ways to enhance RAG workflows to yield more accurate and robust results, which collectively are referred to as advanced RAG.  

ä½†æ˜¯ï¼Œæœ‰å‡ ç§æ–¹æ³•å¯ä»¥å¢å¼º RAG å·¥ä½œæµç¨‹ä»¥äº§ç”Ÿæ›´å‡†ç¡®å’Œå¯é çš„ç»“æœï¼Œè¿™äº›æ–¹æ³•ç»Ÿç§°ä¸ºé«˜çº§ RAGã€‚

Functionality of RAG pipelines can be further extended by incorporating the use of graph databases and agents, which enable even more advanced reasoning and dynamic data retrieval.  

RAG ç®¡é“çš„åŠŸèƒ½å¯ä»¥é€šè¿‡ç»“åˆä½¿ç”¨å›¾å½¢æ•°æ®åº“å’Œä»£ç†æ¥è¿›ä¸€æ­¥æ‰©å±•ï¼Œä»è€Œå®ç°æ›´é«˜çº§çš„æ¨ç†å’ŒåŠ¨æ€æ•°æ®æ£€ç´¢ã€‚  

In this next section, weâ€™ll go over some common advanced RAG techniques and give you an overview of Agentic RAG and Graph RAG.  

åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»ä¸€äº›å¸¸è§çš„é«˜çº§ RAG æŠ€æœ¯ï¼Œå¹¶ä¸ºæ‚¨æä¾› Agentic RAG å’Œ Graph RAG çš„æ¦‚è¿°ã€‚

### Advanced RAG[](https://weaviate.io/blog/introduction-to-rag#advanced-rag "Direct link to Advanced RAG")  

é«˜çº§ RAG[](https://weaviate.io/blog/introduction-to-rag#advanced-rag "Direct link to Advanced RAG")

Advanced RAG techniques can be deployed at various stages in the pipeline.  

é«˜çº§ RAG æŠ€æœ¯å¯ä»¥éƒ¨ç½²åœ¨ç®¡é“çš„å„ä¸ªé˜¶æ®µã€‚  

Pre-retrieval strategies like **metadata filtering** and text **chunking** can help improve the retrieval efficiency and relevance by narrowing down the search space and ensuring only the most relevant sections of data are considered.  

**å…ƒæ•°æ®ç­›é€‰**å’Œæ–‡æœ¬**åˆ†å—**ç­‰é¢„æ£€ç´¢ç­–ç•¥å¯ä»¥é€šè¿‡ç¼©å°æœç´¢ç©ºé—´å¹¶ç¡®ä¿ä»…è€ƒè™‘æœ€ç›¸å…³çš„æ•°æ®éƒ¨åˆ†æ¥å¸®åŠ©æé«˜æ£€ç´¢æ•ˆç‡å’Œç›¸å…³æ€§ã€‚  

Employing more advanced retrieval techniques, such as **hybrid search**, which combines the strengths of similarity search with keyword search, can also yield more robust retrieval results.  

é‡‡ç”¨æ›´é«˜çº§çš„æ£€ç´¢æŠ€æœ¯ï¼Œä¾‹å¦‚**æ··åˆæœç´¢**ï¼Œå®ƒç»“åˆäº†ç›¸ä¼¼æ€§æœç´¢å’Œå…³é”®å­—æœç´¢çš„ä¼˜åŠ¿ï¼Œä¹Ÿå¯ä»¥äº§ç”Ÿæ›´å¼ºå¤§çš„æ£€ç´¢ç»“æœã€‚  

Finally, **re-ranking** retrieved results with a ranker model and using a generative LLM **fine-tuned** on domain-specific data help improve the quality of generated results.  

æœ€åï¼Œä½¿ç”¨æ’åå™¨æ¨¡å‹å¯¹æ£€ç´¢åˆ°çš„ç»“æœ**è¿›è¡Œé‡æ–°æ’å**ï¼Œå¹¶ä½¿ç”¨æ ¹æ®ç‰¹å®šé¢†åŸŸæ•°æ®è¿›è¡Œå¾®è°ƒçš„ç”Ÿæˆå¼ LLMï¼‰ æœ‰åŠ©äºæé«˜ç”Ÿæˆç»“æœçš„è´¨é‡ã€‚

![Advanced RAG](rag-advanced-rag-10422ae0538cb55e5de9660f7cb8271e.png "Advanced RAG")

For a more in-depth exploration of this topic, check out our blog post on [advanced RAG techniques](https://weaviate.io/blog/advanced-rag#3-fine-tuning-embedding-models).  

è¦æ›´æ·±å…¥åœ°æ¢ç´¢è¿™ä¸ªä¸»é¢˜ï¼Œè¯·æŸ¥çœ‹æˆ‘ä»¬å…³äº[é«˜çº§ RAG æŠ€æœ¯çš„](https://weaviate.io/blog/advanced-rag#3-fine-tuning-embedding-models)åšå®¢æ–‡ç« ã€‚

### Agentic RAG[](https://weaviate.io/blog/introduction-to-rag#agentic-rag "Direct link to Agentic RAG")  

ä»£ç† RAG[](https://weaviate.io/blog/introduction-to-rag#agentic-rag "Direct link to Agentic RAG")

**AI agents** are autonomous systems that can interpret information, formulate plans, and make decisions.  

**AI ä»£ç†**æ˜¯å¯ä»¥è§£é‡Šä¿¡æ¯ã€åˆ¶å®šè®¡åˆ’å’Œåšå‡ºå†³ç­–çš„è‡ªä¸»ç³»ç»Ÿã€‚  

When added to a RAG pipeline, agents can reformulate user queries and re-retrieve more relevant information if initial results are inaccurate or irrelevant.  

å½“æ·»åŠ åˆ° RAG ç®¡é“æ—¶ï¼Œå¦‚æœåˆå§‹ç»“æœä¸å‡†ç¡®æˆ–ä¸ç›¸å…³ï¼Œä»£ç†å¯ä»¥é‡æ–°åˆ¶å®šç”¨æˆ·æŸ¥è¯¢å¹¶é‡æ–°æ£€ç´¢æ›´å¤šç›¸å…³ä¿¡æ¯ã€‚  

Agentic RAG can also handle more complex queries that require multi-step reasoning, like comparing information across multiple documents, asking follow-up questions, and iteratively adjusting retrieval and generation strategies.  

Agentic RAG è¿˜å¯ä»¥å¤„ç†éœ€è¦å¤šæ­¥éª¤æ¨ç†çš„æ›´å¤æ‚çš„æŸ¥è¯¢ï¼Œä¾‹å¦‚æ¯”è¾ƒå¤šä¸ªæ–‡æ¡£ä¸­çš„ä¿¡æ¯ã€æå‡ºåç»­é—®é¢˜ä»¥åŠè¿­ä»£è°ƒæ•´æ£€ç´¢å’Œç”Ÿæˆç­–ç•¥ã€‚

To take a closer look at a RAG pipeline that incorporates agents and utilizes advanced techniques like text chunking and reranking, check out this [post](https://www.llamaindex.ai/blog/agentic-rag-with-llamaindex-2721b8a49ff6) and accompanying [notebook](https://github.com/cobusgreyling/LlamaIndex/blob/d8902482a247c76c7902ded143a875d5580f072a/Agentic_RAG_Multi_Document_Agents-v1.ipynb) on the LlamaIndex blog.  

è¦ä»”ç»†äº†è§£åŒ…å«ä»£ç†å¹¶åˆ©ç”¨æ–‡æœ¬åˆ†å—å’Œé‡æ–°æ’åç­‰é«˜çº§æŠ€æœ¯çš„ RAG ç®¡é“ï¼Œè¯·æŸ¥çœ‹ LlamaIndex åšå®¢[ä¸Šçš„è¿™ç¯‡æ–‡ç« å’Œ](https://www.llamaindex.ai/blog/agentic-rag-with-llamaindex-2721b8a49ff6)éšé™„çš„[ç¬”è®°æœ¬](https://github.com/cobusgreyling/LlamaIndex/blob/d8902482a247c76c7902ded143a875d5580f072a/Agentic_RAG_Multi_Document_Agents-v1.ipynb)ã€‚

### Graph RAG[](https://weaviate.io/blog/introduction-to-rag#graph-rag "Direct link to Graph RAG")  

å›¾å½¢ RAG[](https://weaviate.io/blog/introduction-to-rag#graph-rag "Direct link to Graph RAG")

While traditional RAG excels at simple question answering tasks that can be resolved by retrieval alone, it is unable to answer questions and draw conclusions over an _entire_ external knowledge base.  

è™½ç„¶ä¼ ç»Ÿçš„ RAG æ“…é•¿ç®€å•çš„é—®ç­”ä»»åŠ¡ï¼Œè¿™äº›ä»»åŠ¡å¯ä»¥é€šè¿‡å•ç‹¬æ£€ç´¢æ¥è§£å†³ï¼Œä½†å®ƒæ— æ³•_åœ¨æ•´ä¸ªå¤–éƒ¨çŸ¥è¯†åº“_ä¸­å›ç­”é—®é¢˜å¹¶å¾—å‡ºç»“è®ºã€‚  

Graph RAG aims to solve this by using a generative model to create a knowledge graph that extracts and stores the relationships between key entities and can then be added as a data source to the RAG pipeline.  

Graph RAG æ—¨åœ¨é€šè¿‡ä½¿ç”¨ç”Ÿæˆæ¨¡å‹åˆ›å»ºçŸ¥è¯†å›¾è°±æ¥è§£å†³æ­¤é—®é¢˜ï¼Œè¯¥çŸ¥è¯†å›¾è°±æå–å’Œå­˜å‚¨å…³é”®å®ä½“ä¹‹é—´çš„å…³ç³»ï¼Œç„¶åå¯ä»¥ä½œä¸ºæ•°æ®æºæ·»åŠ åˆ° RAG ç®¡é“ä¸­ã€‚  

This enables the RAG system to respond to queries asking to compare and summarize multiple documents and data sources.  

è¿™ä½¿ RAG ç³»ç»Ÿèƒ½å¤Ÿå“åº”è¯·æ±‚æ¯”è¾ƒå’Œæ±‡æ€»å¤šä¸ªæ–‡æ¡£å’Œæ•°æ®æºçš„æŸ¥è¯¢ã€‚

For more information on building graph RAG pipelines, take a look at Microsoftâ€™s GraphRAG [package](https://github.com/microsoft/graphrag/tree/main?tab=readme-ov-file) and [documentation](https://microsoft.github.io/graphrag/).  

æœ‰å…³æ„å»ºå›¾å½¢ RAG ç®¡é“çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹ Microsoft çš„ GraphRAG [åŒ…](https://github.com/microsoft/graphrag/tree/main?tab=readme-ov-file)å’Œ[æ–‡æ¡£](https://microsoft.github.io/graphrag/)ã€‚

## How to evaluate RAG[](https://weaviate.io/blog/introduction-to-rag#how-to-evaluate-rag "Direct link to How to evaluate RAG")  

å¦‚ä½•è¯„ä¼° RAG[](https://weaviate.io/blog/introduction-to-rag#how-to-evaluate-rag "Direct link to How to evaluate RAG")

RAG is a multi-stage, multi-step framework that requires both holistic and granular [evaluation](https://weaviate.io/blog/rag-evaluation). This approach ensures both component-level reliability and high-level accuracy.  

RAG æ˜¯ä¸€ä¸ªå¤šé˜¶æ®µã€å¤šæ­¥éª¤çš„æ¡†æ¶ï¼Œéœ€è¦æ•´ä½“[å’Œç²¾ç»†è¯„ä¼°](https://weaviate.io/blog/rag-evaluation)ã€‚è¿™ç§æ–¹æ³•ç¡®ä¿äº†ç»„ä»¶çº§çš„å¯é æ€§å’Œé«˜æ°´å¹³çš„å‡†ç¡®æ€§ã€‚  

In this section, weâ€™ll explore both of these evaluation approaches and touch on RAGAS, a popular evaluation framework.  

åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨è¿™ä¸¤ç§è¯„ä¼°æ–¹æ³•ï¼Œå¹¶ä»‹ç»ä¸€ç§æµè¡Œçš„è¯„ä¼°æ¡†æ¶ RAGASã€‚

![RAG Evaluation](rag-evaluation-88cda4f05d186dc81cc8101ddc9a29df.png "RAG Evaluation")

### Component-level evaluation[](https://weaviate.io/blog/introduction-to-rag#component-level-evaluation "Direct link to Component-level evaluation")  

ç»„ä»¶çº§è¯„ä¼°[](https://weaviate.io/blog/introduction-to-rag#component-level-evaluation "Direct link to Component-level evaluation")

On a component-level, RAG evaluation generally focuses on assessing the quality of the retriever and the generator, as they both play critical roles in producing accurate and relevant responses.  

åœ¨ç»„ä»¶å±‚é¢ï¼ŒRAG è¯„ä¼°é€šå¸¸ä¾§é‡äºè¯„ä¼°æ£€ç´¢å™¨å’Œç”Ÿæˆå™¨çš„è´¨é‡ï¼Œå› ä¸ºå®ƒä»¬åœ¨äº§ç”Ÿå‡†ç¡®å’Œç›¸å…³çš„å“åº”æ–¹é¢éƒ½å‘æŒ¥ç€å…³é”®ä½œç”¨ã€‚

Evaluation of the retriever centers around accuracy and relevance. In this context, **accuracy** measures how precisely the retriever selects information that directly addresses the query, while **relevance** assesses how closely the retrieved data aligns with the specific needs and context of the query.  

å¯¹æ£€ç´¢å™¨çš„è¯„ä¼°ä»¥å‡†ç¡®æ€§å’Œç›¸å…³æ€§ä¸ºä¸­å¿ƒã€‚åœ¨æ­¤ä¸Šä¸‹æ–‡ä¸­ï¼Œ**å‡†ç¡®æ€§**è¡¡é‡æ£€ç´¢å™¨é€‰æ‹©ç›´æ¥è§£å†³æŸ¥è¯¢çš„ä¿¡æ¯çš„ç²¾ç¡®ç¨‹åº¦ï¼Œè€Œ**ç›¸å…³æ€§**åˆ™è¯„ä¼°æ£€ç´¢åˆ°çš„æ•°æ®ä¸æŸ¥è¯¢çš„ç‰¹å®šéœ€æ±‚å’Œä¸Šä¸‹æ–‡çš„ä¸€è‡´æ€§ã€‚

On the other hand, evaluation of the generator focuses on faithfulness and correctness. **Faithfulness** evaluates whether the response generated by the model accurately represents the information from the relevant documents and checks how consistent the response is with the original sources.  

å¦ä¸€æ–¹é¢ï¼Œå¯¹ç”Ÿæˆå™¨çš„è¯„ä¼°ä¾§é‡äºå¿ å®åº¦å’Œæ­£ç¡®æ€§ã€‚**Faithfulness** è¯„ä¼°æ¨¡å‹ç”Ÿæˆçš„å“åº”æ˜¯å¦å‡†ç¡®è¡¨ç¤ºæ¥è‡ªç›¸å…³æ–‡æ¡£çš„ä¿¡æ¯ï¼Œå¹¶æ£€æŸ¥å“åº”ä¸åŸå§‹æ¥æºçš„ä¸€è‡´æ€§ã€‚  

**Correctness** assesses whether the generated response is truly factual and aligns with the ground truth or expected answer based on the query's context.  

**æ­£ç¡®æ€§**è¯„ä¼°ç”Ÿæˆçš„å“åº”æ˜¯å¦çœŸå®å¯ä¿¡ï¼Œå¹¶ä¸åŸºäºæŸ¥è¯¢ä¸Šä¸‹æ–‡çš„åŸºæœ¬äº‹å®æˆ–é¢„æœŸç­”æ¡ˆä¸€è‡´ã€‚

### End-to-end evaluation[](https://weaviate.io/blog/introduction-to-rag#end-to-end-evaluation "Direct link to End-to-end evaluation")  

ç«¯åˆ°ç«¯è¯„ä¼°[](https://weaviate.io/blog/introduction-to-rag#end-to-end-evaluation "Direct link to End-to-end evaluation")

Although the retriever and the generator are two distinct components, they rely on each other to produce coherent responses to user queries.  

å°½ç®¡æ£€ç´¢å™¨å’Œç”Ÿæˆå™¨æ˜¯ä¸¤ä¸ªä¸åŒçš„ç»„ä»¶ï¼Œä½†å®ƒä»¬ç›¸äº’ä¾èµ–ä»¥ç”Ÿæˆå¯¹ç”¨æˆ·æŸ¥è¯¢çš„ä¸€è‡´å“åº”ã€‚

Calculating Answer Semantic Similarity is a simple and efficient method of assessing how well the retriever and generator work together.  

è®¡ç®—ç­”æ¡ˆè¯­ä¹‰ç›¸ä¼¼æ€§æ˜¯ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ–¹æ³•ï¼Œç”¨äºè¯„ä¼°æ£€ç´¢å™¨å’Œç”Ÿæˆå™¨çš„ååŒå·¥ä½œæƒ…å†µã€‚  

**Answer Semantic Similarity** calculates the semantic similarity between generated responses and ground truth samples.  

**ç­”æ¡ˆè¯­ä¹‰ç›¸ä¼¼æ€§**è®¡ç®—ç”Ÿæˆçš„å“åº”ä¸çœŸå®æ ·æœ¬ä¹‹é—´çš„è¯­ä¹‰ç›¸ä¼¼æ€§ã€‚  

Generated responses with a high degree of similarity to ground truth samples are indicative of a pipeline that can retrieve relevant information and generate contextually appropriate responses.  

ç”Ÿæˆçš„å“åº”ä¸çœŸå€¼æ ·æœ¬é«˜åº¦ç›¸ä¼¼ï¼Œè¿™è¡¨æ˜ç®¡é“å¯ä»¥æ£€ç´¢ç›¸å…³ä¿¡æ¯å¹¶ç”Ÿæˆä¸Šä¸‹æ–‡é€‚å½“çš„å“åº”ã€‚

note  

æ³¨æ„

RAG evaluation frameworks offer structured methods, tools, or platforms to evaluate RAG pipelines. [**RAGAS**](https://docs.ragas.io/en/stable/index.html#) (Retrieval Augmented Generation Assessment) is an especially popular framework, as it offers a suite of metrics to assess retrieval relevance, generation quality, and faithfulness without requiring human-labeled data.  

RAG è¯„ä¼°æ¡†æ¶æä¾›ç»“æ„åŒ–çš„æ–¹æ³•ã€å·¥å…·æˆ–å¹³å°æ¥è¯„ä¼° RAG ç®¡é“ã€‚[**RAGAS**](https://docs.ragas.io/en/stable/index.html#)ï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆè¯„ä¼°ï¼‰æ˜¯ä¸€ä¸ªç‰¹åˆ«å—æ¬¢è¿çš„æ¡†æ¶ï¼Œå› ä¸ºå®ƒæä¾›äº†ä¸€å¥—æŒ‡æ ‡æ¥è¯„ä¼°æ£€ç´¢ç›¸å…³æ€§ã€ç”Ÿæˆè´¨é‡å’Œå¿ å®åº¦ï¼Œè€Œæ— éœ€äººå·¥æ ‡è®°çš„æ•°æ®ã€‚  

Listen to this [episode](https://www.youtube.com/watch?v=C-UQwvO8Koc) of the Weaviate podcast to learn more about how RAGAS works and advanced techniques for optimizing RAGAS scores, straight from the creators themselves.  

æ”¶å¬æœ¬[é›†](https://www.youtube.com/watch?v=C-UQwvO8Koc) Weaviate æ’­å®¢ï¼Œç›´æ¥ä»åˆ›ä½œè€…æœ¬äººé‚£é‡Œäº†è§£æ›´å¤šå…³äº RAGAS çš„å·¥ä½œåŸç†ä»¥åŠä¼˜åŒ– RAGAS åˆ†æ•°çš„é«˜çº§æŠ€æœ¯ã€‚

## RAG vs. fine-tuning[](https://weaviate.io/blog/introduction-to-rag#rag-vs-fine-tuning "Direct link to RAG vs. fine-tuning")  

RAG ä¸å¾®è°ƒ[](https://weaviate.io/blog/introduction-to-rag#rag-vs-fine-tuning "Direct link to RAG vs. fine-tuning")

RAG is only one of several methods to expand the capabilities and mitigate the limitations of generative LLMs. Fine-tuning LLMs is a particularly popular technique for tailoring models to perform highly specialized tasks by training them on domain-specific data.  

RAG åªæ˜¯æ‰©å±•ç”Ÿæˆå¼ LLMsã€‚å¾®è°ƒ LLMs æ˜¯ä¸€ç§ç‰¹åˆ«æµè¡Œçš„æŠ€æœ¯ï¼Œå®ƒé€šè¿‡åœ¨ç‰¹å®šäºé¢†åŸŸçš„æ•°æ®ä¸Šè®­ç»ƒæ¨¡å‹æ¥å®šåˆ¶æ¨¡å‹ä»¥æ‰§è¡Œé«˜åº¦ä¸“ä¸šåŒ–çš„ä»»åŠ¡ã€‚  

While fine-tuning may be ideal for certain use cases, such as training a LLM to adopt a specific tone or writing style, RAG is often the lowest-hanging fruit for improving model accuracy, reducing hallucinations, and tailoring LLMs for specific tasks.  

è™½ç„¶å¾®è°ƒå¯èƒ½é€‚ç”¨äºæŸäº›ç”¨ä¾‹ï¼Œä¾‹å¦‚è®­ç»ƒ LLM é‡‡ç”¨ç‰¹å®šçš„è¯­æ°”æˆ–å†™ä½œé£æ ¼ï¼Œä½† RAG é€šå¸¸æ˜¯æé«˜æ¨¡å‹å‡†ç¡®æ€§ã€å‡å°‘å¹»è§‰å’Œä¸ºç‰¹å®šä»»åŠ¡å®šåˆ¶ LLMsã€‚

The beauty of RAG lies in the fact that the weights of the underlying generative model donâ€™t need to be updated, which can be costly and time-consuming.  

RAG çš„ç¾å¦™ä¹‹å¤„åœ¨äºï¼Œåº•å±‚ç”Ÿæˆæ¨¡å‹çš„æƒé‡ä¸éœ€è¦æ›´æ–°ï¼Œè¿™å¯èƒ½æ—¢æ˜‚è´µåˆè€—æ—¶ã€‚  

RAG allows models to access external data dynamically, improving accuracy without costly retraining.  

RAG å…è®¸æ¨¡å‹åŠ¨æ€è®¿é—®å¤–éƒ¨æ•°æ®ï¼Œæ— éœ€æ˜‚è´µçš„é‡æ–°è®­ç»ƒå³å¯æé«˜å‡†ç¡®æ€§ã€‚  

This makes it a practical solution for applications needing real-time information.  

è¿™ä½¿å…¶æˆä¸ºéœ€è¦å®æ—¶ä¿¡æ¯çš„åº”ç”¨ç¨‹åºçš„å®ç”¨è§£å†³æ–¹æ¡ˆã€‚  

In the next section, weâ€™ll dive deeper into the architecture of RAG and how its components work together to create a powerful retrieval-augmented system.  

åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨ RAG çš„æ¶æ„åŠå…¶ç»„ä»¶å¦‚ä½•ååŒå·¥ä½œä»¥åˆ›å»ºä¸€ä¸ªå¼ºå¤§çš„æ£€ç´¢å¢å¼ºç³»ç»Ÿã€‚

## Summary[](https://weaviate.io/blog/introduction-to-rag#summary "Direct link to Summary")  

æ€»ç»“[](https://weaviate.io/blog/introduction-to-rag#summary "Direct link to Summary")

In this article, we introduced you to RAG, a framework that leverages task-specific external knowledge to improve the performance of applications powered by generative models.  

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å‘æ‚¨ä»‹ç»äº† RAGï¼Œè¿™æ˜¯ä¸€ä¸ªåˆ©ç”¨ç‰¹å®šäºä»»åŠ¡çš„å¤–éƒ¨çŸ¥è¯†æ¥æé«˜ç”±ç”Ÿæˆæ¨¡å‹æä¾›æ”¯æŒçš„åº”ç”¨ç¨‹åºçš„æ€§èƒ½çš„æ¡†æ¶ã€‚  

We learned about the different components of RAG pipelines, including external knowledge sources, prompt templates, and generative models as well as how they work together in retrieval, augmentation, and generation.  

æˆ‘ä»¬äº†è§£äº† RAG ç®¡é“çš„ä¸åŒç»„ä»¶ï¼ŒåŒ…æ‹¬å¤–éƒ¨çŸ¥è¯†æºã€æç¤ºæ¨¡æ¿å’Œç”Ÿæˆæ¨¡å‹ï¼Œä»¥åŠå®ƒä»¬å¦‚ä½•åœ¨æ£€ç´¢ã€å¢å¼ºå’Œç”Ÿæˆä¸­ååŒå·¥ä½œã€‚  

We also discussed popular RAG use cases and frameworks for implementation, such as LangChain, LlamaIndex, and DSPy.  

æˆ‘ä»¬è¿˜è®¨è®ºäº†æµè¡Œçš„ RAG ä½¿ç”¨æ¡ˆä¾‹å’Œå®æ–½æ¡†æ¶ï¼Œä¾‹å¦‚ LangChainã€LlamaIndex å’Œ DSPyã€‚  

Finally, we touched on some specialized RAG techniques, including advanced RAG methods, agentic RAG, and graph RAG as well as methods for evaluating RAG pipelines.  

æœ€åï¼Œæˆ‘ä»¬è°ˆåˆ°äº†ä¸€äº›ä¸“é—¨çš„ RAG æŠ€æœ¯ï¼ŒåŒ…æ‹¬é«˜çº§ RAG æ–¹æ³•ã€ä»£ç† RAG å’Œå›¾å½¢ RAG ä»¥åŠè¯„ä¼° RAG ç®¡é“çš„æ–¹æ³•ã€‚

At a minimum, each section in this post deserves its own individual blog post, if not an entire chapter in a book.  

è‡³å°‘ï¼Œè¿™ç¯‡æ–‡ç« ä¸­çš„æ¯ä¸ªéƒ¨åˆ†éƒ½åº”è¯¥æœ‰è‡ªå·±çš„å•ç‹¬åšå®¢æ–‡ç« ï¼Œå¦‚æœä¸æ˜¯ä¸€æœ¬ä¹¦çš„ä¸€æ•´ç« çš„è¯ã€‚  

As a result, weâ€™ve put together a resource guide with academic papers, blog posts, YouTube videos, tutorials, notebooks, and recipes to help you learn more about the topics, frameworks, and methods presented in this article.  

å› æ­¤ï¼Œæˆ‘ä»¬æ•´ç†äº†ä¸€ä»½èµ„æºæŒ‡å—ï¼Œå…¶ä¸­åŒ…å«å­¦æœ¯è®ºæ–‡ã€åšå®¢æ–‡ç« ã€YouTube è§†é¢‘ã€æ•™ç¨‹ã€ç¬”è®°æœ¬å’Œé£Ÿè°±ï¼Œä»¥å¸®åŠ©æ‚¨äº†è§£æœ‰å…³æœ¬æ–‡ä¸­ä»‹ç»çš„ä¸»é¢˜ã€æ¡†æ¶å’Œæ–¹æ³•çš„æ›´å¤šä¿¡æ¯ã€‚

### Resource guide[](https://weaviate.io/blog/introduction-to-rag#resource-guide "Direct link to Resource guide")  

èµ„æºæŒ‡å—[](https://weaviate.io/blog/introduction-to-rag#resource-guide "Direct link to Resource guide")

ğŸ“„ [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401) (Original RAG paper)  

ğŸ“„ [ç”¨äºçŸ¥è¯†å¯†é›†å‹ NLP ä»»åŠ¡çš„æ£€ç´¢å¢å¼ºç”Ÿæˆ](https://arxiv.org/abs/2005.11401)ï¼ˆåŸå§‹ RAG è®ºæ–‡ï¼‰

ğŸ‘©ğŸ³ [Getting Started with RAG in DSPy](https://github.com/weaviate/recipes/blob/main/integrations/llm-frameworks/dspy/1.Getting-Started-with-RAG-in-DSPy.ipynb) (Recipe)  

ğŸ‘© ğŸ³ [DSPy ä¸­çš„ RAG å…¥é—¨](https://github.com/weaviate/recipes/blob/main/integrations/llm-frameworks/dspy/1.Getting-Started-with-RAG-in-DSPy.ipynb)ï¼ˆé…æ–¹ï¼‰

ğŸ‘©ğŸ³ [Naive RAG with LlamaIndex](https://github.com/weaviate/recipes/blob/main/integrations/llm-frameworks/llamaindex/retrieval-augmented-generation/naive_rag.ipynb) (Recipe)  

ğŸ‘© ğŸ³ [å¸¦æœ‰ LlamaIndex çš„ Naive RAG](https://github.com/weaviate/recipes/blob/main/integrations/llm-frameworks/llamaindex/retrieval-augmented-generation/naive_rag.ipynb)ï¼ˆé£Ÿè°±ï¼‰

ğŸ“ [Advanced RAG Techniques](https://weaviate.io/blog/advanced-rag#3-fine-tuning-embedding-models) (Blog post)  

ğŸ“ [é«˜çº§ RAG æŠ€æœ¯](https://weaviate.io/blog/advanced-rag#3-fine-tuning-embedding-models)ï¼ˆåšå®¢æ–‡ç« ï¼‰

ğŸ“’ [Agentic RAG with Multi-Document Agents](https://github.com/cobusgreyling/LlamaIndex/blob/d8902482a247c76c7902ded143a875d5580f072a/Agentic_RAG_Multi_Document_Agents-v1.ipynb) (Notebook)  

ğŸ“’ [å…·æœ‰å¤šæ–‡æ¡£ä»£ç†çš„ä»£ç† RAG](https://github.com/cobusgreyling/LlamaIndex/blob/d8902482a247c76c7902ded143a875d5580f072a/Agentic_RAG_Multi_Document_Agents-v1.ipynb) ï¼ˆç¬”è®°æœ¬ï¼‰

ğŸ“ [An Overview of RAG Evaluation](https://weaviate.io/blog/rag-evaluation) (Blog post)  

ğŸ“ [RAG è¯„ä¼°æ¦‚è¿°](https://weaviate.io/blog/rag-evaluation) ï¼ˆåšå®¢æ–‡ç« ï¼‰

ğŸ“„ [Evaluation of Retrieval-Augmented Generation: A Survey](https://arxiv.org/abs/2405.07437) (Academic paper)  

ğŸ“„ [æ£€ç´¢å¢å¼ºä¸€ä»£çš„è¯„ä¼°ï¼šä¸€é¡¹è°ƒæŸ¥](https://arxiv.org/abs/2405.07437)ï¼ˆå­¦æœ¯è®ºæ–‡ï¼‰

## Ready to start building?[](https://weaviate.io/blog/introduction-to-rag#ready-to-start-building "Direct link to Ready to start building?")  

å‡†å¤‡å¥½å¼€å§‹æ„å»ºäº†å—ï¼Ÿ[](https://weaviate.io/blog/introduction-to-rag#ready-to-start-building "Direct link to Ready to start building?")

Check out the [Quickstart tutorial](https://weaviate.io/developers/weaviate/quickstart), or build amazing apps with a free trial of [Weaviate Cloud (WCD)](https://console.weaviate.cloud/).  

æŸ¥çœ‹[å¿«é€Ÿå…¥é—¨æ•™ç¨‹](https://weaviate.io/developers/weaviate/quickstart)ï¼Œæˆ–é€šè¿‡å…è´¹è¯•ç”¨ [Weaviate Cloud ï¼ˆWCDï¼‰](https://console.weaviate.cloud/) æ„å»ºä»¤äººæƒŠå¹çš„åº”ç”¨ç¨‹åºã€‚
