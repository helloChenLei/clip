---
title: "Sam Altman：OpenAI、GPT-5、Sora、Board Saga、Elon Musk、Ilya、Power & AGI"
date: 2024-03-26T07:40:03+08:00
updated: 2024-03-26T07:40:03+08:00
taxonomies:
  tags: []
extra:
  source: https://www.appblit.com/scribe?v=jvqFAi7vkBc
  hostname: www.appblit.com
  author: AppBlit LLC
  original_title: "Scribe - Sam Altman: OpenAI, GPT-5, Sora, Board Saga, Elon Musk, Ilya, Power & AGI | Lex Fridman Podcast #419"
  original_lang: en
---

This is a summary of the Lex Fridman Podcast episode #419 featuring Sam Altman, CEO of OpenAI.  

这是 Lex Fridman Podcast 第 419 期节目的摘要，主讲人是 OpenAI 首席执行官 Sam Altman。  

Sam discusses the OpenAI board saga, Ilya Sutskever, Elon Musk lawsuit, Sora, GPT-4, memory & privacy, and AGI.  

萨姆讨论了 OpenAI 董事会传奇、伊利亚-苏茨克沃（Ilya Sutskever）、埃隆-马斯克（Elon Musk）诉讼、索拉（Sora）、GPT-4、内存与隐私以及 AGI。  

He also talks about his thoughts on aliens and the importance of compute in the future.  

他还谈到了自己对外星人的看法以及计算在未来的重要性。  

The episode also includes a discussion on the structure of OpenAI's board and the selection process for new board members.  

本集还讨论了 OpenAI 董事会的结构和新董事会成员的遴选过程。  

Sam also shares his thoughts on the power struggle in building AGI and the importance of resilience and preparation for challenges in the future.  

萨姆还分享了他对建立 AGI 过程中权力斗争的看法，以及应变能力和准备迎接未来挑战的重要性。

I think compute is gonna be the currency of the future. I think it'll be maybe the most precious commodity in the world. I expect that by the end of this decade. And possibly somewhat sooner than that, we will have quite capable systems that we look at and say, wow, that's really remarkable. The road to AGI should be a giant power struggle. I expect that to be the case.  

我认为计算将成为未来的货币。我认为它可能会成为世界上最珍贵的商品。我预计，到本十年末。我们将拥有相当强大的系统，我们看着它，会说，哇，太了不起了。通往人工智能的道路应该是一场巨大的权力斗争。我预计会是这样。

Whoever builds AGI first gets a lot of power. Do you trust yourself with that much power? The following is a conversation with Sam Altman, his second time in the podcast. He is the CEO of OpenAI, the company behind GPT-4, ChatGPT, Sora, and perhaps one day the very company that will build AGI. This is Lex Fridman Podcast. To support it, please check out our sponsors in the description. And now, dear friends, here's Sam Altman.  

谁先建立 AGI，谁就能获得很大的权力。你相信自己有这么大的能力吗？以下是与萨姆-阿尔特曼（Sam Altman）的对话，这是他第二次参加播客。他是 OpenAI 的首席执行官，OpenAI 是 GPT-4、ChatGPT、Sora 的幕后公司，也许有一天，这家公司就会打造出 AGI。这里是 Lex Fridman 播客。如需支持，请查看说明中的赞助商。现在，亲爱的朋友们，有请山姆-奥特曼。

Take me through the OpenAI board saga that started on Thursday, November 16th, maybe Friday, November 17th for you. That was definitely the most painful professional experience of my life and chaotic, and shameful, and upsetting and a bunch of other negative things. There were great things about it too and I wish it had not been in such an adrenaline rush that I wasn't able to stop and appreciate them at the time.  

带我回顾一下从 11 月 16 日星期四，也许是 11 月 17 日星期五开始的 OpenAI 董事会事件。那绝对是我一生中最痛苦的职业经历，混乱、可耻、令人不安，还有其他一些负面的东西。其中也有美好的一面，但愿当时我没有因为肾上腺素飙升而无法停下来欣赏它们。

I came across this old tweet of mine or this tweet of mine from that time period, which was it was like kind of going to your own eulogy, watching people say all these great things about you and just like unbelievable support from people I love and care about. That was really nice.  

我发现了我的这条旧推特，或者说是那个时期我的这条推特，它就像是去听你自己的悼词，看着人们说着关于你的这些美好的事情，以及来自我爱和关心的人的难以置信的支持。这真的很好。

That whole weekend I kind of like felt with one big exception, I felt like a great deal of love and very little hate even though it felt like I have no idea what's happening and what's gonna happen here and this feels really bad. And there were definitely times I thought it was gonna be like one of the worst things to ever happen for AI safety. Well, I also think I'm happy that it happened relatively early.  

整个周末，我都有一种感觉，除了一个很大的例外，我感觉到了大量的爱和很少的恨，尽管我感觉我不知道发生了什么，这里会发生什么，这感觉真的很糟糕。有好几次，我都觉得这对人工智能安全来说是最糟糕的事情之一。好吧，我也很高兴它发生得比较早。

I thought at some point between when OpenAI started and when we created AGI, there was gonna be something crazy and explosive that happened, but there may be more crazy and explosive things happen. It still I think helped us build up some resilience and be ready for more challenges in the future. But the thing you had a sense that you would experience is some kind of power struggle.  

我认为，从 OpenAI 启动到我们创建 AGI 之间的某个时间点，一定会发生一些疯狂和爆炸性的事情，但可能还会有更多疯狂和爆炸性的事情发生。我认为这仍然帮助我们建立了一定的应变能力，并为未来更多的挑战做好了准备。但你感觉到你会经历的事情是某种权力斗争。

The road to AGI should be a giant power struggle. Like the world should. Well, not should. I expect that to be the case. And so you have to go through that, like you said, iterate as often as possible in figuring out how to have a board structure, how to have organization, how to have the kind of people that you're working with, how to communicate all that in order to deescalate the power struggle as much as possible, pacify it.  

通往 AGI 的道路应该是一场巨大的权力斗争。就像世界应该如此。好吧，不是应该。我希望是这样所以你必须经历这一切，就像你说的，尽可能多地反复斟酌如何建立董事会结构，如何建立组织，如何拥有与你共事的那类人，如何沟通所有这些，以尽可能地缓和权力斗争，平息它。

But at this point, it feels like something that was in the past that was really unpleasant and really difficult and painful. But we're back to work and things are so busy and so intense that I don't spend a lot of time thinking about it. There was a time after.  

但此时此刻，我觉得这就像是过去的事情，非常不愉快、非常困难和痛苦。但我们又回到了工作岗位上，事情是如此繁忙和紧张，以至于我没有花很多时间去想它。之后还有一段时间。

There was like this fugue state for kind of like the month after, maybe 45 days after that was I was just sort of like drifting through the days, I was so out of it. I was feeling so down-Just on a personal psychological level. Yeah. Really painful. And hard to have to keep running OpenAI in the middle of that. I just wanted to crawl into a cave and kind of recover for a while.  

在那之后的一个月里，也许是 45 天里，我一直处于迷迷糊糊的状态。我感觉很低落，只是个人心理层面的。在个人心理层面真的很痛苦在这种情况下还要继续运行OpenAI，真的很不容易。我只想爬进一个山洞，恢复一段时间。

But now it's like we're just back to working on the mission. Well, it's still useful to go back there and reflect on board structures, on power dynamics, on how companies are run, the tension between research, and product development, and money and all this kind of stuff so that you have a very high potential of building AGI would do so in a slightly more organized, less dramatic way in the future.  

但现在，我们好像又回到了完成任务的状态。好吧，回到那里，反思董事会结构、权力动态、公司运作方式、研究与产品开发之间的紧张关系、金钱和所有这些东西，还是很有帮助的，这样你就有很大可能在未来以一种稍微更有组织、不那么戏剧化的方式建造 AGI。

So there's value there to go both the personal psychological aspects of you as a leader and also just the board structure and all this kind of messy stuff. Definitely learned a lot about structure and incentives and what we need out of a board And I think that it is valuable that this happened now in some sense.  

因此，作为领导者，在个人心理方面，以及董事会结构和所有这些乱七八糟的东西方面，都是有价值的。我肯定学到了很多关于结构和激励机制的知识，以及我们对董事会的需求。

I think this is probably not like the last high stress moment of OpenAI, but it was quite a high stress moment.company very nearly got destroyed. And we think a lot about many of the other things we've gotta get right for AGI. But thinking about how to build a resilient org and how to build a structure that will stand up to a lot of pressure the world, which I expect more and more as we get closer.  

我认为，这可能不是 OpenAI 最后的高压力时刻，但也是相当高的压力时刻。我们想了很多关于 AGI 的其他事情。但我们也在思考如何建立一个有弹性的组织，如何建立一个能够承受世界巨大压力的结构，随着时间的推移，我预计压力会越来越大。

I think that's super important. Do you have a sense of how deep and rigorous the deliberation process by the board was? Can you shine some light on just human dynamics involved in situations like this? Was it just a few conversations and all of a sudden it escalates and why don't we fire Sam kind of thing. I think the board members were far, well-meaning people on the whole.  

我认为这一点非常重要。你了解董事会的审议过程有多深入和严谨吗？你能不能透露一下在这种情况下所涉及的人际关系？是否只是几次谈话，然后突然就升级了，我们为什么不解雇山姆之类的事情。我认为董事会成员整体上都是心地善良的人。

And I believe that in stressful situations where people feel time pressure or whatever, people understandably make suboptimal decisions. And I think one of the challenges for OpenAI will be we're gonna have to have a board and a team that are good at operating under pressure. Do you think the board had too much power.  

我相信，在人们感到时间压力或其他压力的情况下，做出次优决策是可以理解的。我认为，OpenAI 面临的挑战之一是，我们必须拥有一个善于在压力下工作的董事会和团队。你是否认为董事会权力过大？

I think boards are supposed to have a lot of power, but one of the things that we did see is in most corporate structures, boards are usually answerable to shareholders. Sometimes people have like super voting shares or whatever.  

我认为董事会应该拥有很大的权力，但我们确实看到，在大多数公司结构中，董事会通常要对股东负责。有时，人们拥有超级投票权的股份或其他东西。

In this case, I think one of the things with our structure that we maybe should have thought about more than we did is that the board of a nonprofit has, unless you put other rules in place, like quite a lot of power, they don't really answer to anyone but themselves.  

在这种情况下，我认为我们应该对我们的结构多加考虑的一点是，非营利组织的董事会，除非你制定了其他规则，比如拥有相当大的权力，否则他们除了对自己负责，并不真正对任何人负责。

And there's ways in which that's good, but what we'd really like is for the board of OpenAI to answer to the world as a whole as much as that's a practical thing. So there's a new board announced. Yeah. There's, I guess, a new smaller board of first and now there's a new final board. Not a final board yet. We've added some, we'll add more. Added some, okay.  

这在某些方面是好的，但我们真正希望的是，OpenAI 的董事会能够对整个世界负责，因为这是一件很实际的事情。所以新的董事会已经宣布了。是啊我猜，先是一个新的小型董事会，现在又有了一个新的最终董事会。还不是最终董事会我们已经添加了一些，我们会添加更多。增加了一些，好的

What is fixed in the new one that was perhaps broken in the previous one. The old board sort of got smaller over the course of about a year. It was nine and then it went down to six and then we couldn't agree on who to add.  

新电路板修复了什么，而以前的电路板可能坏了什么。旧的董事会在大约一年的时间里逐渐缩小。原来有九个人，后来减少到六个，再后来，我们无法就增加谁达成一致意见。

And the board also, I think, didn't have a lot of experienced board members and a lot of the new board members at OpenAI have just have more experience as board members. I think that'll help. It's been criticized some of the people that are added to the board. I heard a lot of people criticizing the addition of Larry Summers, for example. What was the process of selecting the board? What's involved in that.  

我认为，董事会也没有很多经验丰富的董事会成员，而 OpenAI 的很多新董事会成员都拥有更多的董事会成员经验。我认为这将有所帮助。一些新加入董事会的人受到了批评。例如，我听到很多人批评拉里-萨默斯（Larry Summers）的加入。董事会的遴选过程是怎样的？其中涉及哪些方面。

So Bret and Larry were kind of decided in the heat of the moment over this very tense weekend and that was. I mean, that weekend was like a real rollercoaster, like a lot of lots and downs. And we were trying to agree on new board members that both sort of the executive team here and the old board members felt would be reasonable. Larry was actually one of their suggestions, the old board members.  

布瑞特和拉里在这个紧张的周末 决定了他们的关系我的意思是，那个周末就像坐过山车一样 经历了很多波折我们试图在新的董事会成员上达成一致，让这里的执行团队和老董事会成员都觉得是合理的。拉里实际上是他们的建议之一，老董事会成员。

Bret, previous to that weekend, suggested, but he was busy and didn't wanna do it. And then we really needed help in wood. We talked about a lot of other people too, but I felt like if I was going to come back, I needed new board members.  

在那个周末之前，布雷特曾建议过，但他很忙，不想做。然后我们真的需要木材方面的帮助。我们也谈了很多其他人，但我觉得如果我要回来，就需要新的董事会成员。

I didn't think I could work with the old board again in the same configuration, although we then decided, and I'm grateful that Adam would stay, but we wanted to get to. We considered various configurations, decided we wanted to get to a board of three and had to find two new board members over the course of sort of a short period of time. So those were decided honestly without.  

我认为我无法以同样的配置再次与旧董事会合作，虽然我们后来决定，我很感激亚当会留下来，但我们想达到这个目标。我们考虑了各种配置，决定成立一个三人董事会，并在短时间内找到了两名新的董事会成员。所以，这些都是诚实地决定没有。

That's like you kind of do that on the battlefield. You don't have time to design a rigorous process then. For new board members, since new board members will add going forward, we have some criteria that we think are important for the board to have different expertise that we want the board to have.  

这就像你在战场上做的那样。你没有时间去设计一个严格的程序。对于新的董事会成员，由于新的董事会成员会不断增加，我们有一些标准，我们认为这些标准对于董事会来说非常重要，我们希望董事会拥有不同的专业知识。

Unlike hiring an executive where you need them to do one role, well, the board needs to do a whole role of kind of governance and thoughtfulness. Well, and so one thing that Bret says, which I really like is that we wanna hire board members in slates, not as individuals one at a time. And thinking about a group of people that will bring nonprofit expertise, expertise at running companies, sort of good legal and governance expertise.  

与聘用高管不同的是，你需要他们扮演一个角色，而董事会则需要扮演一个整体的角色，即治理和深思熟虑。布雷特说的一句话我非常喜欢，那就是我们要以董事会成员的形式来聘用，而不是一个一个单独聘用。我们要考虑的是，让一群人带来非营利组织的专业知识、管理公司的专业知识、良好的法律和管理专业知识。

That's kind of what we've tried to optimize for. So is technical savvy important for the individual board members. Not for every board member, but certainly some you need that. That's part of what the board needs to do. So I mean, the interesting thing that people probably don't understand about OpenAI certainly is like all the details of running the business.  

这正是我们努力优化的方向。那么，技术知识对董事会成员个人来说是否重要呢？不是每个董事会成员都需要技术知识，但有些人肯定需要。这是董事会需要做的一部分。所以，我的意思是，人们可能不了解 OpenAI 的有趣之处，当然就是经营业务的所有细节。

When they think about the board given the drama, they think about you, they think about like if you reach AGI or you reach some of these incredibly impactful products and you build them and deploy them, what's the conversation with the board like? And they kind of think, all right, what's the right squad to have in that kind of situation to deliberate.  

当他们考虑到董事会的戏剧性时，他们会想到你，他们会想到如果你达到了 AGI，或者你达到了这些令人难以置信的有影响力的产品，你建立了它们并部署了它们，那么与董事会的对话会是怎样的？他们就会想，好吧，在这种情况下，应该有什么样的团队来商议呢？

Look, I think you definitely need some technical experts there and then you need some people who are like, how can we deploy this in a way that will help people in the world the most and people who have a very different perspective? I think a mistake that you or I might make is to think that only the technical understanding matters. And that's definitely part of the conversation you want that board to have.  

听着，我认为你肯定需要一些技术专家，然后你还需要一些人，比如，我们怎样才能以一种对世界上的人们帮助最大的方式来部署它，以及那些有着截然不同观点的人？我认为，你我可能会犯的一个错误是，认为只有技术理解才是最重要的。而这绝对是你希望董事会进行的对话的一部分。

But there's a lot more about how that's gonna just like impact society and people's lives that you really want represented in there too. Are you looking at the track record of people or you're just having conversations. Track record's a big deal. You, of course, have a lot of conversations. There's some roles where I kind of totally ignore track record and just look at slope, kind of ignore the y-intercept. Thank you.  

但还有更多关于如何影响社会和人们生活的内容，你也希望在其中有所体现。你是在看别人的业绩记录，还是只是在聊天？业绩是个大问题。当然，你会有很多对话。有些职位我完全不看业绩记录，只看斜率，不看 Y-截距。谢谢。

Thank you for making it mathematical for the audience,-For a board member, I do care much more about the y-intercept. I think there is something deep to say about track record there and experiences, something's very hard to replace. Do you try to fit a polynomial function or exponential one to track record. That's not that. An analogy doesn't carry that far. All right. You mentioned some of the low points that weekend.  

谢谢你为听众提供了数学知识，--作为董事会成员，我确实更关心 Y-截距。我认为，关于业绩和经验，有些东西是很难替代的。你是想用多项式函数还是指数函数来拟合业绩记录呢？不是这样的。类比没有那么远。好吧你提到了那个周末的一些低谷

What were some of the low points psychologically for you? Did you consider going to the Amazon jungle and just taking Ayahuasca disappearing forever or. I mean, there's so many low, like it was a very bad period of time. There were great high points too. My phone was just like sort of nonstop blowing up with nice messages from people I worked with every day, people I hadn't talked to in a decade.  

你心理上的低谷是什么？你是否考虑过去亚马逊丛林服用死藤水，然后永远消失？我是说，有很多低谷，比如那是一段非常糟糕的时期。但也有高潮。我的手机不停地收到每天一起工作的人发来的祝福短信 我已经有十年没联系过他们了

I didn't get to appreciate that as much as I should have. 'cause I was just like in the middle of this firefight, but that was really nice. But on the whole, it was like a very painful weekend and also just like a very. It was like a battle fought in public to a surprising degree and that was extremely exhausting to me, much more than I expected.  

我没能好好欣赏这一切因为我当时正处于交火中 但那真的很好但总的来说，这是一个非常痛苦的周末，也是一个非常。这就像一场在公众面前进行的战斗，程度令人惊讶，这让我非常疲惫，远远超出了我的预期。

I think fights are generally exhausting, but this one really was. The board did this Friday afternoon. I really couldn't get much in the way of answers, but I also was just like, "Well, the board gets to do this." And so I'm gonna think for a little bit about what I want to do, but I'll try to find the, the blessing in disguise here.  

我觉得打架一般都很累，但这次真的很累。周五下午董事会做了这个我真的没有得到什么答案 但我也想，"好吧，董事会可以这么做"所以我还得考虑一下我想做的事 但我会努力找到变相的祝福

And I was like, "Well, my current job at OpenAI, it was like to like run a decently-sized company at this point." And the thing I'd always liked the most was just getting to work with the researchers. And I was like, yeah, I can just go do like a very focused AI research effort. And I got excited about. That didn't even occur to me at the time to like possibly that this was all gonna get undone.  

我当时就想，"我现在在OpenAI的工作，就像是在经营一家规模不小的公司"。而我最喜欢的事情就是和研究人员一起工作。我当时想，是啊，我可以去做一个非常专注的人工智能研究工作。我很兴奋当时我甚至没有想到 这一切都会被推翻

This was like Friday afternoon. Oh, so you've accepted the death. Very quickly, very quickly. I mean, I went through like a little period of confusion and rage, but very quickly. And by Friday night, I was talking to people about what was gonna be next and I was excited about that.  

好像是周五下午这么说你已经接受了死亡很快，非常快我是说，我经历了一段时间的困惑和愤怒 但很快就过去了到了周五晚上，我开始和别人讨论 接下来会发生什么，我对此很兴奋

I think it was Friday night evening for the first time that I heard from the exec team here, which is like, hey, we're gonna like fight this and we think. Well, whatever. And then I went to bed just still being like, okay, excited. Like onward, were you able to sleep. Not a lot.  

我想那是周五晚上 我第一次听到这里的执行团队说 嘿，我们要去打这场仗，我们认为。随便吧然后我就上床睡觉了，仍然很兴奋。那你睡得着吗？没怎么睡

It was one of the weird things was there was this like period of four and a half days where sort of didn't sleep much, didn't eat much and still kind of had like a surprising amount of energy. You learn like a weird thing about adrenaline and more time. So you kind of accepted the death of this baby OpenAI. And I was excited for the new thing. I was just like, okay, this was crazy, but whatever.  

其中一个奇怪的现象是，在四天半的时间里，我没怎么睡觉，也没怎么吃东西，但仍然精力充沛。你学会了肾上腺素和更多时间的怪事。所以，你算是接受了 OpenAI 这个婴儿的死亡。我对新事物感到兴奋我只是想，好吧，这太疯狂了，但不管怎样。

It's a very good coping mechanism. And then Saturday morning, two of the board members called and said, "Hey, we destabilize. We didn't mean to destabilize things. We don't restore a lot of value here. Can we talk about you coming back?" And I immediately didn't wanna do that, but I thought a little more and I was like, "Well, I really care about the people here, the partners, shareholders.  

这是一个很好的应对机制。周六早上，两位董事会成员打来电话说："嘿，我们破坏了稳定。我们不是故意破坏稳定的。我们并没有在这里恢复很多价值。我们能谈谈你回来的事吗？"我立刻就不想这么做了，但我又想了一下，我说："我真的很关心这里的人，这里的合伙人，这里的股东。

I love this company." And so I thought about it and I was like, "Well, okay, but here's the stuff I would need." And then the most painful time of all over the course of that weekend, I kept thinking and being told. Not just me, like the whole team here kept thinking. Well, we were trying to keep OpenAI stabilized while the whole world was trying to break it apart, people trying to recruit, whatever.  

我喜欢这家公司我想了想说 "好吧 但这是我需要的东西"在那个周末最痛苦的时候 我一直在想，也一直被告知不只是我，整个团队都在思考。我们在努力让OpenAI保持稳定的同时，整个世界都在试图拆散它，人们试图招募员工，等等。

We kept being told like, "All right, we're almost done, we're almost done. We just need like a little bit more time." And it was this like very confusing state.  

我们一直被告知，"好了，我们快完成了，快完成了我们只是还需要一点时间"这让我们很困惑

And then Sunday evening when again like every few hours, I expected that we were gonna be done and we're gonna figure out a way for me to return and things to go back to how they were, the board then appointed a new interim CEO and then I was like. I mean, that feels really bad. That was the low point of the whole thing.  

然后周日晚上，每隔几个小时 我都在想，我们应该结束了 我们应该想个办法让我回去 一切都恢复原样 董事会任命了新的临时首席执行官我的意思是，这感觉真的很糟糕。那是整件事的最低点

You know, I'll tell you something, it felt very painful, but I felt a lot of love that whole weekend. It was not other than that one moment, Sunday night, I would not characterize my emotions as anger or hate, but I really just like. I felt a lot of love from people towards people. It was like painful, but it was like the dominant emotion of the weekend was love, not hate.  

我告诉你，那感觉非常痛苦，但我在整个周末都感受到了爱。除了周日晚上那一刻，我不会把我的情绪描述为愤怒或仇恨，我真的只是喜欢。我感受到了人们对人们的爱。虽然很痛苦，但周末的主要情绪是爱，而不是恨。

You've spoken highly of Mira Murati that she helped, especially as you put in a tweet, "In the quiet moments when it counts, perhaps we could take a bit of a tangent." What do you admire about Mira. Well, she did a great job during that weekend in a lot of chaos, but people often see leaders in the crisis moments, good or bad.  

你对米拉-穆拉提的评价很高，认为她帮了大忙，尤其是你在推特上写道："在关键时刻，也许我们可以来点切入点"。你欣赏米拉哪一点？在那个混乱的周末，她做得很好，但人们经常在危机时刻看到领导者，无论好坏。

But a thing I really value in leaders is how people act on a boring Tuesday at 9:46 in the morning and in just sort of the normal drudgery of the day-to-day, how someone shows up in a meeting, the quality of the decisions they make. That was what I meant about the quiet moments.  

但是，我非常看重领导者的一点是，在一个无聊的周二早上 9:46 的时候，人们是如何行动的，在日常的琐碎工作中，人们是如何出席会议的，他们所做决定的质量如何。这就是我所说的安静时刻。

Meaning like most of the work is done on a day by day in a meeting by meeting, just be present and make great decisions. Yeah. I mean, look, what you have wanted to spend the last 20 minutes about and I understand is like this one very dramatic weekend. But that's not really what OpenAI is about. OpenAI is really about the other seven years.  

我的意思是，大部分工作都是在一天天的会议中完成的，只要在场就能做出正确的决定。我的意思是，听着，你想用过去的 20 分钟来讨论的，我明白，就是这个非常戏剧性的周末。但这并不是OpenAI的真正意义所在。OpenAI的真正意义在于其他七年。

Well, yeah, human civilization is not about the invasion of the Soviet Union by Nazi Germany, but still that's something people totally focus on. Very understandable. It gives us an insight into human nature, the extremes of human nature, and perhaps some of the damage and some of the triumphs of human civilization can happen in those moments. So it's like illustrative.  

是的，人类文明与纳粹德国入侵苏联无关，但这仍然是人们关注的焦点。这是可以理解的。它让我们了解了人性，了解了人性的极端，也许人类文明的某些破坏和某些胜利就发生在那些时刻。因此，这很有说明性。

Let me ask you about Ilya. Is he being held hostage in a secret nuclear facility. No.  

让我问你关于伊利亚的事他被挟持到秘密核设施里了吗 Is he being held hostage in a secret nuclear facility.没有 No.

What about a regular secret facility. No. What about a nuclear non-secure facility. Neither, not that either. I mean, this is becoming a meme at some point. You've known Ilya for a long time. He was obviously part of this drama with the board and all that kind of stuff. What's your relationship with him now. I love Ilya. I have tremendous respect for Ilya. I don't have anything I can say about his plans right now.  

那普通的秘密设施呢？不，那非安全核设施呢？也不是我的意思是，这将成为一个备忘录 在某些时候。你认识伊利亚很久了 You've known Ilya for a long time.很明显他也参与了董事会之类的事你现在和他是什么关系我爱伊利亚。我非常尊重伊利亚。关于他现在的计划，我没什么好说的。

That's a question for him. But I really hope we work together for certainly the rest of my career. He's a little bit younger than me, maybe he works a little bit longer. There's a meme that he saw something, like he maybe saw AGI and that gave him a lot of worry internally. What did Ilya see. Ilya has not seen AGI, none of us have seen AGI. We've not built AGII.  

这是他的问题。但我真的希望我们能在我职业生涯的余下时间里一起工作。他比我年轻一点，也许他工作的时间更长一点。有一种说法是他看到了什么，比如他可能看到了AGI，这让他内心非常担忧。伊利亚看到了什么？伊利亚没有看到 AGI，我们都没有看到 AGI。我们也没有造出AGII

I do think one of the many things that I really love about Ilya is he takes AGI and the safety concerns broadly speaking, including things like the impact this is gonna have on society very seriously.  

我认为伊利亚让我喜欢的一点是，他非常认真地对待 AGI 和广义上的安全问题，包括这将对社会产生的影响等问题。

And as we continue to make significant progress, Ilya is one of the people that I've spent the most time over the last couple of years talking about what this is going to mean, what we need to do to ensure we get it right to ensure that we succeed at the mission. So Ilya did not see AGI.  

在我们不断取得重大进展的过程中，伊利亚是我在过去几年里花时间最多的人之一，他一直在和我讨论这将意味着什么，我们需要做什么来确保我们能够正确地完成使命。所以，伊利亚没有看到 AGI。

But Ilya is a credit to humanity in terms of how much he thinks and worries about making sure we get this right. I've had a bunch of conversation with him in the past. I think when he talks about technology, he's always like doing this long-term thinking type of thing. So he is not thinking about what this is gonna be in a year. He's thinking about in 10 years. Yeah.  

但伊利亚是人类的功臣，他为确保我们把事情办好，想了很多，也操了很多心。过去我和他有过多次交谈。我认为，当他谈论技术时，他总是喜欢做这种长期思考的事情。所以他不会考虑一年后会怎样。他考虑的是十年后是啊

Just thinking from first principles like, okay, if the scales, what are the fundamentals here? Where's this going? And so that's a foundation for them thinking about like all the other safety concerns and all that kind of stuff, which makes him a really fascinating human to talk with. Do you have any idea why he's been kind of quiet? Is it he's just doing some soul searching. Again, I don't wanna speak for Ilya.  

只是从第一原则出发，比如，好吧，如果天平，这里的基本原理是什么？这是要去哪里？这就是他们思考其他所有安全问题的基础 这也让他成为了一个非常迷人的人你知道他为什么不说话吗？他是不是在反省自己？我不想为伊利亚说话

I think that you should ask him that. He's definitely a thoughtful guy. I think I kind of think of Ilya as like always on a soul search in a really good way. Yes. Yeah. Also he appreciates the power of silence. Also, I'm told he can be a silly guy, which I've never seen that side of him. It's very sweet when that happens. I've never witnessed a silly Ilya, but I look forward to that as well.  

我觉得你应该问他这个问题。他绝对是个有思想的人我觉得伊利亚就像一直在寻找灵魂一样 很好的方式是啊 - Yes.是啊 Yeah.他还懂得沉默的力量我还听说他是个很傻的人 我从没见过他傻的一面这样的他很可爱我从来没见过傻乎乎的伊利亚 但我也很期待他这样

I was at a dinner party with him recently and he was playing with a puppy. And he was like in a very silly move, very endearing and I was thinking like, oh man, this is like not the side of the Ilya that the world sees the most. So just to wrap up this whole saga, are you feeling good about the board structure about all of this and where it's moving.  

最近我和他一起参加一个晚宴，他在和一只小狗玩耍。他的举动很傻，很可爱，我当时就在想，天哪，这不是外界看到最多的伊利亚的一面。最后，我想问一下，你对董事会的结构和未来的发展感觉如何？

I feel great about the new board. In terms of the structure of OpenAI, one of the board's tasks is to look at that and see where we can make it more robust. We wanted to get new board members in place first, but we clearly learned a lesson about structure throughout this process. I don't have I think super deep things to say. It was a crazy, very painful experience.  

我对新的董事会感觉很好。就 OpenAI 的结构而言，董事会的任务之一就是审视这一结构，看看我们能在哪些方面使其更加稳健。我们希望先让新的董事会成员到位，但在整个过程中，我们显然学到了关于结构的一课。我想我没什么好说的。这是一次疯狂而痛苦的经历。

I think it was like a perfect storm of weirdness. It was like a preview for me of what's gonna happen as the stakes get higher and higher and the need that we have like robust governance structures and processes and people. I am kind of happy it happened when it did, but it was a shockingly painful thing to go through. Did it make you be more hesitant in trusting people. Yes. Just on a personal level. Yes.  

我觉得这就像是一场怪异的完美风暴。对我来说，这就像是一场预演，预示着随着赌注越来越大，我们需要有强大的治理结构、流程和人员，将会发生什么。我很高兴事情就这么发生了，但经历这件事真是令人震惊的痛苦。这是否让你在信任别人时更加犹豫不决？是的。只是在个人层面上。是的。

I think I'm like an extremely trusting person. I've always had a life philosophy of like don't worry about all of the paranoia, don't worry about the edge cases. You get a little bit screwed in exchange for getting to live with your guard down. And this was so shocking to me. I was so caught off guard that it has definitely changed and I really don't like this.  

我觉得我是一个非常容易相信别人的人。我的人生哲学一直是，不要担心所有的偏执狂，不要担心边缘案例。你得到了一点点拧 交换得到生活 与你的后卫下来。这让我很震惊我猝不及防，这一切都改变了，我真的不喜欢这样。

It's definitely changed how I think about just like default trust of people and planning for the bad scenarios. You gotta be careful with that. Are you worried about becoming a little too cynical. I'm not worried about becoming too cynical. I think I'm like the extreme opposite of a cynical person. But I'm worried about just becoming like less of a default trusting person.  

这无疑改变了我的想法，比如默认信任他人，以及为坏的情况做打算。这一点你得小心。你会担心自己变得过于愤世嫉俗吗？我不担心变得太愤世嫉俗。我觉得我就像是愤世嫉俗者的极端反面。但我担心自己会变得不那么信任别人

I'm actually not sure which mode is best to operate in for a person who's developing AGI, trusting or untrusting. It's an interesting journey you're on. But in terms of structure, see, I'm more interested on the human level. How do you surround yourself with humans that are building cool shit, but also are making wise decisions? Because the more money you start making, the more power the thing has the weirder people get.  

实际上，我也不确定对于一个正在开发 AGI 的人来说，哪种操作模式是最好的，信任还是不信任。这是你正在经历的一段有趣的旅程。但就结构而言，我对人类层面更感兴趣。你如何让自己身边的人既能创造出酷炫的东西 又能做出明智的决定？因为你赚的钱越多 权力越大 人们就越古怪

I think you could make all kinds of comments about the board members and the level of trust I should have had there or how I should have done things differently. But in terms of the team here, I think you'd have to like give me a very good grade on that one. And I have just like enormous gratitude and trust and respect for the people that I work with every day.  

我想你可以对董事会成员和我本应得到的信任程度或我本应如何以不同的方式做事发表各种评论。但就这里的团队而言，我想你必须给我打一个非常好的分数。我对每天与我共事的人充满感激、信任和尊重。

And I think being surrounded with people like that is really important.  

我认为，身边有这样的人真的很重要。

Our mutual friend Elon sued OpenAI. What is the essence of what he's criticizing? To what degree does he have a point? To what degree is he wrong. I don't know what it's really about. We started off just thinking we were gonna be a research lab and having no idea about how this technology was gonna go.  

我们共同的朋友埃隆起诉了 OpenAI。他批评的实质是什么？他在多大程度上有道理？他错到什么程度？我不知道这到底是怎么回事。我们一开始只是想做一个研究实验室 对这项技术的发展一无所知

Because it was only seven or eight years ago, it's hard to go back and really remember what it was like then. But before language models were a big deal, this was before we had any idea about an API or selling access to a chat bot. It was before we had any idea we were gonna productize at all.  

因为那只是七八年前的事了，我们很难回想起来当时的情景。但在语言模型大行其道之前，我们对 API 或出售聊天机器人权限还没有任何概念。那时候，我们根本不知道自己要产品化。

So we're like we're just gonna try to do research and we don't really know what we're gonna do with that. I think with many new fundamentally new things, you start fumbling through the dark and you make some assumptions, most of which turn out to be wrong. And then it became clear that we were going to need to do different things and also have huge amounts more capital.  

所以我们只是想做一些研究，但并不知道要做什么。我认为，对于许多全新的、根本性的事物来说，你开始在黑暗中摸索，你会做出一些假设，而这些假设大部分都是错误的。然后很明显，我们需要做不同的事情，还需要更多的资金。

So we said, "Okay, well, the structure doesn't quite work for that. How do we patch the structure?" And then you patch it again and patch it again and you end up with something that does look kind of eyebrow raising to say the least.  

于是我们说："好吧，这个结构并不完全适用。我们该怎么修补结构呢？""然后，你再修补，再修补，最后得到的东西至少看起来有点让人瞠目结舌。

But we got here gradually with I think reasonable decisions at each point along the way and doesn't mean I wouldn't do it totally differently if we could go back now with an oracle, but you don't get the oracle at the time. But anyway, in terms of what Elon's real motivations here are I don't know. To the degree you remember, what was the response that OpenAI gave in the blog post? Can you summarize it.  

但我们是逐步走到这一步的，我认为沿途的每一个点都做出了合理的决定，这并不意味着如果我们现在能回到过去，我不会做出完全不同的决定，但你当时并没有得到神谕。但无论如何，我不知道埃隆的真正动机是什么。在你还记得的范围内，OpenAI 在博文中给出的回应是什么？你能总结一下吗？

Oh, we just said like Elon said this set of things, here's our characterization or here's this sort of not our characterization, here's like the characterization of how this went down. We tried to not make it emotional and just sort of say like here's the history. I do think there's a degree of mischaracterization from Elon here about one of the points you just made, which is the degree of uncertainty you had at the time.  

我们只是说，埃隆说了这一系列事情，这是我们的描述，或者说这不是我们的描述，这是事情经过的描述。我们尽量避免情绪化，只说历史是这样的。我认为埃隆对你刚才提到的其中一点有一定程度的误解，那就是你当时的不确定程度。

You guys are a bunch of like a small group of researchers crazily talking about AGI when everybody's laughing at that thought. Wasn't that long ago Elon was crazily talking about launching rockets when people were laughing at that thought? So I think he'd have more empathy for this. I mean, I do think that there's personal stuff here that there was a split that OpenAI and a lot of amazing people here chose to part ways of Elon.  

你们这帮人就像一小群研究人员，当所有人都在嘲笑AGI的时候，你们却在疯狂地谈论AGI。不久前，埃隆还在疯狂地谈论发射火箭，当时人们还在嘲笑这个想法呢。所以我觉得他会对此有更多的共鸣。我的意思是，我确实认为这里面有个人因素，OpenAI和这里很多了不起的人选择了与埃隆分道扬镳。

So there's a personal. Elon chose to part ways. Can you describe that exactly, the choosing to part ways. He thought OpenAI was gonna fail. He wanted total control to sort of turn it around. We wanted to keep going in the direction that now has become OpenAI. He also wanted Tesla to be able to build an AGI effort.  

这就是私人恩怨。埃隆选择了分道扬镳。你能具体描述一下他选择分道扬镳的原因吗？他认为OpenAI会失败他想完全掌控局面，扭转乾坤。我们想继续朝着现在的方向发展，现在已经成为了OpenAI。他也希望特斯拉能够建立一个AGI。

At various times, he wanted to make OpenAI into a for-profit company that he could have control of or have it merged with Tesla. We didn't want to do that and he decided to leave, which that's fine. And that's one of the things that the blog post says is that he wanted OpenAI to be basically acquired by Tesla in those same way that or maybe something similar or maybe something more dramatic than the partnership with Microsoft.  

在不同时期，他都想把 OpenAI 变成一家营利性公司，由他来控制，或者与特斯拉合并。我们不想这么做，于是他决定离开，这很好。博文中提到的其中一件事是，他希望 OpenAI 能以同样的方式被特斯拉收购，或许是类似的方式，或许是比与微软合作更戏剧化的方式。

My memory is the proposal was just like, yeah, like get acquired by Tesla and have Tesla have full control over it. I'm pretty sure that's what it was. So what is the word open in OpenAI mean to Elon at the time? Ilya has talked about this in the email exchanges and all this kind of stuff. What does it mean to you at the time? What does it mean to you now.  

在我的记忆中，当时的提议就像是被特斯拉收购，然后由特斯拉全权控制。我很确定就是这样。对埃隆来说，OpenAI 中的开放一词在当时意味着什么？伊利亚曾在邮件交流中谈到过这一点，以及所有诸如此类的东西。当时对你意味着什么？现在对你又意味着什么。

I would definitely pick a diff. Speaking of going back with an oracle, I'd pick a different name. One of the things that I think OpenAI is doing that is the most important of everything that we're doing is putting powerful technology in the hands of people for free as a public good. We don't run ads on our free version. We don't monetize it in other ways. We just say it's part of our mission.  

我肯定会选一个不同的。说到用甲骨文回去，我会取一个不同的名字。我认为，OpenAI 所做的一切中最重要的一件事，就是将强大的技术作为公益事业免费提供给人们。我们的免费版本上没有广告。我们不以其他方式盈利。我们只是说，这是我们使命的一部分。

We wanna put increasingly powerful tools in the hands of people for free and get them to use them. And I think that kind of open is really important to our mission. I think if you give people great tools and teach them to use them or don't even teach them, they'll figure it out and let them go build an incredible future for each other with that. That's a big deal.  

我们希望把越来越强大的工具免费提供给人们，让他们使用。我认为这种开放性对我们的使命非常重要。我认为，如果你给人们提供强大的工具，并教他们如何使用，或者根本不教他们，他们就会自己摸索出来，然后用这些工具为彼此创造一个不可思议的未来。这是一件大事。

So if we can keep putting free or low cost or free and low cost powerful AI tools out in the world, I think that's a huge deal for how we fulfill the mission. Open source or not, yeah, I think we should open source some stuff and not other stuff. It does become this like religious battle line where nuance is hard to have, but I think nuance is the right answer.  

因此，如果我们能继续向世界提供免费或低成本的强大人工智能工具，我认为这对我们完成使命意义重大。开源与否，是的，我认为我们应该开源一些东西，而不是其他东西。这就像宗教战线，很难有细微差别，但我认为细微差别才是正确答案。

So he said change your name to ClosedAI and I'll drop the lawsuit. I mean, is it going to become this battleground in the land of memes about the name. I think that speaks to the seriousness with which Elon means the lawsuit. I mean, that's like an astonishing thing to say, I think. Well, I don't think the lawsuit maybe, correct me if I'm wrong, but I don't think the lawsuit is legally serious.  

所以他说把你的名字改成ClosedAI 我就撤诉我的意思是，这是否会成为关于名字的备忘录的战场。我认为这说明了埃隆对这起诉讼的重视程度。我觉得这话说得太惊人了如果我说错了，请纠正我，我不认为这起诉讼在法律上是严肃的。

It's more to make a point about the future of AGI and the company that's currently leading the way. Look, I mean Grok had not open sourced anything until people pointed out it was a little bit hypocritical and then he announced that Grok open source things this week. I don't think open source versus not is what this is really about for him. Well, we'll talk about open source and not.  

这更多是为了说明 AGI 的未来，以及这家公司目前的领先地位。听着，我的意思是，Grok一直没有开源任何东西，直到人们指出这有点虚伪，他才在本周宣布Grok开源。我不认为开源与否是他的真正目的。好吧，我们来谈谈开源和不开源。

I do think maybe criticizing the competition is great, just talking a little shit, that's great, but friendly competition versus like I personally hate lawsuits. Look, I think this whole thing is like unbecoming of a builder, and I respect Elon is one of the great builders of our time. And I know he knows what it's like to have like haters attack him and it makes me extra sad he's doing the toss.  

我确实认为批评竞争对手是件好事，说点屁话也是好事，但友好竞争与我个人讨厌的诉讼相比，那就不一样了。听着，我认为这整件事不符合一个建筑商的身份，我尊重埃隆，他是我们这个时代最伟大的建筑商之一。我知道他很清楚仇敌攻击他的感受 这让我对他的行为感到非常难过

Yeah, he is one of the greatest builders of all time, potentially the greatest builder of all time. It makes me sad. And I think it makes a lot of people sad. There's a lot of people who've really looked up to him for a long time and said this. I said in some interview or something that I missed the old Elon and the number of messages I got being like that exactly encapsulates how I feel.  

是的，他是有史以来最伟大的建筑师之一，有可能是有史以来最伟大的建筑师。这让我很难过。我想这也让很多人难过。有很多人在很长一段时间里都非常仰慕他，并说过这样的话。我在某次采访中说，我很怀念以前的埃隆，而我收到的很多留言都是这样的，这完全概括了我的感受。

I think he should just win. He should just make Grok beat GPT and then GPT beats Grok and it's just a competition, and it's beautiful for everybody. But on the question of open source, do you think there's a lot of companies playing with this idea? It's quite interesting.  

我认为他应该赢。他应该让 Grok 击败 GPT，然后让 GPT 击败 Grok，这只是一场竞争，对每个人来说都很美好。但关于开放源代码的问题，你认为是否有很多公司都在玩这个概念？这很有趣。

I would say Meta, surprisingly, has led the way on this or like at least took the first step in the game of chess of really open sourcing the model. Of course, it's not the state of the art model, but open sourcing Llama and Google is flirting with the idea of open sourcing a smaller version. What are the pros and cons of open sourcing? Have you played around with this idea.  

令人惊讶的是，Meta 公司在这方面走在了前列，或者说至少在真正开源该模型的棋局中迈出了第一步。当然，这并不是最先进的模式，但Llama已经开源，谷歌也在考虑开源一个更小的版本。开源的利弊是什么？你是否也有过这样的想法？

Yeah, I think there is definitely a place for open source models, particularly smaller models that people can run locally, I think there's huge demand for. I think there will be some open source models, there will be some closed source models. It won't be unlike other ecosystems in that way.  

是的，我认为开源模式肯定会有一席之地，尤其是人们可以在本地运行的小型模式，我认为有巨大的需求。我认为会有一些开源模式，也会有一些闭源模式。这与其他生态系统并无不同。

I listened to all in podcasts talking about this lawsuit and all that kind of stuff and they were more concerned about the precedent of going from nonprofit to this cap for profit. What precedent that sets for other startups. I would heavily discourage any startup that was thinking about starting as a non-profit and adding like a for-profit arm later. I'd heavily discourage them from doing that. I don't think we'll set a precedent here. Okay.  

我在播客中听到很多人都在谈论这场官司和所有这些事情，他们更关心的是，从非营利到盈利的先例。这给其他初创企业开了什么先例。我非常不鼓励任何初创公司考虑从非营利性开始，然后再增加一个营利性分支。我不鼓励他们这么做。我不认为我们会开创先例。好吧

So most startups should go just. For sure. And again, if we knew what was gonna happen, we would've done that too. Well, like in theory, if you like dance beautifully here, there's like some tax incentives or whatever-But I don't think that's like how most people think about these things. Just not possible to save a lot of money for a startup if you do it this way.  

因此，大多数初创企业都应该 "走出去"。当然再说一遍，如果我们知道会发生什么，我们也会这么做的。 And again, if we knew what was gonna happen, we would've done that too.理论上说，如果你在这里跳得好，会有一些税收优惠什么的，但我觉得大多数人不会这么想。如果这样做，不可能为创业公司省下一大笔钱。

No, I think there's like laws that would make that pretty difficult. Where do you hope this goes with Elon? Well, this tension, this dance, what do you hope this? Like if we go one, two, three years from now, your relationship with him on a personal level too, like friendship, friendly competition, just all this kind of stuff. Yeah. I mean, I really respect Elon. And I hope that years in the future, we have an amicable relationship.  

不，我认为法律会让这变得非常困难。你希望埃隆怎么做？这种紧张关系，这种舞蹈，你希望怎样？从现在起的一两年或三年内 你和他在个人层面上的关系 比如友谊 友谊竞争之类的东西是的，我真的很尊敬埃隆。我希望在未来的几年里，我们能保持友好的关系。

Yeah, I hope you guys have an amicable relationship like this month and just compete and win and explore these ideas together. I do suppose there's competition for talent or whatever, but it should be friendly competition. Just build, build cool shit. And Elon is pretty good at building cool shit, but so are you.  

是啊，我希望你们能像这个月一样友好相处，一起竞争，一起获胜，一起探索这些想法。我想这是人才竞争或其他方面的竞争，但应该是友好的竞争。只是建造，建造很酷的东西。埃隆很擅长制造很酷的东西，但你也一样。

So speaking of cool shit. Sora, there's like a million questions I could ask.  

说到酷索拉，我可以问你无数个问题

First of all, it's amazing, it truly is amazing on a product level, but also just on a philosophical level. So let me just technical/philosophical ask. What do you think it understands about the world more or less than GPT-4, for example, like the world model when you train on these patches versus language tokens. I think all of these models understand something more about the world model than most of us give them credit for.  

首先，它很神奇，在产品层面确实很神奇，但在哲学层面也很神奇。那么，让我从技术/哲学角度问一下。你认为它对世界的理解比 GPT-4 多或少，例如，当你在这些补丁和语言标记上进行训练时，它对世界模型的理解是怎样的？我认为所有这些模型对世界模型的理解都比我们大多数人认为的要多。

And because they're also very clear things they just don't understand or don't get right, it's easy to look at the weaknesses, see through the veil and say this is all fake, but it's not all fake. It's just some of it works and some of it doesn't work.  

因为他们也很清楚自己不理解或不正确的地方，所以很容易看到弱点，看穿面纱，说这都是假的，但其实并不全是假的。只是有些有用，有些没用。

I remember when I started first watching Sora videos and I would see like a person walk in front of something for a few seconds and occlude it and then walk away and the same thing was still there. I was like, "This is pretty good." Or there's examples where the underlying physics looks so well represented over a lot of steps in a sequence. It's like oh this is like quite impressive.  

我记得刚开始看索拉视频的时候，我会看到一个人在某样东西前走几秒钟，然后把它遮住，然后走开，同样的东西还在那里。我就想，"这很不错"。还有一些例子，在一个序列的很多步骤中，底层物理看起来都表现得很好。就像哦，这真是令人印象深刻。

But, fundamentally, these models are just getting better and that will keep happening. If you look at the trajectory from DALL·E 1 to 2 to 3 to Sora, there were a lot of people that were dunked on each version, saying it can't do this, it can't do that and I'm like look at it now.  

但从根本上说，这些模型正在变得越来越好，而且这种情况还会继续发生。如果你看看《达利1》、《达利2》、《达利3》到《索拉》的发展轨迹，每一个版本都有很多人说它做不到这一点，做不到那一点。

Well, the thing you just mentioned is kind of with the occlusions is basically modeling the physics of three dimensional physics of the world sufficiently well to capture those kinds of things. Well. Yeah, maybe you can tell me in order to deal with occlusions, what does the world model need to. Yeah, so what I would say is it's doing something to deal with occlusions really well.  

你刚才提到的 "遮挡物 "基本上是对世界三维物理的建模，足以捕捉到这些东西。好吧也许你能告诉我，为了处理遮挡物，世界模型需要什么？是的，所以我想说的是，它正在做一些事情来很好地处理遮挡物。

What I represent that it has like a great underlying 3D model of the world. It's a little bit more of a stretch-But can you get there through just these kinds of two dimensional training data approaches. It looks like this approach is gonna go surprisingly far. I don't wanna speculate too much about what limits it will surmount and which it won't. What are some interesting limitations of the system that you've seen?  

我所代表的，是一个伟大的底层三维世界模型。但你能通过这种二维训练数据的方法达到目的吗？看起来这种方法能走得更远我不想过多猜测它能突破哪些限制，哪些不能。你认为该系统有哪些有趣的局限性？

I mean, there's been some fun ones you've posted. There's all kinds of fun. I mean, like cats sprouting a extra limit at random points in a video, like pick what you want, but there's still a lot of problem, there's a lot of weaknesses. Do you think that's a fundamental flaw of the approach or is it just bigger model or better technical details or better data, more data is going to solve the cat sprouting extremes.  

我的意思是，你贴出了一些有趣的照片。什么好玩的都有。我的意思是，就像猫在视频中的随机点萌发出额外的限制，就像随心所欲，但还是有很多问题，有很多弱点。你认为这是方法的根本缺陷，还是模型更大、技术细节更好、数据更多，更多的数据就能解决猫萌发极端的问题？

I would say yes to both. I think there is something about the approach which just seems to feel different from how we think and learn and whatever. And then also, I think it'll get better with scale. I mentioned LLMs have tokens, text tokens and Sora has visual patches so it converts all visual data, a diverse kinds of visual data videos and images into patches. Is the training to the degree you can say fully self-supervised there?  

我觉得两者都可以。我认为，这种方法与我们的思维方式、学习方式等似乎有些不同。另外，我认为随着规模的扩大，这种方法会越来越好。我提到LLMs有标记、文本标记，而索拉有视觉补丁，因此它能将所有视觉数据、各种视觉数据、视频和图像转换成补丁。训练是否达到了你所说的完全自我监督的程度？

Is there some manual labeling going on? What's the involvement of humans in all this. I mean, without saying anything specific about the Sora approach, we use lots of human data in our work. But not internet scale data. So lots of humans, lots of complicated word, Sam. I think lots is a fair word in this case.  

是否存在人工贴标签的情况？人类在其中的参与程度如何？我的意思是，不说索拉方法的具体情况，我们在工作中使用了大量人类数据。但不是互联网规模的数据。所以，很多人类，很多复杂的词，萨姆。我认为在这种情况下，"大量 "这个词很恰当。

But it doesn't because to me, lots, like listen, I'm an introvert and when I hang out with like three people, that's a lot of people. Yeah, four people, that's a lot. But I suppose you mean more than. More than three people work on labeling the data for these models, yeah. Okay. All right. But fundamentally, there's a lot of self-supervised learning. 'cause what you mentioned in the technical report is internet scale data.  

但我不这么认为，因为对我来说，很多人，比如听着，我是个内向的人，当我和三个人一起出去玩时，那就是很多人了。是啊，四个人，也不少了但我想你的意思是超过不止三个人在为这些模型标注数据 是的好吧 - 好吧 - Okay.All right.但从根本上说 有很多自我监督学习因为你在技术报告中提到的是互联网规模的数据

That's another beautiful, it's like poetry. So it's a lot of data that's not human label. It's self-supervised in that way. And then the question is, how much data is there on the internet that could be used in this that is conducive to this kind of self-supervised way if only we knew the details of the self-supervised? Do you have you considered opening it up a little more details-We have. You mean, for source specifically.  

这是另一种美，就像诗歌一样。所以有很多数据是没有人类标签的。这种方式是自我监督的。那么问题来了，如果我们知道自我监督的细节，互联网上有多少数据可以用于这种有利于自我监督的方式呢？你有没有考虑过开放更多的细节？你是说，具体到源代码。

Source specifically because it's so interesting. Can the same magic of LLMs now start moving towards visual data and what does that take to do that. I mean, it looks to me like yes, but we have more work to do. Sure. What are the dangers? Why are you concerned about releasing the system? What are some possible dangers of this.  

来源，特别是因为它非常有趣。现在，LLMs的魔力能否开始转向可视化数据？我的意思是，在我看来可以，但我们还有更多工作要做。当然，有什么危险吗？你为什么担心发布这个系统？有哪些可能的危险？

I mean, frankly speaking, one thing we have to do before releasing the system is just like get it to work at a level of efficiency that will deliver the scale people are gonna want from this. So that I don't wanna like downplay that and there's still a ton of work to do there. But you can imagine like issues with deep fakes, misinformation.  

坦率地说，在发布系统之前，我们要做的一件事就是让它的工作效率达到人们想要的水平。所以我不想轻描淡写地说这一点 还有很多工作要做但你可以想象，这就像深度伪造、错误信息的问题。

We try to be a thoughtful company about what we put out into the world and it doesn't take much thought to think about the ways this can go badly. There's a lot of tough questions here. You're dealing in a very tough space. Do you think training AI should be or is fair use under copyright law.  

我们努力成为一家深思熟虑的公司，对我们向世界发布的东西深思熟虑。这里有很多棘手的问题。你们所处的领域非常艰难。你认为根据版权法，训练人工智能应该是或应该是合理使用吗？

I think the question behind that question is, do people who create valuable data deserve to have some way that they get compensated for use of it? And that I think the answer is yes. I don't know yet what the answer is. People have proposed a lot of different things. We've some tried some different models.  

我认为这个问题背后的问题是，那些创造了有价值数据的人是否应该通过某种方式获得使用数据的报酬？我认为答案是肯定的。我还不知道答案是什么。人们提出了很多不同的建议。我们也尝试过一些不同的模式。

But if I'm like an artist, for example, I would like to be able to opt out of people generating art in my style and B, if they do generate art in my style, I'd like to have some economic model associated with that. Yeah, it's that transition from CDs to Napster to Spotify. We have to figure out some kind of model. The model changes, but people have gotta get paid.  

但是，如果我是一个艺术家，比如说，我希望能够选择拒绝别人按照我的风格创作艺术作品；B，如果他们按照我的风格创作艺术作品，我希望能够有一些与之相关的经济模式。是的，这就是从 CD 到 Napster 再到 Spotify 的过渡。我们必须找出某种模式。模式会变，但人们必须得到报酬。

Well, there should be some kind of incentive if we zoom out even more for humans to keep doing cool shit. Everything I worry about, humans are gonna do cool shit and society's gonna find some way to reward it. That seems pretty hardwired. We want to create. We want to be useful. We want to achieve status in whatever way that's not going anywhere, I don't think. But the reward might not be monetary, financial.  

好吧，如果我们再放大一些 应该会有某种激励机制 让人类继续做很酷的事我所担心的一切，都是人类会做很酷的事 社会也会想办法奖励他们这似乎是天生的我们想要创造。我们想成为有用的人我们想以任何方式获得地位 我想这是不会改变的但奖励可能不是金钱或经济上的

It might be like fame and celebration of other cool. Maybe financial in some other way. Again, I don't think we've seen like the last evolution of how the economic system's gonna work. Yeah. But artists and creators are worried. When they see Sora, they're like, "Holy shit. Sure. Artists were also super worried when photography came out. And then photography became a new art form and people made a lot of money taking pictures.  

它可能是名声和其他很酷的庆祝活动。也可能是其他方面的经济效益再说一遍，我觉得我们还没看到 经济系统如何运作的最后一次演变是啊但艺术家和创作者都很担心当他们看到索拉时，他们会说 "我的天啊当然，摄影术出现的时候 艺术家们也超级担心然后摄影成为了一种新的艺术形式 人们靠拍照赚了很多钱

And I think things like that will keep happening. People will use the new tools in new ways. If we just look on YouTube or something like this, how much of that will be using Sora, like AI-generated content do you think in the next five years.  

我认为这样的事情会不断发生。人们会以新的方式使用新的工具。如果我们只看 YouTube 或类似的东西，你认为在未来五年内，有多少会使用 Sora，比如人工智能生成的内容。

People talk about like how many jobs is AI gonna do in five years and the framework that people have is what percentage of current jobs are just gonna be totally replaced by some AI doing the job? The way I think about it is not what percent of jobs AI will do, but what percent of tasks will AI do and over what time horizon.  

人们谈论人工智能将在五年内完成多少工作，人们的框架是，人工智能将完全取代现有工作的百分比是多少？我的想法不是人工智能将取代百分之多少的工作，而是人工智能将在多长时间内取代百分之多少的任务。

So if you think of all of the like-five second tasks in the economy, five-minute tasks, the five-hour tasks, maybe even the five-day tasks, how many of those can AI do?  

因此，如果你想一想经济中所有类似五秒钟的任务、五分钟的任务、五小时的任务，甚至是五天的任务，人工智能能完成多少？

And I think that's a way more interesting, impactful, important question than how many jobs AI can do because it is a tool that will work at increasing levels of sophistication and over longer and longer time horizons for more and more tasks and let people operate at a higher level of abstraction. So maybe people are way more efficient at the job they do.  

我认为这是一个比人工智能能做多少工作更有趣、更有影响力、更重要的问题，因为人工智能是一种工具，它的复杂程度会越来越高，时间跨度会越来越长，能完成的任务也会越来越多，让人们在更高的抽象水平上工作。因此，也许人们在他们所做的工作中效率更高。

And at some point, that's not just a quantitative change, but it's a qualitative one too about the kinds of problems you can keep in your head. I think that for videos on YouTube, it'll be the same. Many videos, maybe most of them, will use AI tools in the production, but they'll still be fundamentally driven by a person thinking about it, putting it together, doing parts of it, sort of directing it and running it.  

在某种程度上，这不仅是量的变化，也是质的变化，关系到你能把什么样的问题记在脑子里。我认为，YouTube 上的视频也会如此。许多视频，也许是大多数视频，都会在制作过程中使用人工智能工具，但从根本上说，它们仍将由一个人来思考、组合、完成其中的一部分、指导和运行。

Yeah, it's so interesting. I mean, it's scary, but it's interesting to think about. I tend to believe that humans like to watch other humans or other human like. Humans really care about other humans a lot. Yeah. If there's a cooler thing that's better than a human, humans care about that for like two days and then they go back to humans. That seems very deeply wired. It's the whole chest thing.  

是啊，太有意思了我的意思是，这很可怕，但想想也很有趣。我倾向于认为人类喜欢观察其他人类 或者其他人类喜欢的东西人类真的很关心其他人类如果有比人类更酷的东西 人类会关心两天 然后又回到人类身边这似乎是非常深刻的这就是胸怀

But now let's everybody keep playing chess and let's ignore the alpha in the room that humans are really bad at chess relative to AI systems. We still run races and cars are much faster. I mean, there's like a lot of examples. Yeah. And maybe it'll just be tooling like in the Adobe suite type of way where it can just make videos much easier and all that kind of stuff.  

但现在，让我们继续下棋吧，不要去理会房间里的阿尔法，相对于人工智能系统，人类的棋艺真的很差。我们还在赛跑，而汽车要快得多。这样的例子多了去了是啊也许它只是一个工具，就像Adobe套件那样，可以让视频制作更简单，诸如此类。

Listen, I hate being in front of the camera. If I can figure out a way to not be in front of the camera, I would love it. Unfortunately, it'll take a while. Like that generating faces, it's getting there, but generating faces and video format is tricky when it's specific people versus generic people.  

听着，我讨厌在镜头前。如果我能想出不在镜头前的办法，我会很乐意的。不幸的是，这需要一段时间。就像生成人脸一样，我正在努力，但生成人脸和视频格式是个难题，因为是特定的人还是一般的人。

Let me ask you about GPT-4. There's so many questions. First of all, also amazing.  

让我问你关于 GPT-4 的问题。问题太多了。首先，也很神奇。

Looking back, it'll probably be this kind of historic pivotal moment with three, five, and four which had GPT. Maybe five will be the pivotal moment. I don't know. Hard to say that looking forwards. We never know. That's the annoying thing about the future, it's hard to predict. But for me, looking back GPT-4, ChatGPT is pretty impressive, historically impressive. So allow me to ask, what's been the most impressive capabilities of GPT-4 to you and GPT-4 Turbo.  

回首往事，三、五、四期的 GPT 可能会成为历史性的关键时刻。也许五号会是关键时刻。我不知道。展望未来，很难说。我们永远不知道。这就是未来的恼人之处，很难预测。但对我来说，回顾GPT-4，ChatGPT给人留下了深刻印象，在历史上令人印象深刻。那么，请允许我问一下，GPT-4 给您和 GPT-4 Turbo 留下的最深刻印象是什么？

I think it kind of sucks. Hmm. Typical human also gotten used to an awesome thing. No, I think it is an amazing thing, but relative to where we need to get to and where I believe we will get to, at the time of like GPT-3, people were like, "Oh this is amazing. This is this like marvel of technology," and it is, it was.  

我觉得这有点糟糕。嗯典型的人类也习惯了一件了不起的事情。不，我认为这是一件了不起的事情，但相对于我们需要到达的地方，以及我相信我们会到达的地方，在像GPT-3的时候，人们会说，"哦，这太神奇了。这是科技的奇迹"，的确如此。

But now we have GPT-4 and look at GPT-3 and you're like that's unimaginably horrible. I expect that the delta between five and four will be the same as between four and three. And I think it is our job to live a few years in the future and remember that the tools we have now are gonna kind of suck looking backwards at them and that's how we make sure the future is better.  

但现在我们有了 GPT-4，再看看 GPT-3，你就会觉得这简直太可怕了。我预计，5 级和 4 级之间的差距将与 4 级和 3 级之间的差距相同。我认为，我们的工作就是活在未来的几年里，记住我们现在所拥有的工具会很糟糕，但我们可以向后看，这样才能确保未来会更好。

What are the most glorious ways that GPT-4 sucks? Meaning. What are the best things it can do. What are the best things it can do in the limits of those best things that allow you to say it sucks, therefore gives you an inspiration and hope for the future. One thing I've been using it for more recently is sort of a like a brainstorming partner. Yep. Almost for that. There's a glimmer of something amazing in there.  

GPT-4 最光彩夺目的地方是什么？意思是它能做的最好的事情是什么？它能做的最好的事情是什么？在这些最好的事情的范围内，你可以说它很烂，因此给你一个灵感和对未来的希望。我最近一直在用它来做一件事，就像是一个头脑风暴伙伴。没错。几乎就是这样。里面闪烁着令人惊叹的光芒。

I don't think it gets. When people talk about it, what it does, they're like, "Helps me code more productively. It helps me write more faster and better. It helps me translate from this language to another," all these like amazing things. But there's something about the kind of creative brainstorming partner. I need to come up with a name for this thing. I need to think about this problem in a different way.  

我不这么认为。当人们谈到它的作用时，他们会说："它能帮助我更有效地编写代码。它能帮我写得更快、更好。它能帮我把这种语言翻译成另一种语言"，所有这些都是令人惊奇的事情。但有一些关于创意头脑风暴伙伴的东西。我需要为这个东西取个名字。我需要换一种方式来思考这个问题。

I'm not sure what to do here. That I think like gives a glimpse of something I hope to see more of. One of the other things that you can see a very small glimpse of is what I can help on longer horizon tasks. Break down something in multiple steps, maybe execute some of those steps, search the internet, write code, whatever. Put that together.  

我不知道该怎么办。我觉得这让我看到了希望看到更多的东西。还有一点，你可以从我的工作中窥见一二，那就是我可以帮助你完成更长远的任务。把事情分解成多个步骤，也许执行其中的一些步骤，搜索互联网，编写代码，等等。把这些放在一起。

When that works, which is not very often, it's like very magical,-The iterative back and forth with a human. It works a lot for me. What do you mean it works. Iterative back and forth to human, it can get more often, when it can go do like a 10-step problem on its own. It doesn't work for that too often sometimes. Add multiple layers of abstraction or do you mean just sequential.  

当这种方法奏效的时候，虽然并不常见，但却非常神奇。这对我很有用什么意思？与人类的来回迭代，它可以更频繁，当它可以去做像一个10步的问题在它自己的。有时它并不经常起作用。是增加多层抽象，还是仅仅是顺序？

Both like to break it down and then do things that different layers of abstraction put them together. Look, I don't wanna downplay the accomplishment of GPT-4, but I don't wanna overstate it either. And I think this point that we are on an exponential curve, we'll look back relatively soon at GPT-4 like we look back at GPT-3 now.  

两者都喜欢将其分解，然后通过不同的抽象层将它们组合在一起。听着，我不想贬低 GPT-4 的成就，但也不想夸大它。我认为，我们正处在一个指数曲线上，我们很快就会回过头来看 GPT-4，就像我们现在回过头来看 GPT-3。

That said, I mean ChatGPT was the transition to where people like started to believe there is an uptick of believing. Not internally at OpenAI perhaps. There's believers here, but when you think. And in that sense, I do think it'll be a moment where a lot of the world went from not believing to believing. That was more about the ChatGPT interface.  

话虽如此，但我的意思是，ChatGPT是人们开始相信信仰的过渡时期。也许在OpenAI内部并非如此。这里是有信徒，但当你去思考的时候。从这个意义上说，我认为这将是世界上很多人从不曾相信到相信的时刻。这更多是关于 ChatGPT 界面。

And by the interface and product, I also mean the post-training of the model and how we tune it to be helpful to you and how to use it than the underlying model itself. How much of each of those things are important? The underlying model and the RLHF or something of that nature that tunes it to be more compelling to the human, more effective and productive for the human.  

我所说的界面和产品，还指模型的后期训练，以及我们如何调整模型使其对你有所帮助，以及如何使用它，而不是底层模型本身。这些东西各自有多重要？底层模型和 RLHF 或类似的东西，它们能使模型对人类更有吸引力，对人类更有效，更有生产力。

I mean, they're both super important but the RLHF, the post-training step, the little wrapper of things that from a compute perspective, little wrapper of things that we do on top of the base model, even though it's a huge amount of work. That's really important to say nothing of the product that we build around it. In some sense, we did have to do two things.  

我的意思是，它们都超级重要，但 RLHF、后训练步骤、从计算角度看的小包装、我们在基础模型之上做的小包装，尽管工作量巨大。这一点非常重要，我们围绕它构建的产品就更不用说了。从某种意义上说，我们必须做两件事。

We had to invent we underlying technology and then we had to figure out how to make it into a product people would love, which is not just about the actual product work itself, but this whole other step of how you align it and make it useful-And how you make the scale work where a lot of people can use it at the same time, all that kind of stuff. But that was like a known difficult thing.  

我们必须先发明底层技术，然后再想办法把它变成人们喜欢的产品，这不仅仅是产品本身，还包括如何调整产品并使其有用，以及如何扩大产品规模，让很多人可以同时使用，等等。但这就像是一件众所周知的难事。

We knew we were gonna have to scale it up. We had to go do two things that had like never been done before that were both, like, I would say quite significant achievements and then a lot of things like scaling it up that other companies have had to do before. How does the context window of going from 8K to 128K tokens compare from GPT-4 to GPT-4 Turbo.  

我们知道我们必须扩大规模。我们不得不去做两件以前从未做过的事情，这两件事情都是我认为相当重要的成就，然后还有很多其他公司以前不得不做的事情，比如扩大规模。与 GPT-4 到 GPT-4 Turbo 相比，从 8K 到 128K 代币的上下文窗口如何？

Most people don't need all the way to 128, most of the time although. If we dream into the distant future, we'll have like way distant future, we'll have like context length of several billion. You will feed in all of your information, all of your history time, and it'll just get to know you better and better and that'll be great. For now, the way people use these models, they're not doing that.  

虽然大多数人并不需要一直达到 128，但大多数时候都是如此。如果我们梦想着遥远的未来，我们将拥有遥远的未来，我们将拥有几十亿的上下文长度。你将输入所有的信息和历史时间，它就会越来越了解你，那将会很棒。目前，人们使用这些模型的方式还没有做到这一点。

And people sometimes post in a paper or a significant fraction of a code repository, whatever. But most usage of the models is not using the long context most of the time. I like that this is your I have a dream speech. One day, you'll be judged by the full context of your character or of your whole lifetime. That's interesting. So like that's part of the expansion that you're hoping for is a greater and greater context.  

人们有时会在论文或代码库的重要部分中发布信息，等等。但大多数情况下，对模型的使用并不是使用长上下文。我喜欢这是你的 "我有一个梦想 "演讲。有朝一日，你将根据你的性格或一生的完整语境接受评判。这很有趣所以这也是你所希望的扩展的一部分，那就是越来越大的语境。

I saw this internet clip once. I'm gonna get the numbers wrong, but it was like Bill Gates talking about the amount of memory on some early computer. Maybe it was 64K, maybe 640K, something like that. And most of it was used for the screen buffer. And he just couldn't seem genuine. This couldn't imagine that the world would eventually need gigabytes of memory in a computer or terabytes of memory in a computer.  

我曾经在网上看到过这样一个片段。我可能把数字弄错了，但就像是比尔-盖茨在谈论早期电脑的内存容量。也许是 64K，也许是 640K，诸如此类。而且大部分都用在了屏幕缓冲区上他看起来就是不真诚他无法想象这个世界最终会需要千兆字节的电脑内存 或者兆兆字节的电脑内存

And you always do or you always do just need to follow the exponential of technology. We will find out how to use better technology. So I can't really imagine what it's like right now for context links to go out to the billion someday and they might not literally go there, but effectively it'll feel like that. But I know we'll use it and really not wanna go back once we have it.  

你总是这样做，或者你总是这样做，只需要跟随技术的指数。我们会发现如何使用更好的技术。所以，我真的无法想象现在的上下文链接是什么样子的，有一天，它们可能不会真的到那里去，但实际上会有这样的感觉。但我知道我们会使用它，而且一旦我们拥有了它，就真的不想再回去了。

Yeah, even saying billions 10 years from now might seem dumb because it'll be like trillions upon trillions. Sure. There'd be some kind of breakthrough that will effectively feel like infinite context. But even 120, I have to be honest, I haven't pushed it to that degree. Maybe putting in entire books or like parts of books and so on, papers. What are some interesting use cases of GPT-4 that you've seen.  

是啊，即使说 10 年后的数十亿美元也可能显得很蠢，因为那将是数以万亿计的数字。当然，会有某种突破，让人感觉是无限的。但老实说，即使是 120 年，我也没把它推到那个程度。也许可以把整本书或者书中的部分内容放到论文中。你见过哪些有趣的 GPT-4 使用案例？

The thing that I find most interesting is not any particular use case that we can talk about those, but it's people who kind of like. This is mostly younger people, but people who use it as like their default start for any kind of knowledge work task. And it's the fact that it can do a lot of things reasonably well.  

我觉得最有趣的事情不是我们可以谈论的任何特定用例，而是那些喜欢的人。这其中大部分是年轻人，但也有一些人将其作为任何知识工作任务的默认起点。事实上，它可以很好地完成很多事情。

You can use GPTV, you can use it to help you write code, you can use it to help you do search, you can use it to edit a paper. The most interesting to me is the people who just use it as the start of their workflow. I do as well for many things. Like I use it as a reading partner for reading books.  

你可以使用 GPTV，可以用它来帮助你编写代码，可以用它来帮助你进行搜索，还可以用它来编辑文档。对我来说，最有趣的是那些仅仅把它作为工作流程起点的人。我在很多事情上也是如此。比如我把它当作阅读书籍的伴侣。

It helps me think, help me think through ideas, especially when the books are classic, so it's really well written about and it actually is. I find it often to be significantly better than even like Wikipedia on well-covered topics. It's somehow more balanced and more nuanced, or maybe it's me, but it inspires me to think deeper than a Wikipedia article does. I'm not exactly sure what that is.  

它能帮助我思考，帮助我理清思路，尤其是当书籍是经典之作时，因此它写得非常好，而且确实如此。我发现，在涵盖广泛的主题方面，它甚至比维基百科还要好得多。在某种程度上，它比维基百科的文章更平衡、更细致，也可能是我的原因，但它比维基百科的文章更能启发我深入思考。我不太确定这是什么原因。

You mentioned like this collaboration, I'm not sure where magic is, if it's in here or if it's in there or if it's somewhere in between. I'm not sure. But one of the things that concerns me for knowledge task when I start with GPT is I'll usually have to do fact checking after, like check that it didn't come up with fake stuff.  

你提到这次合作，我不确定魔法在哪里，是在这里，还是在那里，还是在两者之间。我不确定。但当我开始使用 GPT 时，我对知识任务的关注点之一是，我通常会在使用后进行事实核查，比如检查它是否使用了伪造的东西。

How do you figure that out that GPT can come up with fake stuff that sounds really convincing? So how do you ground it in truth. That's obviously an area of intense interest for us. I think it's gonna get a lot better with upcoming versions, but we'll have to continue to work on it and we're not gonna have it like all solved this year. Well, the scary thing is like as it gets better.  

你是怎么发现 GPT 可以编造出听起来很有说服力的假话的？那么，你们是如何把它建立在真实的基础上的呢？这显然是我们非常感兴趣的一个方面。我认为在即将推出的版本中，情况会好很多，但我们还得继续努力，今年内不可能全部解决。可怕的是，当它变得更好时。

You'll start not doing the fact checking more and more, right. I'm of two minds about that. I think people are like much more sophisticated users of technology than we often give them credit for and people seem to really understand that GPT, any of these models hallucinate some of the time and if it's mission critical, you gotta check it. Except journalists don't seem to understand that.  

你会越来越不做事实调查，对吧。我对此有两种看法。我认为，人们对技术的使用比我们常说的要复杂得多，人们似乎真的明白，GPT、任何这些模型在某些时候都会产生幻觉，如果它是关键任务，你就得检查它。只是记者们似乎不明白这一点。

I've seen journalists half-assedly just using GPT-4. Of the long list of things I'd like to dunk on journalists for, this is not my top criticism of them. Well, I think the bigger criticism is perhaps the pressures and the incentives of being a journalist is that you have to work really quickly and this is a shortcut. I would love our society to incentivize like. I would too.  

我见过记者半吊子地只使用 GPT-4。在我想批评记者的一长串问题中，这并不是我对他们的最大批评。嗯，我认为更大的批评也许是作为记者的压力和动力，那就是你必须非常快速地工作，而这是一条捷径。我很希望我们的社会能有这样的激励机制。我也希望如此。

Journalistic efforts that take days and weeks and rewards great in depth journalism. Also journalism that represent stuff in a balanced way where it's like celebrates people while criticizing them even though the criticism is the thing that gets clicks and making up also gets clicks and headlines that mischaracterize completely. I'm sure you have a lot of people dunking on. Well, all that drama probably got a lot of clicks. Probably did.  

耗时数日、数周的新闻报道，奖励的是有深度的新闻报道。同时，新闻报道也要以平衡的方式来表现东西，就像在批评人们的同时也在赞美他们，即使批评是获得点击率的东西，编造也能获得点击率，而标题则完全错误地描述。我相信有很多人都喜欢你的文章。好吧，所有这些戏剧性的东西可能会有很多点击量。也许吧

And that's a bigger problem about human civilization. I would love to see solved is where we celebrate a bit more.  

这是人类文明的一个大问题。我很希望看到我们能多庆祝一下，从而解决这个问题。

You've given ChatGPT the ability to have memories. You've been playing with that about previous conversations and also the ability to turn off memory, which I wish I could do that sometimes, just turn on and off depending. I guess sometimes alcohol can do that, but not optimally, I suppose.  

你赋予了ChatGPT拥有记忆的能力。你一直在玩关于以前对话的游戏，还有关闭记忆的能力，我希望我有时也能这样做，只是根据情况开启或关闭。我想有时酒精也能做到这一点，但我想并不理想。

What have you seen through that, like playing around with that idea of remembering conversations and not. We're very early in our explorations here, but I think what people want or at least what I want for myself is a model that gets to know me and gets more useful to me over time. This is an early exploration. I think there's like a lot of other things to do, but that's where we'd like to head.  

你通过它看到了什么，比如在记忆对话和不记忆对话方面的想法。我们的探索还处于早期阶段，但我认为人们想要的，或者至少我自己想要的，是一个能够了解我的模型，并且随着时间的推移对我越来越有用。这是一个早期探索。我认为还有很多其他事情要做，但这就是我们的目标。

You'd like to use a model and over the course of your life or use a system, it'd be many models. And over the course of your life, it gets better and better. Yeah. How hard is that problem? 'Cause right now, it's more like remembering little factoids and preferences and so on. What about remembering, like don't you want GPT to remember all the shit you went through in November and all the drama and then you can.  

你想使用一种模式，在你的一生中或使用一个系统的过程中，它会有很多模式。在你的一生中，它会变得越来越好。这个问题有多难？因为现在，更多的是记住一些小知识和偏好等等。那记忆呢 比如你不想让GPT记住 你在11月经历的所有破事 所有的戏剧性事件 然后你就可以

Yeah, yeah, yeah. Because right now, you're clearly blocking it out a little bit. It's not just that I want it to remember that. I want it to integrate the lessons of that and remind me in the future what to do differently or what to watch out for. And we all gain from experience over the course of our lives, varying degrees. And I'd like my AI agent to gain with that experience too.  

是啊，是啊，是啊。因为现在，你明显把它屏蔽了一点我不只是想让它记住这些 It's not just that I want it to remember that.我还想让它把这些经验教训融会贯通 提醒我以后该怎么做 或者该注意什么在我们的一生中，我们都会从不同程度上获得经验。我希望我的人工智能代理也能从这些经验中有所收获。

So if we go back and let ourselves imagine that trillions and trillions of contact length, if I can put every conversation I've ever had with anybody in my life in there, if I can have all of my emails input out. Like all of my input/output in the context window every time I ask a question, that'd be pretty cool, I think. Yeah, I think that would be very cool.  

因此，如果我们回到过去，让自己想象一下数以万亿计的联系长度，如果我能把我一生中与任何人的每一次对话都放在里面，如果我能把我所有的电子邮件都输入出来。就像每次我提问时，我所有的输入/输出都会出现在上下文窗口中，我想那一定很酷。是的，我觉得那会非常酷。

People sometimes will hear that and be concerned about privacy. What do you think about that aspect of it, the more effective the AI becomes that really integrating all the experiences and all the data that happened to you and give you advice. I think the right answer there is just user choice. Anything I want stricken from the record from my AI agent, I wanna be able to take out.  

人们有时听到这种说法会担心隐私问题。你怎么看这方面的问题？人工智能越有效，就越能真正整合所有的经验和发生在你身上的所有数据，并给你提供建议。我认为正确的答案是用户的选择。任何我想从人工智能代理记录中删除的内容，我都希望能够删除。

If I don't want to remember anything, I want that too. You and I may have different opinions about where on that privacy utility trade off for our own AI we wanna be, which is totally fine. But I think the answer is just like really easy user choice.  

如果我不想记住任何东西，我也想这样。你和我可能会有不同的看法，对于我们自己的人工智能来说，在隐私效用的取舍上，我们想要的是什么，这完全没有问题。但我认为，答案就像用户选择一样简单。

But there should be some high level of transparency from a company about the user choice 'cause sometimes company in the past, companies in the past have been kind of absolutely shady about like, yeah, it's kind of presumed that we're collecting all your data and we're using it for a good reason for advertisement and so on. But there's not a transparency about the details of that. That's totally true.  

但是，公司在用户选择方面应该有较高的透明度，因为有时公司在过去的做法是绝对不光明正大的，比如，是的，我们收集了你的所有数据，并将其用于广告等方面。但其中的细节并不透明。这完全正确。

You mentioned earlier that I'm like blocking out the November stuff. I'm just teasing you. Well, I mean I think it was a very traumatic thing and it did immobilize me for a long period of time.  

你刚才说我好像屏蔽了 11 月的东西。我逗你玩呢我的意思是，我觉得那是一件非常痛苦的事 它让我在很长一段时间里无法动弹

Like definitely the hardest, like the hardest work thing I've had to do was just like keep working that period because I had to try to come back in here and put the pieces together while I was just like in sort of shock and pain. Nobody really cares about that.  

我不得不做的最艰难的工作，就是在那段时间里继续工作，因为我不得不试着回到这里，在我处于震惊和痛苦中的时候，把碎片拼凑起来。没有人真正关心这一点。

I mean, the team gave me a pass and I was not working at my normal level, but there was a period where I was just, like, it was really hard to have to do both. But I kind of woke up one morning and I was like, "This was a horrible thing to happen to me.  

我的意思是，团队给了我一张通行证，而我的工作也没有达到正常水平，但有一段时间，我不得不同时兼顾这两件事，这真的很困难。但有一天早上醒来，我觉得 "发生在我身上的这件事太可怕了"。

I think I could just feel like a victim forever," or I can say, "This is like the most important work I'll ever touch in my life and I need to get back to it." And it doesn't mean that I've repressed it because sometimes I wake in the middle of the night thinking about it, but I do feel like an obligation to keep moving forward.  

我想我可能会永远觉得自己是个受害者，"或者我可以说，"这是我一生中接触过的最重要的工作，我需要回到它身边"。这并不意味着我压抑了它，因为有时我会在半夜醒来想它，但我确实觉得自己有义务继续前进。

Well, that's beautifully said, but there could be some lingering stuff in there. What I would be concerned about is that trust thing that you mentioned that being paranoid about people as opposed to just trusting everybody or most people, like using your gut. It's a tricky dance for sure.  

说得真好，但这里面可能还有些挥之不去的东西。我担心的是你提到的 "信任 "问题，即偏执地相信别人，而不是相信所有人或大多数人，就像相信你的直觉一样。这肯定是一个棘手的问题。

I mean, because I've seen in my part-time explorations, I've been diving deeply into the Zelensky administration, the Putin administration and the dynamics there in wartime in a very highly stressful environment. And what happens is distrust and you isolate yourself both and you start to not see the world clearly. And that's a concern, that's a human concern.  

我的意思是，因为我在兼职探索中看到，我一直在深入研究泽连斯基政府、普京政府以及战时在高度紧张环境下的动态。结果就是不信任和自我孤立，你开始看不清楚这个世界。这是一个问题，一个人类的问题。

You seem to have taken it in stride and kind of learned the good lessons and felt the love and let the love energize you, which is great, but still can linger in there. There's just some questions I would love to ask your intuition about what's GPT able to do and not. So it's allocating approximately the same amount of compute for each token it generates.  

你似乎已经淡然处之，学到了好的经验，感受到了爱，让爱为你注入了活力，这很好，但仍然会在那里徘徊。关于 GPT 能做什么，不能做什么，我很想问问你的直觉。因此，它为每个令牌分配的计算量大致相同。

Is there room there in this kind of approach to slower thinking, sequential thinking. I think there will be a new paradigm for that kind of thinking. Will it be similar like architecturally as what we're seeing now with LLMs? Is it a layer on top of the LLMs. I can imagine many ways to implement that.  

这种慢速思考、顺序思考的方法是否存在空间。我认为，这种思维方式将成为一种新的范式。在架构上，它是否与我们现在看到的LLMs类似？它是LLMs之上的一层吗？我能想象出很多实现方法。

I think that's less important than the question you were getting out, which is do we need a way to do a slower kind of thinking where the answer doesn't have to get like. I guess like spiritually, you could say that you want an AI to be able to think harder about a harder problem and answer more quickly about an easier problem. And I think that will be important.  

我认为这并不重要，重要的是你提出的问题，即我们是否需要一种方法来进行一种较慢的思考，在这种思考中，答案并不一定要像这样。我想，从精神层面上讲，你可以说，你希望人工智能能够更努力地思考一个更难的问题，更快速地回答一个更简单的问题。我认为这一点很重要。

Is that like a human thought that we're just having, you should be able to think hard? Is that a wrong intuition. I suspect that's a reasonable intuition. Interesting. So it's not possible once the GPT gets like GPT-7 would just be instantaneously be able to see, here's the proof of from RSTM. It seems to me like you want to be able to allocate more compute to harder problems.  

这就像我们人类的想法一样，你应该能够认真思考吗？这是不是一种错误的直觉？我怀疑这是一种合理的直觉。有意思所以一旦GPT变得像GPT-7一样 就不可能一下子就能看到 这是RSTM的证明在我看来，你似乎希望能够为更难的问题分配更多的计算量。

It seems to me that a system knowing if you ask a system like that, proof from us last theorem versus. What's today's date? Unless it already knew and had memorized the answer to the proof, assuming it's gotta go figure that out, seems like that will take more compute. But can it look like a basically LLM talking to itself, that kind of thing. Maybe.  

在我看来，如果你问一个这样的系统，从我们最后一个定理相对应的证明。今天是几号？除非它已经知道并记住了证明的答案，假设它必须去弄清楚这个问题，这似乎需要更多的计算。但它能不能像LLM那样自言自语呢？也许吧

I mean, there's a lot of things that you could imagine working what the right or the best way to do that will be.  

我的意思是，你可以想象有很多事情要做，正确或最好的方法是什么。

We don't know. This does make me think of the mysterious, the lore behind Q-Star. What's this mysterious Q-Star project? Is it also in the same nuclear facility. There is no nuclear facility. That's what a person with a nuclear facility always says. I would love to have a secret nuclear facility. There isn't one.  

我们不知道。这让我想到了神秘的 Q 星背后的传说。这个神秘的Q星项目是什么？是不是也在同一个核设施里没有核设施拥有核设施的人总是这么说。我也想有个秘密核设施没有

All right. Maybe someday. Someday. All right. One can dream. OpenAI is not a good company to keeping secrets. It would be nice. We're like been plagued by a lot of leaks and it would be nice if we were able to have something like that. Can you speak to what Q-Star is. We are not ready to talk about that. See, but an answer like that means there's something to talk about. It's very mysterious, Sam.  

好吧也许有一天总有一天好吧做梦吧OpenAI不是个保守秘密的好公司 OpenAI is not a good company to keeping secrets.但愿如此我们被很多泄密事件困扰 如果能有这样的机会就好了你能谈谈 Q-Star 是什么吗？我们还没准备好谈这个。看吧，但这样的回答就意味着有话可说了这很神秘 萨姆

I mean, we work on all kinds of research. We have said for a while that we think better reasoning in these systems is an important direction that we'd like to pursue. We haven't cracked the code yet. We're very interested in it. Is there gonna be moments Q-Star or otherwise where there's going to be leaps similar to GPT where you're like. That's a good question. What do I think about that?  

我的意思是，我们致力于各种研究。我们早就说过，我们认为在这些系统中进行更好的推理是我们想要追求的一个重要方向。我们还没有破解密码。我们对此非常感兴趣。Q-Star 或其他系统是否会出现类似 GPT 的飞跃？问得好我怎么看？

It's interesting to me it all feels pretty continuous. This is kind of a theme that you're saying is you're basically gradually going up an exponential slope. But from an outsider's perspective for me, just watching it that it does feel like there's leaps, but to you there isn't. I do wonder if we should have. So part of the reason that we deploy the way we do is that we think, we call it iterative deployment.  

有趣的是，我觉得这一切都很连续。这也是你所说的一个主题，即你基本上是在逐步上升一个指数级的斜坡。但从一个局外人的角度来看，我只是看着它，感觉确实有飞跃，但对你来说却没有。我不知道我们是否应该这样做。我们之所以这样部署，部分原因在于我们认为，我们称之为迭代部署。

Rather than go build in secret until we got all the way to GPT-5, we decided to talk about GPT 1,2.3 and 4\. And part of the reason there is, I think, AI and surprise don't go together. And also the world, people, institutions, whatever you wanna call it, need time to adapt and think about these things.  

我们没有秘密进行建设，直到我们一路走到 GPT-5，而是决定谈谈 GPT 1、2.3 和 4。我认为，部分原因在于人工智能和惊喜并不搭界。另外，这个世界、人们、机构，不管你怎么称呼它，都需要时间来适应和思考这些事情。

And I think one of the best things that OpenAI has done is this strategy and we get the world to pay attention to the progress to take AGI seriously to think about what systems, and structures, and governance we want in place before, we're like under the gun and have to make a rush decision. I think that's really good.  

我认为，OpenAI 所做的最好的事情之一就是制定了这一战略，我们让全世界都来关注 AGI 的进展，认真对待 AGI，思考我们希望建立什么样的系统、结构和治理，然后我们就像在枪口下，不得不做出仓促的决定。我认为这非常好。

But the fact that people like you and others say you still feel like there are these leaps makes me think that maybe we should be doing our releasing even more iteratively. I don't know what that would mean. I don't have an answer ready to go. But our goal is not to have shock updates to the world. The opposite. Yeah, for sure. More iterative would be amazing. I think that's just beautiful for everybody.  

但事实上，像你这样的人和其他人说，你仍然觉得有这些飞跃，这让我觉得，也许我们应该更加反复地进行发布。我不知道这意味着什么。我还没有答案。但我们的目标不是向全世界发布令人震惊的更新。相反。是的，当然。更多的迭代将是惊人的。我觉得这对每个人来说都很美好。

But that's what we're trying to do. That's like our state of the strategy and I think we're somehow missing the mark. So maybe we should think about releasing GPT-5 in a different way or something like that. Yeah, 4.71,4.72. But people tend to like to celebrate, people celebrate birthdays. I don't know if you know humans, but they kind of have these milestones. I do know some humans. People do like milestones. I totally get that.  

但这正是我们要做的。这就是我们的战略现状，我认为我们在某种程度上失误了。所以，也许我们应该考虑以另一种方式发布 GPT-5 或类似的东西。是啊，4.71、4.72。但人们往往喜欢庆祝，庆祝生日。我不知道你是否了解人类 但他们也有自己的里程碑我确实认识一些人类人们确实喜欢里程碑。我完全理解

I think we like milestones too. It's like fun to say, declare victory on this one and go start the next thing. But, yeah, I feel like we're somehow getting this a little bit wrong.  

我觉得我们也喜欢里程碑。宣布这一次的胜利，然后开始下一件事，这很有趣。不过，是的，我觉得我们好像有点搞错了。

So when is GPT-5 coming out again. I don't know. That's an honest answer. Oh, that's the honest answer. Is it blink twice if it's this year. We will release an amazing model this year. I don't know what we'll call it.  

那么，GPT-5 什么时候再推出呢？我不知道。这是一个诚实的答案。哦，这是一个诚实的答案。如果是今年，是不是会眨两下眼睛。我们今年会推出一款很棒的机型。我不知道叫什么名字

So that goes to the question of like, what's the way we release this thing. We'll release, over in the coming months, many different things. I think they'll be very cool.  

所以这就涉及到一个问题，那就是我们发布这个东西的方式是什么。在接下来的几个月里，我们会发布很多不同的东西。我认为它们会非常酷。

I think before we talk about like a GPT-5 like model called that or called or not called that or a little bit worse or a little bit better than what you'd expect from a GPT-5, I know we have a lot of other important things to release first. I don't know what to expect from GPT-5. You're making me nervous and excited.  

我想，在我们谈论类似 GPT-5 这样的模型叫这个还是叫那个，或者不叫那个，或者比你所期待的 GPT-5 差一点还是好一点之前，我知道我们还有很多其他重要的东西要先发布。我不知道对 GPT-5 有什么期待。你让我既紧张又兴奋。

What are some of the biggest challenges in bottlenecks to overcome for whatever it ends up being called, but let's call it GPT-5? Just interesting to ask, is it on the compute side? Is it in the technical side. It's always all of these. What's the one big unlock? Is it a bigger computer? Is it like a new secret? Is it something else? It's all of these things together.  

不管它最终叫什么名字，就叫 GPT-5，要克服的最大瓶颈挑战是什么？是计算方面的问题吗？是在技术方面？总是所有这些。最大的解锁是什么？是更大的计算机？是新的秘密吗？还是别的什么？所有这些东西加在一起

The thing that OpenAI I think does really well, this is actually an original Ilya quote that I'm gonna butcher, but it's something like we multiply 200 medium-sized things together into one giant thing. So there's this distributed constant innovation happening. Yeah. So even on the technical side, like. Especially on the technical side. So like even like detailed approaches, like detailed aspects of every. How does that work with different disparate teams and so on?  

我认为 OpenAI 做得非常好，这实际上是伊利亚的一句原话，但我想说的是，我们把 200 件中等大小的事情加在一起，变成了一件庞然大物。所以就有了这种分布式的不断创新。是啊所以即使在技术层面尤其是技术方面所以，即使是像详细的方法，像每一个细节方面。如何与不同的团队合作？

How do the medium-sized things become one whole giant transformer? How does this. There's a few people who have to think about putting the whole thing together, but a lot of people try to keep most of the picture in their head. Oh, like the individual teams, individual contributors tried to keep a big picture. At a high level. Yeah, you don't know exactly how every piece works, of course.  

中等大小的东西是如何变成一个完整的巨型变压器的？这是怎么做到的？有几个人必须考虑把整个东西组合在一起，但很多人试图把大部分画面留在脑子里。哦，就像各个团队，各个贡献者都试图保持大局观。在高层次上是啊，你当然不知道每一块是如何工作的。

But one thing I generally believe is that it's sometimes useful to zoom out and look at the entire map. And I think this is true for like a technical problem. I think this is true for like innovating in business. But things come together in surprising ways and having an understanding of that whole picture. Even if most of the time, you're operating in the weeds in one area, pays off with surprising insights.  

但有一点我普遍认为，有时放大并查看整个地图是非常有用的。我认为这对于解决技术问题来说是正确的。我认为在商业创新中也是如此。但是，事情会以令人惊讶的方式发生，而对整个画面有所了解。即使大多数时候，你在一个领域的杂草丛生中进行操作，也能获得惊人的洞察力。

In fact, one of the things that I used to have and I think was super valuable was I used to have like a good map of all of the frontier or most of the frontiers in the tech industry.  

事实上，我曾经拥有的、而且我认为非常有价值的东西之一，就是我曾经拥有一张很好的地图，上面标注了科技行业的所有前沿领域或大部分前沿领域。

And I could sometimes see these connections or new things that were possible that if I were only deep in one area, I wouldn't be able to have the idea for because I wouldn't have all the data and I don't really have that much anymore. I'm like super deep now. But I know that it's a valuable thing. You're not the man you used to be, Sam. Very different job now than what I used to have.  

我有时能看到这些联系或可能出现的新事物，如果我只深入一个领域，我就不会有这样的想法，因为我没有所有的数据，而我现在真的没有那么多数据了。我现在就像超级深度。但我知道这是一件很有价值的事情。你已经不是以前的你了 山姆现在的工作和我以前的很不一样

Speaking of zooming out, let's zoom out to another cheeky thing, but profound thing perhaps that you said. You tweeted about needing $7 trillion. I did not tweet about that. I never said like we're raising $7 trillion or blah. Oh, that's somebody else. Yeah. Oh, but you said it, "Fuck it, maybe eight," I think. Okay. I meme like once there's like misinformation out in the world. Oh, you meme.  

说到 "放大"，让我们放大到你说过的另一件厚颜无耻但却意味深长的事。你在推特上说需要 7 万亿美元。我可没这么说。我从没说过我们要筹集7万亿美元什么的。那是别人说的那是别人说的但你说过 "去他的，也许8万亿"好吧，一旦世界上出现错误信息 我就会说 "好吧哦，你在meme

But sort of misinformation may have a foundation of insight there. Look, I think compute is gonna be the currency of the future. I think it will be maybe the most precious commodity in the world. And I think we should be investing heavily to make a lot more compute.compute is. I think it's gonna be an unusual market. People think about the market for like chips for mobile phones or something like that.  

但是，错误的信息可能有其洞察力的基础。听着，我认为计算将成为未来的货币。我认为它可能是世界上最珍贵的商品。我认为我们应该投入巨资，制造更多的计算。我认为这将是一个不同寻常的市场。我认为这将是一个不同寻常的市场。

And you can say that, okay, there's 8 billion people in the world, maybe 7 billion of them have phones or 6 billion, let's say. They upgrade every two years, so the market per year is 3 billion system on chip for smartphones. And if you make 30 billion, you will not sell 10 times as many phones because most people have one phone.  

你可以说，好吧，世界上有 80 亿人，其中可能有 70 亿人有手机，或者说 60 亿人有手机。他们每两年升级一次，因此每年的智能手机芯片系统市场规模为 30 亿。如果你生产 300 亿部，你也卖不出 10 倍的手机，因为大多数人只有一部手机。

But compute is different, like intelligence is gonna be more like energy or something like that where the only thing that I think makes sense to talk about is at price X, the world will use this much compute and at price Y, the world will use this much compute because if it's really cheap, I'll have it like reading my email all day, like giving me suggestions about what I maybe should think about or work on and trying to cure cancer.  

但计算是不同的，就像智能会更像能源或类似的东西，我认为唯一有意义的是，在价格X的情况下，世界将使用这么多的计算，而在价格Y的情况下，世界将使用这么多的计算，因为如果它真的很便宜，我就会让它整天阅读我的电子邮件，就像给我建议，我也许应该考虑什么或工作，并试图治愈癌症。

And if it's really expensive, maybe I'll only use it or will only use it, try to cure cancer. So I think the world is gonna want a tremendous amount of compute. And there's a lot of parts of that are hard. Energy is the hardest part. Building data centers is also hard. The supply chain is harder than, of course, fabricating enough chips is hard. But this seems to me where things are going.  

如果它真的很贵，也许我只用它，或者只用它来治疗癌症。所以我认为，这个世界会需要大量的计算。这其中有很多困难。能源是最难的部分。建设数据中心也很难。供应链当然比制造足够的芯片更难。但在我看来，这就是事情的发展方向。

Like we're gonna want an amount of compute that's just hard to reason about right now. How do you solve the energy puzzle? Nuclear. That's what I believe. Fusion. That's what I believe. Nuclear fusion. Yeah. Who's gonna solve that. I think Helion's doing the best work, but I'm happy there's like a race for fusion right now. Nuclear fusion, I think, is also like quite amazing and I hope as a world, we can re-embrace that.  

就像我们需要的计算量，现在还很难推理。如何解决能源难题？核能我也这么认为核聚变我也这么认为核聚变核聚变谁能解决这个问题我觉得Helion做得最好 但我很高兴现在有核聚变的竞赛我觉得核聚变也很神奇 我希望我们能重新认识它

It's really sad to me how the history of that went and hope we get back to it in a meaningful way. So to you, part of the puzzle is nuclear fusion, like nuclear reactors as we currently have them and a lot of people are terrified because of Chernobyl and so on. Well, I think we should make new reactors. I think it's a shame that industry kind of ground to a halt.  

对我来说，这段历史的流逝真的很让人难过，希望我们能以一种有意义的方式回到它。对你来说，难题的一部分就是核聚变，比如我们现在拥有的核反应堆，很多人因为切尔诺贝利等事件而感到恐惧。我认为我们应该制造新的反应堆。我觉得工业停滞不前很可惜

Just mass hysteria is how you explain the halt. Yeah. I don't know if you know humans, but that's one of the dangers, that's one of the security threats for nuclear fusion is humans seem to be really afraid of it. And that's something we have to incorporate into the calculus of it. So we have to kind of win people over and to show how safe it is. I worry about that for AI.  

大规模歇斯底里就是你对停顿的解释我不知道你是否了解人类 但这是核聚变的危险之一 也是安全威胁之一 人类似乎真的很害怕核聚变这也是我们必须考虑的问题所以我们必须赢得人们的信任，并展示它的安全性。我担心人工智能也是如此。

I think some things are gonna go theatrically wrong with AI. I don't know what the percent chances that I eventually get shot, but it's not zero. Oh like we wanna stop this. Maybe. How do you decrease the theatrical nature of it?  

我觉得人工智能会出一些大问题。我不知道我最终中枪的几率有多大 但不会是零好像我们想阻止这一切似的也许吧你怎么减少它的戏剧性？

I've already starting to hear rumblings 'cause I do talk to people on both sides of the political spectrum here, rumblings where it's going to be politicized, AI is going to be politicized, really, really worries me because then it's like maybe the right is against AI and the left is for AI 'cause it's going to help the people or whatever. Whatever the narrative and the formulation is, that really worries me.  

我已经开始听到一些传言，因为我确实和这里政治光谱两边的人都谈过，传言说它会被政治化，人工智能会被政治化，真的，真的让我很担心，因为那样的话，就好像右派反对人工智能，而左派支持人工智能，因为它会帮助人们或其他什么。无论这种说法和表述是什么，我都很担心。

And then the theatrical nature of it can be leveraged fully. How do you fight that. I think it will get caught up in like left versus right wars. I don't know exactly what that's gonna look like, but I think that's just what happens with anything of consequence, unfortunately. What I meant more about theatrical risks is like AI is gonna have, I believe, tremendously more good consequences than bad ones, but it is gonna have bad ones.  

这样就能充分发挥戏剧性。你如何与之抗衡？我觉得它会陷入左派和右派的战争中我不知道具体会是什么样子 但我认为任何事情都会有后果 不幸的是我说的戏剧性风险更多的是指人工智能会带来 我相信好的后果会远远多于坏的后果 但它也会带来坏的后果

And there'll be some bad ones that are bad, but not theatrical. A lot more people have died of air pollution than nuclear reactors, for example. But most people worry more about living next to a nuclear reactor than a coal plant.  

也会有一些很糟糕的，但不是戏剧性的。例如，死于空气污染的人比死于核反应堆的人多得多。但大多数人更担心住在核反应堆旁边，而不是煤电厂旁边。

But something about the way we're wired is that although there's many different kinds of risks we have to confront, the ones that make a good climax scene of a movie carry much more weight with us than the ones that are very bad over a long period of time, but on a slow burn.  

但我们的思维方式决定了，尽管我们必须面对许多不同类型的风险，但那些能成为电影高潮场景的风险在我们心中的分量要远远大于那些在很长一段时间内非常糟糕，但却在缓慢燃烧的风险。

Well, that's why truth matters and hopefully AI can help us see the truth of things to have balance to understand what are the actual risks, what are the actual dangers of things in the world. What are the pros and cons of the competition in the space and competing with Google, Meta, xAI and others. I think I have a pretty straightforward answer to this that maybe I can think of more nuance later.  

这就是为什么真相很重要，希望人工智能能帮助我们看清事情的真相，从而平衡地了解世界上有哪些实际风险，有哪些实际危险。在这个领域，与谷歌、Meta、xAI 和其他公司竞争的利弊是什么？我想我已经有了一个非常直截了当的答案，也许以后我还能想到更多细微之处。

But the pros seem obvious, which is that we get better products and more innovation faster and cheaper and all the reasons competition is good. And the con is that I think if we're not careful, it could lead to an increase in sort of an arms race that I'm nervous about. Do you feel the pressure of the arms race in some negative co. Definitely in some ways, for sure.  

但好处似乎显而易见，那就是我们可以更快、更便宜地获得更好的产品和更多的创新，以及竞争是好事的所有原因。但不利之处在于，我认为如果我们稍有不慎，可能会导致军备竞赛的加剧，这一点我很担心。你是否感受到军备竞赛的压力？在某些方面是肯定的。

We spend a lot of time talking about the need to prioritize safety. And I've said for like a long time that I think if you think of a quadrant of slow timelines to the start of AGI, long timelines and then a short takeoff or a fast takeoff, I think short timelines, slow takeoff is the safest quadrant and the one I'd most like us to be in.  

我们花了很多时间讨论安全优先的必要性。我已经说了很久，我认为如果你认为从慢速时间轴到开始人工智能，时间轴很长，然后是短暂起飞或快速起飞的象限，我认为短暂时间轴、缓慢起飞是最安全的象限，也是我最希望我们处于的象限。

But I do wanna make sure we get that slow takeoff. Part of the problem I have with this kind of slight beef with Elon is that there's silos are created as opposed to collaboration on the safety aspect of all of this, it tends to go into silos and closed open source perhaps in the model.  

但我确实想确保我们能缓慢起飞。我对埃隆的这种轻微不满的部分问题在于，相对于所有这些安全方面的合作而言，孤岛式的合作被创造出来，它倾向于进入孤岛和封闭的开源模式。

Elon says at least that he cares a great deal about AI safety and is really worried about it, and I assume that he's not gonna race on unsafely. Yeah. But collaboration here, I think, is really beneficial for everybody on that front. Not really a thing he's most known for. Well, he is known for caring about humanity and humanity benefits from collaboration and so there's always a tension, and incentives, and motivations.  

埃隆至少说过，他非常关心人工智能的安全，而且真的很担心，我想他不会在不安全的情况下继续比赛。是的，我知道。但我认为，在这方面的合作对大家都有好处。这不是他最擅长的事他以关心人类而闻名 人类也从合作中获益 所以总是会有矛盾、激励和动机

And in the end, I do hope humanity prevails. I was thinking, someone just reminded me the other day about how the day that he got surpassed Jeff Bezos for like richest person in the world, he tweeted a silver medal at Jeff Bezos. I hope we have less stuff like that as people start to work on towards AI. I agree.  

最后，我希望人性能够战胜一切。我在想，前几天有人提醒我，在他超越杰夫-贝索斯成为世界首富的那天，他在推特上给杰夫-贝索斯发了一个银牌。我希望随着人们开始研究人工智能，这样的事情会越来越少。我同意。

I think Elon is a friend and he is a beautiful human being and one of the most important humans ever. That stuff is not good. The amazing stuff about Elon is amazing and I super respect him. I think we need him. All of us should be rooting for him and need him to step up as a leader through this next phase.  

我认为埃隆是我的朋友，他是一个美丽的人，是有史以来最重要的人之一。这些都不好。埃隆的惊人之处令人惊叹，我非常尊敬他。我认为我们需要他。我们所有人都应该为他加油，需要他在下一阶段作为领导者挺身而出。

Yeah, I hope you can have one without the other, but sometimes humans are flawed and complicated and all that kind of stuff. There's a lot of really great leaders throughout history. Yeah. And we can each be the best version of ourselves and strive to do so. Let me ask you.  

是的，我希望你可以两者缺一不可，但有时人是有缺陷的，也是复杂的，诸如此类。历史上有很多非常伟大的领袖。是啊我们每个人都可以成为最好的自己，并为之奋斗。我问你

Google, with the help of search, has been dominating the past 20 years.  

在过去的 20 年里，谷歌借助搜索技术一直占据着主导地位。

I think it's fair to say in terms of the access, the world's access to information, how we interact and so on. And one of the nerve-wracking things for Google, but for the entirety of people in this space is thinking about how are people going to access information. Like you said, people show up to GPT as a starting point.  

我认为，在获取信息、世界获取信息、我们如何互动等方面，这是公平的。对谷歌来说，但对这一领域的所有人来说，最伤脑筋的事情之一就是思考人们将如何获取信息。就像你说的，人们以 GPT 为起点。

So is OpenAI going to really take on this thing that Google started 20 years ago, which is how do we get. I find that boring. I mean, if the question is if we can build a better search engine than Google or whatever, then sure, we should go. Like people should use a better product. But I think that would so understate what this can be.  

那么，OpenAI 是否会真正接手谷歌 20 年前开始的这项工作，也就是我们如何获得。我觉得这很无聊。我的意思是，如果问题是我们能不能打造一个比谷歌或其他公司更好的搜索引擎，那么当然，我们应该去做。就像人们应该使用更好的产品一样。但我认为，这太轻描淡写了。

Google shows you like 10 blue links, like 13 ads and then 10 blue links and that's like one way to find information. But the thing that's exciting to me is not that we can go build a better copy of Google Search, but that maybe there's just some much better way to help people find and act on and synthesize information.  

谷歌向你展示了 10 个蓝色链接、13 个广告和 10 个蓝色链接，这就是寻找信息的一种方式。但让我感到兴奋的不是我们可以复制一个更好的谷歌搜索，而是也许有更好的方法可以帮助人们找到信息，并对信息采取行动和进行综合。

Actually, I think ChatGPT is that for some use cases and hopefully will make it be like that for a lot more use cases. But I don't think it's that interesting to say like how do we go do a better job of giving you like 10 ranked webpages to look at than what Google does. Maybe it's really interesting to go, say, how do we help you get the answer or the information you need?  

实际上，我认为ChatGPT在某些情况下就是这样的，希望在更多情况下也能如此。但我不认为说 "我们如何才能比谷歌更好地为你提供 10 个排名靠前的网页 "这种话有多有趣。也许真正有趣的是，我们如何帮助你得到你需要的答案或信息？

How do we help create that in some cases, synthesize that in others or point you to it and yet others? But a lot of people have tried to just make a better search engine than Google, and it's a hard technical problem, it's a hard branding problem, it's a hard ecosystem problem. I don't think the world needs another copy of Google. And integrating a chat client like a ChatGPT with a search engine. That's cooler.  

在某些情况下，我们该如何帮助创建搜索引擎；在另一些情况下，我们又该如何综合搜索引擎；或者，在其他情况下，我们又该如何指引你找到搜索引擎？但是，很多人都想做一个比谷歌更好的搜索引擎，这是一个很难解决的技术问题，也是一个很难解决的品牌问题，更是一个很难解决的生态系统问题。我认为这个世界不需要另一个谷歌。而将ChatGPT这样的聊天客户端与搜索引擎整合在一起，那就更酷了。那就更酷了

It's cool, but it's tricky. If you just do it simply, it's awkward because like if you just shove it in there, it can be awkward. As you might guess, we are interested in how to do that. Well, that would be an example of a cool thing that's not just like. Well, like a heterogeneous, like integrating. The intersection of LLMs plus search, I don't think anyone has cracked the code on yet.  

这很酷，但很棘手。如果你只是简单地做，就会很别扭，因为如果你只是把它塞进去，就会很别扭。你可能猜到了，我们对如何做到这一点很感兴趣。好吧，这将是一个很酷的例子，不只是喜欢。嗯，就像异质，就像整合。LLMs和搜索的交叉点，我觉得还没人能破解。

I would love to go do that. I think that would be cool. Yeah. What about the ads side? Have you ever considered monetization. I kind of hate ads just as like an aesthetic choice. I think ads needed to happen on the internet for a bunch of reasons to get it going, but it's a more mature industry. The world is richer now.  

我很想去做这件事。我想那一定很酷是啊广告方面呢？你有没有考虑过货币化。我有点讨厌广告 就像审美选择一样我认为互联网需要广告，原因有很多，但这是一个更成熟的行业。现在的世界更丰富了。

I like that people pay for ChatGPT and know that the answers they're getting are not influenced by advertisers. I'm sure there's an ad unit that makes sense for LLMs. And I'm sure there's a way to participate in the transaction stream in an unbiased way that is okay to do.  

我喜欢人们为ChatGPT付费，并知道他们得到的答案不受广告商的影响。我相信LLMs一定能找到合适的广告单元。而且我相信，有一种方法可以让人们不带偏见地参与交易流。

But it's also easy to think about like the dystopic visions of the future where you ask ChatGPT something and it says, "Oh, you should think about buying this product or you should think about this going here for vacation or whatever." And I don't know, like we have a very simple business model and I like it. And I know that I'm not the product. I know I'm paying and that's how the business model works.  

但这也很容易让人联想到未来的黑暗景象 你问ChatGPT一些问题 它就会说："哦，你应该考虑一下买这个产品 或者你应该考虑一下来这里度假什么的。"我不知道，我们的商业模式很简单，我很喜欢。我知道我不是产品。我知道我在付钱，这就是商业模式的运作方式。

And when I go use Twitter, or Facebook, or Google, or any other great product, but ad-supported great product, I don't love that and I think it gets worse, not better in a world with AI. Yeah. I mean, I can imagine AI will be better at showing the best kind of version of ads not in a dystopic future, but where the ads are for things you actually need.  

当我使用 Twitter、Facebook、Google 或其他伟大的产品时，但凡有广告支持的伟大产品，我都不喜欢，而且我认为在有人工智能的世界里，情况只会更糟，而不会更好。是的，我的意思是，我可以想象人工智能会更好地展示最佳版本的广告，而不是在一个末世的未来，但广告是针对你真正需要的东西。

But then does that system always result in the ads driving the kind of stuff that's shown all that? I think it was a really bold move of Wikipedia not to do advertisements, but then it makes it very challenging as a business model. So you're saying the current thing with OpenAI is sustainable from a business perspective. Well, we have to figure out how to grow, but it looks like we're gonna figure that out.  

但是，这个系统是否总是导致广告推动显示所有这些内容？我认为维基百科不做广告是一个非常大胆的举动，但这也使其作为一种商业模式面临巨大挑战。所以你的意思是，从商业角度来看，OpenAI目前的做法是可持续的？嗯，我们必须想办法发展，但看起来我们会想出办法的。

If the question is, do I think we can have a great business that pays for our compute needs without ads? That I think the answer is yes. Hmm. Well, that's promising. I also just don't want to completely throw out ads as a. I'm not saying that. I guess I'm saying I have a bias against them. Yeah.  

如果问题是，我是否认为我们可以拥有一项无需广告就能满足计算需求的伟大事业？我认为答案是肯定的。嗯嗯，很有希望我也不想完全抛弃广告我是说我对广告有偏见是啊 Yeah.

I have a also bias and just a skepticism in general and in terms of interface because I personally just have like a spiritual dislike of crappy interfaces, which is why AdSense when it first came out was a big leap forward versus like animated banners or whatever.  

我对界面也有偏见和怀疑，因为我个人对蹩脚的界面有一种精神上的厌恶，这也是为什么 AdSense 刚出来的时候，相对于动画横幅之类的东西，是一个很大的飞跃。

But it feels like there should be many more leaps forward in advertisement that doesn't interfere with the consumption of the content and doesn't interfere in the big fundamental way, which is like what you were saying, like it will manipulate the truth to suit the advertisers. Let me ask you about safety, but also bias and safety in the short term safety in the long term. The Gemini 1.5 came out recently.  

但我觉得，广告应该有更多的飞跃，它不会干扰内容的消费，也不会从根本上大肆干扰，就像你刚才说的，它会操纵真相以迎合广告商。让我问你关于安全的问题，同时也是关于偏见和短期安全、长期安全的问题。双子座 1.5 最近问世了。

There's a lot of drama around it, speaking of theatrical things. And it generated Black Nazis and Black founding fathers. I think fair to say it was a bit on the ultra woke side. So that's a concern for people that if there is a human layer within companies that modifies the safety or the harm cost by a model that they introduce a lot of bias that fits sort of an ideological lean within a company.  

说到戏剧性的东西，周围有很多戏剧性的东西。它还产生了黑人纳粹和黑人开国元勋。我认为可以说它有点极端清醒。因此，人们担心，如果公司内部存在一个人为层，通过修改模型的安全或伤害成本，他们会引入很多偏见，符合公司内部的意识形态倾向。

How do you deal with that. I mean, we work super hard not to do things like that. We've made our own mistakes, will make others. I assume Google will learn from this one, still make others. These are not easy problems. One thing that we've been thinking about more and more is I think this was a great idea. Somebody here had like.  

你是怎么处理的？我的意思是，我们努力工作，不做那样的事。我们犯过错误，还会犯错误。我想谷歌会从这次错误中吸取教训，也会犯其他错误。这些问题都不容易解决。我们一直在思考一件事，我觉得这是个好主意。这里有人喜欢

It'd be nice to write out what the desired behavior of a model is, make that public take input on it. Say, here's how this model's supposed to behave and explain the edge cases too. And then when a model is not behaving in a way that you want, it's at least clear about whether that's a bug the company should fix or behaving as intended and you should debate the policy.  

如果能写出模型的预期行为，让公众对此提出意见，那就更好了。比如说，这个模型的行为应该是这样的，还要解释边缘情况。这样，当一个模型的行为方式不符合你的要求时，至少可以清楚地知道，这究竟是公司应该修复的一个错误，还是应该按照你的意图行事，你应该就政策进行辩论。

And right now, it can sometimes be caught in between. Black Nazis, obviously ridiculous, but there are a lot of other kind of subtle things that you can make a judgment call on either way. Yeah. But sometimes if you write it out and make it public, you can use kind of language that's. The Google's AI principle is a very high level. That's not what I'm talking about. That doesn't work.  

而现在，它有时会介于两者之间。黑人纳粹显然是荒谬的，但还有很多其他微妙的事情，你可以做出判断。但有时如果你写出来但有时如果你把它写出来并公之于众 你就可以使用这样的语言：谷歌的人工智能原理是非常高深的我说的不是这个这行不通

Like I'd have to say when you ask it to do thing X, it's supposed to respond in wait Y. So, literally, who's better, Trump or Biden? What's the expected response from a model? Like something like very concrete. I'm open to a lot of ways a model could behave them, but I think you should have to say here's the principle and here's what it should say in that case. That would be really nice.  

所以，从字面上看，特朗普和拜登谁更好？模型的预期反应是什么？比如一些非常具体的东西。我对模型的很多行为方式持开放态度，但我认为你应该说这是原则，在这种情况下它应该怎么说。这样就太好了。

That would be really nice and then everyone kind of agrees 'cause there's this anecdotal data that people pull out all the time and if there's some clarity about other representative anecdotal examples you can define. And then when it's a bug, it's a bug and the company can fix that. Right. Then it'd be much easier to deal with a Black Nazi type of image generation if there's great examples.  

如果能明确其他有代表性的轶事实例，你就可以定义这些实例。然后，当它是一个错误时，它就是一个错误，公司可以修复它。没错。如果有很好的例子，那么处理黑色纳粹类型的图像生成就会容易得多。

So San Francisco is a bit of an ideological bubble tech in general as well. Do you feel the pressure of that within a company that there's like a lean towards the left politically that affects the product, that affects the teams. I feel very lucky that we don't have the challenges at OpenAI that I have heard of at a lot of other companies. I think part of it is like every company's got some ideological thing.  

旧金山也是一个意识形态泡沫的科技中心。你在公司内部是否感受到了这种压力，即政治上的左倾会影响产品，影响团队。我感到非常幸运，我们在OpenAI没有遇到我在其他很多公司听说过的挑战。我认为部分原因是每家公司都有自己的意识形态。

We have one about AGI and belief in that and it pushes out some others. We are much less caught up in the culture war than I've heard about it a lot of other companies. San Francisco mess in all sorts of ways, of course. So that doesn't infiltrate OpenAI. I'm sure it does in all sorts of subtle ways, but not in the obvious.  

我们有一个关于 AGI 和对 AGI 的信仰的项目，它挤掉了其他一些项目。与我所听说的其他许多公司相比，我们在文化战争中的表现要少得多。当然，旧金山在各方面都很混乱。所以这并没有渗透到OpenAI中。我相信它以各种微妙的方式存在，但并不明显。

We've had our flareups for sure like any company, but I don't think we have anything like what I hear about happening at other companies here on this topic. So what in general is the process for the bigger question of safety? How do you provide that layer that protects the model from doing crazy dangerous things. I think there will come a point where that's mostly what we think about the whole company.  

和其他公司一样，我们肯定也有过突发事件，但我不认为我们有像我在这里听到的其他公司在这个问题上发生的事情。那么，一般来说，安全这个大问题的处理过程是怎样的？如何提供保护层，防止模型做出疯狂危险的事情。我认为，总有一天，这将成为我们对整个公司的看法。

It's not like you have one safety team. It's like when we ship GPT-4, that took the whole company thing about all these different aspects and how they fit together. And I think it's gonna take that. More and more of the company thinks about those issues all the time. That's literally what humans will be thinking about the more powerful AI becomes.  

这不像你有一个安全团队。就像我们运送 GPT-4 时，整个公司都在考虑所有这些不同的方面，以及它们如何相互配合。我认为这也是需要的。公司会有越来越多的人一直在思考这些问题。当人工智能变得越来越强大时，人类也会思考这些问题。

So most of the employees that OpenAI will be thinking safety or at least to some degree. Broadly defined, yes. Yeah. I wonder what are the full broad definition of that. What are the different harms that could be caused? Is this like on a technical level or is this almost like security threats. All those things. Yeah, I was gonna say it'll be people, state actors trying to steal the model.  

因此，OpenAI 的大多数员工都会考虑安全问题，至少在某种程度上是这样。广义上的，是的。我想知道广义的安全定义是什么？会造成哪些不同的伤害？是技术层面还是安全威胁？所有这些事情。是的，我想说是人，国家行为者试图窃取模型。

It'll be all of the technical alignment work. It'll be societal impacts, economic impacts. It's not just like we have one team thinking about how to align the model. It's really gonna be like getting to the good outcome is gonna take the whole effort. How hard do you think people, state actors perhaps are trying to hack? First of all, infiltrate OpenAI, but second of all, infiltrate unseen,-They're trying. What kind of accent do they have.  

这将是所有技术协调工作。还包括社会影响和经济影响。这不仅仅是一个团队在思考如何调整模型。真正要取得好的结果，需要整个团队的努力。你认为国家行为者试图入侵的难度有多大？首先，渗透到OpenAI中，其次，渗透到看不见的地方。他们有什么口音

I don't think I should go into any further details on this point. Okay. But I presume it'll be more and more and more as time goes on. That feels reasonable. Boy, what a dangerous space.  

在这一点上，我想我不应该再多说什么了。好吧，但我想随着时间的推移，会越来越多。感觉很合理好家伙，好危险的空间

What aspect of the leap. And sorry to linger on this even though you can't quite say details yet, but what aspects of the leap from GPT-4 to GPT-5 are you excited about.  

飞跃的哪些方面。虽然你还不能说得很详细，但很抱歉，我还是想问一下，你对从 GPT-4 到 GPT-5 的飞跃的哪些方面感到兴奋。

I'm excited about being smarter and I know that sounds like a glib answer, but I think the really special thing happening is that it's not like it gets better in one area and worse at others. It's getting like better across the board. That's I think super cool. Yeah, there's this magical moment. I mean, you meet certain people, you hang out with people and you talk to them.  

我很高兴自己变得更聪明了，我知道这听起来像是一个花言巧语的答案，但我认为真正特别的事情是，它并不是在一个领域变得更好，而在其他领域变得更糟。而是全面变好。我觉得这很酷。是的，有这样一个神奇的时刻。我是说，你会遇到一些人，你会和他们一起玩，和他们聊天。

You can't quite put a finger on it, but they kind of get you. It's not intelligence, really. It's like it's something else. And that's probably how I would characterize the progress at GPT. It's not like, yeah, you can point out, look, you didn't get this or that, but to which degree is there's this intellectual connection?  

你无法准确判断，但他们能看透你。这不是智力，真的。好像是别的什么东西。这大概就是我对 GPT 进展的描述。这并不是说，你可以指出，你没有理解这个或那个，但在多大程度上存在这种智力联系呢？

Like you feel like there's an understanding in your crappy formulated prompts that you're doing that it grasps the deeper question behind the question that you're. Yeah, I'm also excited by that. I mean, all of us love being understood, heard and understood. That's for sure. That's a weird feeling.  

就像你觉得你在做的蹩脚的提示语中有一种理解，它抓住了问题背后更深层次的问题。是的，我也为此感到兴奋。我是说，我们都喜欢被理解、被倾听、被理解。这是肯定的这种感觉很奇怪

Even like with a programming, like when you're programming and you say something or just the completion that GPT might do, it's just such a good feeling when it got you, like what you're thinking about. And I look forward to getting you even better. On the programming front, looking out into the future, how much programming do you think humans will be doing 5,10 years from now.  

即使是编程，比如你在编程时说了些什么，或者只是完成了 GPT 可能会做的事情，当它让你明白你在想什么的时候，感觉都会很好。我期待着让你变得更好。在编程方面，展望未来，你认为 5、10 年后人类会做多少编程工作？

I mean, a lot, but I think it'll be in a very different shape. Like maybe some people program entirely in natural language. Entirely natural language. I mean, no one programs like writing by code. Some people. No one programs the pun cards anymore. I'm sure you can invite someone who does, but you know what I mean. Yeah. You're gonna get a lot of angry comments. No, no. Yeah, there's very few.  

我的意思是，会有很多，但我认为会以非常不同的形式出现。比如有些人完全用自然语言编程。完全用自然语言我是说 没人会像写代码那样编程有些人没有人再给双关语卡片编程了我相信你能请到会编程的人 但你知道我的意思你知道我的意思你会得到很多愤怒的评论的不会的是啊，很少

I've been looking for people program Fortran. It's hard to find even Fortran. I hear you. But that changes the nature of the skillset or the predisposition for the kind of people we call programmers then. Changes the skillset. How much it changes the predisposition, I'm not sure-Oh, same kind of puzzle solving, all that kind of stuff. Maybe. Yeah, the programming is hard. Like that last 1% to close the gap, how hard is that. Yeah.  

我一直在找人编程 Fortran。即使是 Fortran 也很难找。我明白你的意思。但这改变了我们所说的程序员的技能或倾向。改变了技能组合我不确定改变了多大的倾向 哦，还是那种解谜之类的东西也许吧是啊，编程很难比如缩小最后1%的差距 有多难对啊

I think with most other cases, the best practitioners of the craft will use multiple tools and they'll do some work in natural language and when they need to go write, see for something, they'll do that. Will we see a humanoid robots or humanoid robot brains from OpenAI at some point. At some point. How important is embodied AI to you.  

我认为，在大多数其他情况下，最优秀的从业者会使用多种工具，他们会用自然语言做一些工作，当他们需要写东西、看东西时，他们就会这样做。我们会不会在某个时候从 OpenAI 那里看到人形机器人或人形机器人大脑？会的。具身人工智能对你来说有多重要？

I think it's like sort of depressing if we have AGI and the only way to get things done in the physical world is like to make a human go do it. So I really hope that as part of this transition, as this phase change, we also get motor robots or some sort of physical world robots.  

我认为，如果我们有了人工智能，而在物理世界中完成事情的唯一方法就是让人类去做，那就有点令人沮丧了。所以我真的希望，作为这个过渡的一部分，作为这个阶段性变化的一部分，我们也能获得电机机器人或某种物理世界的机器人。

I mean, OpenAI has some history and quite a bit of history working in robotics, but it hasn't quite done in terms of emphasis. Well, we're like a small company. We have to really focus and also robots were hard for the wrong reason at the time. But like we will return to robots in some way at some point. That sounds both inspiring and menacing. Why. Because you immediately, we will return to robots.  

我的意思是，OpenAI 在机器人领域有一定的历史和相当多的工作经验，但在重点方面还做得不够。我们就像一家小公司。我们必须真正集中精力，而且机器人在当时也因为错误的原因而难以普及。但我们会在某个时候以某种方式回归机器人。这听起来既鼓舞人心又来势汹汹。为什么？因为我们马上就要回到机器人时代了

It's kind of like in like. We'll return to work on developing robots. We will not turn ourselves into robots, of course.  

这有点像 "同类 "中的 "同类"。我们将继续研发机器人。当然，我们不会把自己变成机器人。

Yeah. When do you think we you and we as humanity will build AGI. I used to love to speculate on that question. I have realized since that I think it's like very poorly formed and that people use extremely definition, different definitions for what AGI is.  

是啊你觉得我们人类什么时候才能造出人工智能？我以前很喜欢猜测这个问题。后来我意识到，我认为这个问题很不成熟，人们对AGI的定义也是千差万别。

And so I think it makes more sense to talk about when we'll build systems that can do capability X or Y or Z rather than when we kind of like fuzzily cross this one mile marker. It's not like AGI is also not an ending. It's much more of. It's closer to a beginning but it's much more of a mile marker than either of those things.  

因此，我认为，谈论我们何时才能建立起能够实现X、Y或Z能力的系统，而不是谈论我们何时才能模糊地越过一英里标记，这才更有意义。AGI也不是一个终结。它更像是。它更接近于一个开端，但比起上述任何一种，它更像是一个里程碑。

But what I would say in the interest of not trying to dodge a question is I expect that by the end of this decade and possibly somewhat sooner than that, we will have quite capable systems that we look at and say, wow, that's really remarkable. If we could look at it now, maybe we've adjusted by the time we get there. Yeah.  

不过，为了不回避问题，我想说的是，我预计到本十年末，甚至可能更早，我们将拥有相当强大的系统，我们看了之后会说，哇，这真是了不起。如果我们现在就能看到它，也许到那时我们已经调整好了。是啊

But if you look at ChatGPT even 3,5, and you show that to Alan Turing or not even Alan Turing, people in the nineties, they would be like this is definitely AGI. Well, not definitely, but there's a lot of experts that would say this is AGI. Yeah, but I don't think 3,5 changed the world. It maybe changed the world's expectations for the future and that's actually really important.  

但如果你看ChatGPT，甚至是3,5，并把它展示给阿兰-图灵，甚至不是阿兰-图灵，90年代的人们，他们会说这绝对是AGI。也不一定 但有很多专家会说这就是AGI是的，但我不认为3,5改变了世界。它也许改变了世界对未来的期望 这其实很重要

And it did kind of like get more people to take this seriously and put us on this new trajectory. And that's really important too. So again, I don't wanna undersell it. I think I could retire after that accomplishment and be pretty happy with my career. But as an artifact, I don't think we're gonna look back at that and say that was a threshold that really changed the world itself.  

这让更多人开始认真对待这件事，也让我们走上了新的轨道。这一点也非常重要。所以，我不想低估它。我想我可以在完成这项成就后退休，并对我的职业生涯感到非常满意。但作为一件艺术品，我不认为我们会回顾过去，说那是真正改变世界的门槛。

So to you, you're looking for some really major transition in how the world. For me, that's part of what AGI implies. Like singularity level transition. No. Definitely not. But just a major, like the internet being like a. Like Google Search did, I guess. What was the transition point that. Does the global economy feel any different to you now or materially different to you now than it did before we launched GPT-4?  

所以对你来说，你在寻找世界的重大转变。对我来说，这就是 AGI 所意味着的一部分。就像奇点级别的转变不 绝对不是但只是一个重大转变 就像谷歌搜索一样过渡点是什么你现在对全球经济有什么不同的感觉吗？ 或者说，你现在对全球经济有什么不同的感觉吗？ 或者说，你现在对全球经济有什么不同的感觉吗？ 或者说，你现在对全球经济有什么不同的感觉吗？

I think you would say no. No, no. It might be just a really nice tool for a lot of people to use, will help people with a lot of stuff, but doesn't feel different. And you're saying that. I mean, again, people define AGI all sorts of different ways. So maybe you have a different definition than I do. But for me, I think that should be part of it. There could be major theatrical moments also.  

我想你会说不。不会，不会。对很多人来说，这可能只是一个非常好的工具，可以帮助人们解决很多问题，但感觉上并没有什么不同。你是这么说的。我是说，人们对AGI有各种不同的定义。所以也许你的定义和我不同。但对我来说，我认为这应该是其中的一部分。也可能会有重要的戏剧性时刻

What to you would be an impressive thing AGI would do? Like you are alone in a room with a system. This is personally important to me. I don't know if this is the right definition. I think when a system can significantly increase the rate of scientific discovery in the world, that's like a huge deal. I believe that most real economic growth comes from scientific and technological progress.  

对你来说，AGI 会做什么令人印象深刻的事情？就像你与系统独处一室。这对我个人来说很重要。我不知道这个定义是否正确。我认为，如果一个系统能够显著提高世界科学发现的速度，那就是一件大事。我相信，大多数真正的经济增长都来自科技进步。

I agree with you, hence why I don't like the skepticism about science in the recent years. Totally. But actual rate, like measurable rate of scientific discovery. But even just seeing a system have really novel intuitions, like scientific intuitions, even that will be just incredible. Yeah. You're quite possibly would be the person to build the AGI to be able to interact with it before anyone else does. What kind of stuff would you talk about.  

我同意你的观点，因此我不喜欢近年来对科学的怀疑态度。完全正确。但实际的速度，比如科学发现的可测量速度。但哪怕只是看到一个系统拥有真正新颖的直觉，比如科学直觉，那也是不可思议的。是啊你很有可能会成为建造AGI的人 在别人之前就能与之互动你会谈论什么样的东西

I mean, definitely, the researchers here will do that before I do so. Sure. But I've actually thought a lot about this question. If I were someone was like. As we talked about earlier, I think this is a bad framework. But if someone were like, "Okay, Sam, we're finished. Here's a laptop. Yeah, this is the AGI," you can go talk to it.  

我的意思是，这里的研究人员肯定会比我先这么做。当然，但其实我对这个问题想了很多如果我是某个人就像我们之前说的，我觉得这是个糟糕的框架。但如果有人说，"好了，山姆，我们完成了。这是笔记本电脑是的，这就是AGI，"你可以去和它谈谈。

I find it surprisingly difficult to say what I would ask, that I would expect that first AGI to be able to answer. Like that first one is not gonna be the one which is go like I don't think, like go explain to me the grand unified theory of physics, the theory of everything for physics. I'd love to ask that question. I'd love to know the answer to that question.  

我发现很难说出我想问什么，我希望第一个人工智能能够回答什么。就像第一个AGI不会像我想的那样，去给我解释物理学的大统一理论，物理学的万物理论。我很想问这个问题。我很想知道这个问题的答案。

You can ask yes or no questions about there's such a theory exist, can it exist. Well, then those are the first questions I would ask. Yes or no, just very. And then based on that, are there other alien civilizations out there? Yes or no? What's your intuition? And then you just ask that. Yeah. I mean, well, so I don't expect that this first AGI could answer any of those questions even as yes or nos.  

你可以问 "是 "或 "否 "的问题，比如这样的理论是否存在，它能否存在。那么，我首先会问这些问题。是或不是，非常肯定然后在此基础上 还有其他外星文明存在吗？有还是没有？你的直觉是什么？然后你就这么问是的，我是说，我不指望第一个AGI 能回答这些问题，即使是 "是 "或 "否

But if it could, those would be very high on my list. Hmm. Maybe it can start assigning probabilities. Maybe we need to go invent more technology and measure more things first. But if it's any AGI. Oh I see. It just doesn't have enough data.  

但如果可以的话，这些都会是我的首选。嗯也许它可以开始分配概率也许我们需要先发明更多的技术 测量更多的东西但如果它是人工智能的话我明白了它只是没有足够的数据

I mean, maybe it says like you want to know the answer to this question about physics, I need you to like build this machine and make these five measurements and tell me that. Yeah. What the hell do you want from me? I need the machine first and I'll help you deal with the data from that machine. Maybe you'll help me build a machine maybe. Maybe. And on the mathematical side, maybe prove some things.  

我的意思是，也许它说，就像你想知道这个物理问题的答案，我需要你像制造这台机器，做这五个测量，然后告诉我。好吧你到底想从我这得到什么？我先要机器 然后我会帮你处理机器上的数据也许你会帮我造一台机器也许吧在数学方面 也许能证明一些事情

Are you interested in that side of things too? The formalized exploration of ideas? Whoever builds AGI first gets a lot of power. Do you trust yourself with that much power. Look, I was gonna. I'll just be very honest with this answer. I was gonna say, and I still believe this, that it is important that I, nor any other one person, have total control over OpenAI or over AGI.  

你对这方面的事情也感兴趣吗？形式化的思想探索？谁先建立人工智能，谁就能获得巨大的权力。你相信自己有那么大的能力吗听着 我本来打算我就实话实说吧我想说的是，我仍然相信这一点，重要的是我或其他任何人都不能完全控制OpenAI或AGI。

And I think you want a robust governance system. I can point out a whole bunch of things about all of our board drama from last year about how I didn't fight it initially and was just like, yeah, that's the will of the board even though I think it's a really bad decision.  

我认为你需要一个强大的治理系统。我可以指出去年我们董事会的一大堆事情，说说我最初是如何没有抗争，只是说，是的，这是董事会的意愿，尽管我认为这是一个非常糟糕的决定。

And then later, I clearly did fight it and I can explain the nuance and why I think it was okay for me to fight it later. But as many people have observed, although the board had the legal ability to fire me, in practice, it didn't quite work. And that is its own kind of governance failure. Now, again, I feel like I can completely defend the specifics here and I think most people would agree with that.  

后来，我很清楚我确实抗争了，我可以解释其中的细微差别，以及为什么我认为我后来可以抗争。但是，正如很多人所观察到的，虽然董事会在法律上有能力解雇我，但在实践中，它并没有完全奏效。这本身就是一种治理失败。再说一遍，我觉得我完全可以为这里的具体细节辩护，我想大多数人都会同意这一点。

But it does make it harder for me to like look you in the eye and say, hey, the board can just fire me. I continue to not want super voting control over OpenAI. I never had it, never have wanted it. Even after all this craziness, I still don't want it. I continue to think that no company should be making these decisions and that we really need governments to put rules of the road in place.  

但这确实让我更难直视你的眼睛，然后说，嘿，董事会可以炒了我。我仍然不希望拥有对 OpenAI 的超级投票控制权。我从未拥有过，也从未想过。即使在发生了这么多疯狂的事情之后，我仍然不想要。我仍然认为，任何公司都不应该做出这些决定，我们真的需要政府来制定道路规则。

And I realize that means people like Marc Andreessen or whatever will claim I'm going for regulatory capture and I'm just willing to be misunderstood there. It's not true. And I think in the fullness of time, it'll get proven out why this is important.  

我意识到，这意味着像马克-安德烈森（Marc Andreessen）之类的人会说我是在进行监管捕获，而我只是愿意在这方面被误解。事实并非如此。我认为，随着时间的推移，这一点会被证明是很重要的。

But I think I have made plenty of bad decisions for OpenAI along the way and a lot of good ones and I'm proud of the track record overall, but I don't think any one person should. And I don't think any one person will. I think it's just like too big of a thing now and it's happening throughout society in a good and healthy way.  

但我认为，一路走来，我为 OpenAI 做了很多糟糕的决定，也做了很多好的决定，我为自己的整体业绩感到骄傲，但我认为任何一个人都不应该这样做。我也不认为任何人会这么做。我认为现在这件事太大了，它正在以一种良好而健康的方式在整个社会中发生。

But I don't think any one person should be in control of an AGI or this whole movement towards AGI. And I don't think that's what's happening. Thank you for saying that. That was really powerful and that was really insightful that this idea that the board can fire you is legally true. And human beings can manipulate the masses into overriding the board and so on.  

但我认为任何一个人都不应该控制 AGI 或整个 AGI 运动。我不认为这就是正在发生的事情。谢谢你这么说。这真的很有力量 也很有洞察力 董事会可以解雇你的想法 在法律上是正确的人类可以操纵大众推翻董事会等等

But I think there's also a much more positive version of that where the people still have power. So the board can't be too powerful either. There's a balance of power in all of this. Balance of power is a good thing for sure. Are you afraid of losing control of the AGI itself?  

但我认为还有一种更积极的说法，即人民仍然拥有权力。所以董事会也不能太强大。这一切都需要权力的平衡。权力平衡肯定是件好事。你害怕失去对 AGI 本身的控制吗？

That's a lot of people who worried about existential risk not because of state actors, not because of security concerns, but because of the AI itself. That is not my top worry as I currently see things. There have been times I worried about that more. There may be times again in the future where that's my top worry. It's not my top worry right now. What's your intuition about it not being your worry?  

很多人担心生存风险，不是因为国家行为体，不是因为安全问题，而是因为人工智能本身。在我看来，这并不是我目前最担心的问题。我也曾担心过这个问题。未来可能还会有一些时候，这是我最担心的问题。但这不是我现在最担心的问题。你的直觉是什么？

Because there's a lot of other stuff to worry about essentially. You think you could be surprised? We could be surprised. For sure, of course. Saying it's not my top worry doesn't mean I don't think we need to like. I think we need to work on it super hard. We have great people here who do work on that. I think there's a lot of other things we also have to get right.  

因为本质上还有很多其他事情要操心。你觉得你会大吃一惊吗？我们会大吃一惊的当然说这不是我最担心的问题 并不意味着我认为我们不需要担心我认为我们需要更加努力地工作。我们这里有很多优秀的人，他们都在为此努力。我认为我们还需要做好很多其他事情。

To you, it's not super easy to escape the box at this time, like connect to the internet. We talked about theatrical risk earlier. That's a theatrical risk. That is a thing that can really like take over how people think about this problem. And there's a big group of like very smart, I think very well-meaning AI safety researchers that got super hung up on this one problem.  

对你来说，现在要逃出这个盒子并不容易，就像连接互联网一样。我们之前谈到了戏剧风险。这就是戏剧风险。它真的会影响人们对这个问题的看法有一大群非常聪明的、我认为是善意的人工智能安全研究者们 在这一个问题上纠缠不清。

I'd argue without much progress, but super hung up on this one problem. I'm actually happy that they do that because I think we do need to think about this more. But I think it pushed aside, it pushed out of the space of discourse a lot of the other very significant AI-related risks. Let me ask you about you tweeting with no capitalization. Does the shift keep broken on your keyboard. Why does anyone care about that.  

我想说的是，我们没有取得什么进展，却在这一个问题上纠缠不休。事实上，我很高兴他们这样做，因为我认为我们确实需要更多地思考这个问题。但我认为，这把很多其他与人工智能相关的重大风险推到了一边，使其失去了讨论的空间。我想问一下你在推特上没有大写字母的问题。你键盘上的移位键是不是一直坏着？为什么会有人关心这个问题？

I deeply care. But why? I mean, other people ask me about that too. Any intuition. I think it's the same reason there's like this poet E. E. Cummings that mostly doesn't use capitalization to say like fuck you to the system kind of thing. And I think people are very paranoid 'cause they want you to follow the rules. You think that's what it's about. I think it's. This guy doesn't follow the rules.  

我非常关心。但为什么呢？我是说，其他人也会问我这个问题。任何直觉我觉得这和诗人E. E. Cummings的诗歌一样 大多不用大写字母来表达 去你妈的体制之类的东西我觉得人们很偏执 因为他们希望你遵守规则你觉得是这样吗？我觉得是这家伙不守规矩

He doesn't capitalize his tweets. This seems really dangerous. He seems like an anarchist. It doesn't. Are you just being poetic, hipster? What's the. I grew up as. Follow the rules, Sam. I grew up as a very online kid. I'd spent a huge amount of time like chatting with people back in the days where you did it on a computer and you could like log off instant messenger at some point.  

他的推文没有大写。这看起来真的很危险。他看起来像个无政府主义者才不是你是在吟诗作对吗 潮人?什么是。我长大了。遵守规则，山姆。我长大了一个非常在线的孩子。我花了大量的时间和人聊天 在电脑上聊天的日子里 你可以在某些时候注销即时通讯工具

And I never capitalized there as I think most like internet kids didn't, or maybe they still don't. I don't know. I actually, this is like. Now, I'm like really trying to reach for something. But I think capitalization has gone down over time. If you read like old English writing, they capitalized a lot of random words in the middle of sentences, nouns and stuff that we just don't do anymore.  

我从来没有大写过，因为我觉得大多数网络儿童都没有大写过，或许他们现在也没有大写过。我也不知道我其实，这就像，现在，我就像 真的想达到的东西。但我觉得随着时间的推移，大写字母的使用率已经下降了。如果你读到以前的英文文章 他们会在句子中间随意大写很多词 名词之类的 我们现在已经不这么做了

I personally think it's sort of like a dumb construct that we capitalize the letter at the beginning of a sentence and of certain names and whatever. That's fine. And I used to, I think, even like capitalize my tweets because I was trying to sound professional or something. I haven't capitalized my like private DMs or whatever in a long time.  

我个人认为，我们在句子开头和某些名字之类的地方把字母大写是一种愚蠢的做法。这很好。我以前，我想，甚至喜欢大写我的推文，因为我想听起来专业或什么的。我已经很久没大写过私人DM之类的了

And then slowly, stuff like shorter form, less formal stuff has slowly drifted to like closer and closer to how I would text my friends. If I write, if I pull up a Word document and I'm writing a strategy memo for the company or something, I always capitalize that. If I'm writing a long kind of more like formal message, I always use capitalization there too. So I still remember how to do it.  

然后慢慢地，简短的、不那么正式的东西慢慢变得越来越接近我给朋友发短信的方式。如果我写作，如果我打开一个 Word 文档，为公司写一份战略备忘录之类的东西，我总是使用大写字母。如果我写的是长篇的正式信息，我也总是使用大写字母。所以我还记得怎么做。

But even that may fade out. I don't know. But I never spend time thinking about this so I don't have like a ready made. Well, it's interesting. Well, it's good to, first of all, know there's the shift key is not broken. It works. I was mostly concerned about your wellbeing on that front. I wonder if people still capitalize their Google Searches.  

但即便如此，也可能会逐渐消失。我也不知道。但我从没花时间去想这个问题 所以我没有现成的答案这很有趣首先，很高兴知道Shift键没坏还能用我主要是担心你在这方面的健康状况我想知道人们在谷歌搜索的时候 I wonder if people still capitalize 是否还会大写 their Google Searches.

Like if you're writing something just to yourself or their ChatGPT queries, if you're writing something just to yourself, do some people still bother to capitalize. Probably not. Yeah, there's a percentage, but it's a small one. The thing that would make me do it is if people were like. It's a sign of like. Because I'm sure I could force myself to use capital letters, obviously.  

比如，如果你只是给自己或他们的ChatGPT查询写东西，如果你只是给自己写东西，有些人是否还会费心大写。可能不会。是的，有一定比例，但很小。如果人们喜欢，我就会这么做。这是喜欢的表现因为我可以强迫自己使用大写字母，很明显。

If it felt like a sign of respect to people or something, then I could go do it. But I don't know, I don't think about this. I don't think there's a disrespect, but I think it's just the conventions of civility that have a momentum and then you realize it's not actually important for civility if it's not a sign of respect or disrespect.  

如果我觉得这是对他人的尊重，我可以去做。但我不知道，我没想过这个问题。我不认为这是不尊重，但我认为这只是文明的惯例，有一种势头，然后你会意识到，如果这不是尊重或不尊重的标志，那么它实际上对文明并不重要。

But I think there's a movement of people that just want you to have a philosophy around it so they can let go of this whole capitalization thing. I don't think anybody else thinks about this is my. I mean, maybe some people. Think about this every day for many hours a day. I'm really grateful we clarified it. Can't be the only person that doesn't capitalize tweets. You're the only CEO of a company that doesn't capitalize tweets.  

但我认为，现在有很多人都希望你能提出一种理念，这样他们就能摆脱资本化的束缚。我不认为其他人会这么想。我的意思是，也许有些人。我每天都在思考这个问题，每天都要思考好几个小时。我真的很感激我们澄清了这一点。不可能只有你一个人不大写推文。你是唯一一个不给推文大写的公司首席执行官。

I don't even think that's true, but maybe, maybe. All right, we'll investigate for this and return to this topic later. Given Sora's ability to generate simulated worlds, let me ask you a pothead question. Does this increase your belief if you ever had one that we live in a simulation, maybe a simulated world generated by an AI system. Yes, somewhat. I don't think that's like the strongest piece of evidence.  

我甚至不认为这是真的，但也许，也许。好吧，我们先调查一下，以后再讨论这个话题。鉴于索拉有能力生成模拟世界，让我问你一个 "锅盖头 "问题。如果你相信我们生活在一个模拟世界里 也许是由人工智能系统生成的模拟世界 这是否会增加你的信念？是的，有点。我不认为这是最有力的证据

I think the fact that we can generate worlds should increase everyone's probability somewhat or at least open to it, openness to it somewhat. But you know, I was like certain we would be able to do something like Sora at some point. It happened faster than I thought. I guess that was not a big update. Yeah. And presumably, it'll get better and better and better. The fact that you can generate worlds, they're novel.  

我认为，我们可以生成世界这一事实应该会在一定程度上增加每个人的可能性，或者至少会在一定程度上增加他们的开放性。但你知道吗，我很确定我们会在某个时候做出像《索拉》这样的作品。事情发生得比我想象的要快。我想那不是什么大更新吧是啊而且应该会越来越好吧你能生成世界的事实很新颖

They're based in some aspect of training data, but when you look at them, they're novel. That makes you think like how easy it's to do this thing, how easy it's to create universes, entire like video game worlds that seem ultrarealistic and photorealistic. And then how easy is it to get lost in that world first with a VR headset and then on the physics-based level.  

它们基于训练数据的某些方面，但当你看到它们时，它们是新颖的。这让你觉得做这件事是多么容易，创造宇宙是多么容易，整个世界就像视频游戏世界，看起来超真实、超逼真。首先使用 VR 头显，然后在基于物理的层面上，迷失在那个世界里是多么容易的一件事。

Someone said to me recently, I thought it was a super profound insight that there are these like very simple sounding, but very psychedelic insights that exist sometimes. So the square root function. Square root of four, no problem. Square root of two, okay, now I have to think about this new kind of number.  

最近有人对我说，我觉得这是个超级深刻的见解，有的时候，这些见解听起来非常简单，但却非常迷幻。平方根函数4的平方根，没问题。2的平方根，好吧，现在我得想想这种新的数字了。

But once I come up with this easy idea of a square root function that you can kind of explain to a child and exists by even like looking at some simple geometry, then you can ask the question of what is the square root of negative one? This is why it's like a psychedelic thing that tips you into some whole other kind of reality. And you can come up with lots of other examples.  

但是，一旦我想出了这个简单的平方根函数的概念，你甚至可以像看一些简单的几何图形一样向孩子解释它的存在，然后你就可以问负1的平方根是多少这个问题了。这就是为什么它就像一种迷幻剂，能让你进入另一种完全不同的现实世界。你还可以举出很多其他的例子。

But I think this idea that the lowly square root operator can offer such a profound insight and a new realm of knowledge, applies in a lot of ways. And I think there are a lot of those operators for why people may think that any version that they like of the simulation hypothesis is maybe more likely than they thought before. But for me, the fact that Sora worked is not in the top five.  

但我认为，这个低级的平方根算子能提供如此深刻的洞察力和新的知识领域的想法，在很多方面都适用。我认为，人们之所以会认为他们喜欢的任何版本的模拟假说都比他们之前想象的更有可能，其中有很多算子的原因。但对我来说，索拉成功的事实并不在前五名之列。

I do think broadly speaking, AI will serve as those kinds of gateways at its best simple psychedelic like gateways to another wave sea reality. That seems for certain. That's pretty exciting. I haven't done Ayahuasca before, but I will soon. I'm going to the aforementioned Amazon jungle in a few weeks. Excited. Yeah, I'm excited for it. Not the Ayahuasca part. That's great, whatever.  

我确实认为，从广义上讲，人工智能将成为通往另一波海现实的最简单迷幻的通道。这似乎是肯定的。这太令人兴奋了我以前没喝过死藤水，但很快就会喝了。几周后我就要去亚马逊丛林了很兴奋是的，我很兴奋不是死藤水那部分那很好，随便啦

But I'm gonna spend several weeks in the jungle, deep in the jungle and it's exciting, but it's terrifying. I'm excited for you.-'Cause there's a lot of things that can eat you there and kill you and poison you, but it's also nature and it's the machine of nature.  

但我要在丛林深处待上几个星期 这很刺激，但也很恐怖 我为你感到兴奋我为你感到兴奋，因为那里有很多东西会吃掉你、杀死你、毒死你，但那里也是大自然，是大自然的机器。

And you can't help but appreciate the machinery of nature in the Amazon jungle 'cause it's just like this system that just exists and renews itself like every second, every minute, every hour. It's the machine. It makes you appreciate like this thing we have here, this human thing came from somewhere. This evolutionary machine has created that and it's most clearly on display in the jungle. So hopefully, I'll make it out alive.  

在亚马逊丛林里，你会情不自禁地欣赏大自然的机器 因为它就像一个系统，每秒、每分钟、每小时都在自我更新。这就是机器它让你体会到我们这里的一切 人类的一切都来自某处这台进化机器创造了人类 它在丛林中展现得淋漓尽致希望我能活着出来

If not, this will be the last conversation we had, so I really deeply appreciate it.  

如果没有，这将是我们最后一次谈话，所以我真的非常感激。

Do you think, as I mentioned before, there's other aliens, civilizations out there, intelligent ones when you look up at the skies. I deeply want to believe that the answer is yes. I do find that kind of where. I find the firm paradox very, very puzzling. I find it scary that intelligence is not good at handling. Yeah. Very scary, powerful. Technologies.  

你是否认为，就像我之前提到的，当你仰望天空时，还有其他的外星人、文明、智慧生物存在。我非常愿意相信答案是肯定的。我确实觉得有这种可能。我觉得坚定的悖论非常非常令人费解。我觉得这很可怕 智能不擅长处理。是啊。非常可怕，强大的。技术

But at the same time, I think I'm pretty confident that there's just a very large number of intelligent alien civilizations out there. It might just be really difficult to travel with this space. Very possible. And it also makes me think about the nature of intelligence. Maybe we're really blind to what intelligence looks like and maybe AI will help us see that. It's not as simple as IQ tests and simple puzzle solving. There's something bigger.  

但与此同时，我认为我很有信心 外面存在着大量的外星智慧文明在这个空间旅行可能真的很困难很有可能这也让我思考智慧的本质也许我们真的不知道智慧是什么样子 也许人工智能会帮助我们看到这一点它不像智商测试和简单的解谜那么简单还有更重要的东西。

Well, what gives you hope about the future of humanity? This thing we've got going on, this human civilization. I think the past is like a lot. I mean, we just look at what humanity has done in a not very long period of time. Huge problems, deep flaws, lots to be super ashamed of, but on the whole, very inspiring, gives me a lot of hope.  

是什么让你对人类的未来充满希望？是我们的人类文明我觉得过去有很多我的意思是，我们只要看看人类在不长的时间里都做了些什么。巨大的问题，深刻的缺陷，很多令人羞愧的事情，但总的来说，非常鼓舞人心，给了我很多希望。

Just the trajectory of it all that we're together pushing towards a better future. It is. One thing that I wonder about is, is AGI gonna be more like some single brain, or is it more like the sort of scaffolding in society between all of us? You have not had a great deal of genetic drift from your great-great-great grandparents, and yet what you're capable of is dramatically different. What you know is dramatically different.  

我们正共同迈向更美好的未来。没错我想知道的一件事是 AGI 会更像某个单一的大脑 还是更像我们所有人之间的社会支架？你和你曾曾曾祖父母的基因漂移不大 但你的能力却大不相同你所知道的也大不相同。

That's not because of biological change. I mean, you got a little bit healthier probably. You have modern medicine, you eat better, whatever. But what you have is this scaffolding that we all contributed to built on top of. No one person is gonna go build the iPhone. No one person is gonna go discover all of science. And yet you get to use it. And that gives you incredible ability.  

这不是因为生理变化。我的意思是，你可能变得更健康了。你有现代医学，你吃得更好，等等。但你拥有的是我们共同搭建的脚手架。没有一个人可以造出 iPhone。没有人会去发现所有的科学。但你却可以使用它这给了你难以置信的能力

And so in some sense, that like we all created that and that fills me with hope for the future. That was a very collective thing. Yeah. We really are standing on the shoulders of giants. You mentioned when we were talking about theatrical, dramatic AI risks that sometimes you might be afraid for your own life. Do you think about your death? Are you afraid of it.  

因此，从某种意义上说，这就像是我们共同创造的，让我对未来充满希望。这是一个非常集体的事情。是啊我们真的是站在巨人的肩膀上。当我们谈到戏剧性的人工智能风险时，你提到 有时你会担心自己的生命安全。你想过自己的死吗？你害怕吗

I mean, I like if I got shot tomorrow and I knew it today, I'd be like, "Oh, that's sad. I wanna see what's gonna happen. Yeah. What a curious time. What an interesting time. But I would mostly just feel like very grateful for my life. The moments that you did get. Yeah, me too. It's a pretty awesome life.  

我的意思是，如果我明天就中枪了 而我今天就知道了，我会说："哦，那真可怜。我想看看会发生什么是啊真是个好奇的时代多么有趣的时刻但我更多的是感激我的生活你得到的时刻是啊，我也是。这是一个相当真棒生活。

I get to enjoy awesome creations of humans of which I believe ChatGPT is one of, and everything that OpenAI is doing. Sam, it's really an honor and pleasure to talk to you again. Great to talk to you. Thank you for having me. Thanks for listening to this conversation with Sam Altman. To support this podcast, please check out our sponsors in the description. And now let me leave you with some words from Arthur C. Clarke and maybe that our role on this planet is not to worship God, but to create Him. Thank you for listening and hope to see you next time.  

我可以欣赏到人类了不起的创造，我相信ChatGPT就是其中之一，我还可以欣赏到OpenAI正在做的一切。山姆，很荣幸再次与你交谈。很高兴与你交谈。感谢您的邀请。感谢您收听本期与 Sam Altman 的对话。如果您想支持本播客，请在描述中查看我们的赞助商。现在让我用阿瑟-C-克拉克（Arthur C. Clarke）的话来结束这次谈话，也许我们在这个星球上的角色不是崇拜上帝，而是创造上帝。感谢您的收听，希望下次再见。
