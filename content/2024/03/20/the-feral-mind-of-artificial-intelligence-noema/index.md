---
title: "大型语言模型是否有意识？"
date: 2024-03-20T18:21:19+08:00
updated: 2024-03-20T18:21:19+08:00
taxonomies:
  tags: []
extra:
  source: https://www.noemamag.com/feral-intelligence/?utm_source=substack&utm_medium=email
  hostname: www.noemamag.com
  author: Stephanie Kotin
  original_title: "The Feral Mind Of Artificial Intelligence | NOEMA"
  original_lang: en
---

John Last is a freelance journalist based in Padua, Italy.  

John Last 是一名自由职业记者，常驻意大利帕多瓦。

Found in the hilly woods of Haute-Languedoc, he must have first seemed a strange kind of animal: naked, afraid, often hunched on all fours, foraging in the undergrowth.  

它是在上朗格多克的山林中被发现的，起初看起来一定是一种奇怪的动物：赤身裸体，害怕，经常四肢蜷缩，在灌木丛中觅食。  

But this was no mere animal.  

但这不是一只普通的动物。  

Victor, as he would come to be known, was a scientific marvel: a feral child, perhaps 12 years of age, completely untouched by civilization or society.  

维克多后来被人们称为科学奇迹：一个野孩子，大概只有 12 岁，完全没有受到文明或社会的影响。

Accounts vary, but we know that eventually Victor was whisked away to a French hospital, where news of his discovery spread fast.  

各种说法不一，但我们知道，维克多最终被送往一家法国医院，他被发现的消息在那里迅速传播开来。  

By the winter of 1799, the story of the “Savage of Aveyron” had made its way to Paris, where it electrified the city’s learned community.  

1799 年冬天，"阿韦龙的野人 "的故事传到了巴黎，并在巴黎的知识界引起了轰动。  

On the cusp of a new century, France was in the midst of a nervy transition, and not only because of the rising tyranny of the Bonapartes.  

在新世纪到来之际，法国正处于紧张的转型期，这不仅是因为波拿巴暴政的抬头。  

The previous few decades had seen the rational inquiries of philosophers like Jean-Jacques Rousseau and the Baron de Montesquieu shake the religious foundations of the nation.  

前几十年，让-雅克-卢梭和孟德斯鸠男爵等哲学家的理性探索动摇了国家的宗教基础。

It was a time of vigorous debate about which powers, exactly, nature imparted to the human subject.  

在那个时代，关于大自然究竟赋予人类哪些力量的争论十分激烈。  

Was there some biological inevitability to the development of our elevated consciousness?  

我们的高级意识的发展是否有某种生物学上的必然性？  

Or did our societies convey to us a greater capacity to reason than nature alone could provide?   

还是我们的社会向我们传递了比自然本身所能提供的更强的推理能力？

Victor, a vanishingly rare example of a human mind developed without language or society, could seemingly answer many such questions.  

维克多是人类在没有语言和社会的情况下发展起来的思想的一个罕见例子，他似乎可以回答许多这样的问题。  

So it was only natural that his arrival in Paris, in the summer of 1800, was greeted with great excitement.  

因此，他在 1800 年夏天抵达巴黎时，自然受到了热烈欢迎。

“The most brilliant but unreasonable expectations were formed by the people of Paris respecting the Savage of Aveyron, before he arrived,” [wrote](https://books.googleusercontent.com/books/content?req=AKW5Qacakn3tQtJB-eBAt0m2rkve8pP1-kQGr1czs1uASZFyxE7Lf8jZLzwvC1ZkkUYjL5L0UH3GpyeAkgqRf0VAEI82JF1wP7b-E9zWABbeX06tvsXUphkjBow8kb7uuzMKAZkSox2GhgjbfHHwYFUAMKxeyjY0gOCBatdtaEtoewnnjnd8Ab9ik4x257wvhZdJma_yJ3zaapr6tVGADQsaWTb6IGhUc9sVPqJniuOtlUR-VzwhOza1vMO7JamEVwlZcEdmWV9Eo4zDTblyV1YHOQXNr70vLw) Jean Marc Gaspard Itard, the man eventually made responsible for his rehabilitation.  

"让-马克-加斯帕德-伊塔德（Jean Marc Gaspard Itard）写道："在阿韦龙的野人到来之前，巴黎人对他抱有最美好但最不合理的期望。  

“Many curious people anticipated great pleasure in beholding what would be his astonishment at the sight of all the fine things in the capital.”  

"许多好奇的人期待着看到他在看到首都的所有美好事物时会有怎样的惊奇"

“Instead of this, what did they see?” he continued.  

"他继续问道："与此相反，他们看到了什么？  

“A disgusting, slovenly boy … biting and scratching those who contradicted him, expressing no kind of affection for those who attended upon him; and, in short, indifferent to everybody, and paying no regard to anything.”  

"一个令人作呕的、邋遢的男孩......对顶撞他的人又咬又抓，对照顾他的人毫无好感；总之，对每个人都漠不关心，对任何事都不屑一顾"。

“Is there some biological inevitability to the development of our elevated consciousness?  

"我们的高级意识的发展是否有某种生物学上的必然性？  

Or do our societies convey to us a greater capacity to reason than nature alone could provide?”  

还是我们的社会向我们传递了比自然本身所能提供的更强的理性能力？

Faced with the reality of an abandoned, developmentally delayed child, many of the great minds of Paris quickly turned on him.  

面对一个被遗弃、发育迟缓的孩子的现实，巴黎的许多大人物很快就把目光转向了他。  

Some called him an imposter; others, a congenital “idiot” — a defective mind or missing link, perhaps, to some lesser race of human.  

有人说他是个冒牌货；还有人说他是个先天性的 "白痴"--也许是心智有缺陷，也许是与某些低等人种的联系缺失。  

His critics [herded](https://www.degruyter.com/document/doi/10.1515/9783110854893.101/html?lang=en) to an ever-harsher position of biological essentialism — a conservative reaction to Enlightenment ideas about the exceptionality of our minds that countered that our capacities were determined by natural inequalities alone.  

他的批评者对生物本质论的立场越来越严苛--生物本质论是对启蒙思想的保守反动，认为我们的思维能力是由自然的不平等决定的。

Unlike these antagonists, Itard never doubted that the boy was still capable of deep interior thought — he witnessed his “contemplative ecstasy” on occasion.  

与这些对立面不同，伊塔德从未怀疑过这个男孩仍然能够进行深入的内心思考--他偶尔会目睹他的 "沉思狂喜"。  

But he soon realized that without the power of speech, such contemplation would remain forever locked in Victor’s mind, far from the view of his harshest critics.  

但他很快意识到，如果没有语言能力，这种沉思将永远锁在维克多的脑海中，远离他最严厉的批评者的视线。  

Nor could Victor, without the subtleties of speech at his disposal, acquire the more abstract wants that defined civilized man: the appreciation of beautiful music, fine art or the loving company of others.  

维克多没有精妙的语言表达能力，他也无法获得文明人更抽象的需求：欣赏美妙的音乐、精美的艺术或与他人相亲相爱。

Itard spent years tutoring Victor in the hope that he might gain the power of language.  

伊塔德花了数年时间辅导维克多，希望他能获得语言的力量。  

But he never succeeded in his quest.  

但他的追求从未成功。  

He denied Victor food, water and affection, hoping he would use words to express his desires — but despite no physical defect, it seemed he could not master the sounds necessary to produce language.  

他不给维克多食物、水和关爱，希望他能用语言表达自己的愿望，但尽管维克多没有身体缺陷，他似乎无法掌握产生语言所需的声音。  

“It appears that speech is a kind of music to which certain ears, although well organized in other respects, may be insensible,” Itard recorded.  

"伊塔德记录道："看来，语言是一种音乐，某些耳朵虽然在其他方面很有条理，但对这种音乐却无感。

Despite Itard’s failure to rehabilitate Victor, his effort, viewable only through the coke-bottle glass of 18th-century science, continues to haunt our debates about the role of language in enabling the higher cognition we call consciousness.  

尽管伊塔德没能让维克多恢复名誉，但他的努力只能通过 18 世纪科学的可乐瓶玻璃杯来观察，却继续困扰着我们关于语言在促成我们称之为意识的高级认知方面的作用的辩论。  

Victor is one of a tiny sample of cases where we can glimpse the nature of human experience without language, and he has long been seen as a possible key to understanding the role it plays in the operation of our minds.  

维克多是我们可以在没有语言的情况下窥见人类经验本质的极少数案例之一，他一直被视为理解语言在我们思维运作中所起作用的关键。

Today, this field, for most of its history a largely academic one, has taken on an urgent importance.  

如今，这个在历史上大部分时间都以学术研究为主的领域已变得十分重要。  

Much like Itard, we stand at the precipice of an exciting new age where the foundational understandings of our own natures and our cosmos are being rocked by new technologies and discoveries, confronting something that threatens to upend what little agreement we have about the exceptionality of the human mind.  

与伊塔德一样，我们正站在一个激动人心的新时代的悬崖边上，在这个时代里，我们对自身本性和宇宙的基本理解正被新技术和新发现所震撼，我们所面对的东西有可能颠覆我们对人类思维的特殊性所达成的一点共识。  

Only this time, it’s not a mind without language, but the opposite: language, without a mind.  

只是这一次，不是没有语言的头脑，而是恰恰相反：没有头脑的语言。

In the past few years, large language models (LLMs) have spontaneously developed unnerving abilities to mimic the human mind, threatening to disrupt the tenuous moral universe we have established on the basis of our elevated consciousness, one made possible by the power of our language to reflect the hidden inner workings of our brains.  

在过去的几年里，大型语言模型（LLMs）自发地发展出了令人不安的模仿人类思维的能力，有可能破坏我们在意识提升的基础上建立起来的脆弱的道德世界。

Now, in a strange symmetry across centuries, we are presented with the exact opposite question to the one raised by Victor two hundred years ago: Can consciousness really develop from language alone?  

现在，一个奇怪的跨世纪对称现象向我们提出了一个与维克多在两百年前提出的问题完全相反的问题：意识真的可以仅仅从语言中发展出来吗？

___

First, a disclaimer.  

首先是免责声明。  

Consciousness is a notoriously slippery term, if nonetheless possessed of a certain common-sense quality.  

意识是一个出了名的模糊词汇，尽管它具有一定的常识性。  

In some ways, being conscious just means being aware — aware of ourselves, of others, of the world beyond — in a manner that creates a subject apart, a self or “I,” that can observe.  

在某些方面，有意识只是意味着意识到--意识到我们自己、他人和外面的世界--在某种程度上创造了一个独立的主体，一个能够观察的自我或 "我"。

That all sounds simple enough, but despite centuries of deep thinking on the matter, we still don’t have a commonly accepted definition of consciousness that can encapsulate all its theoretical extensions.  

这一切听起来很简单，但尽管我们对这个问题进行了几个世纪的深入思考，我们仍然没有一个公认的、能够囊括所有理论延伸的意识定义。  

It’s one reason why philosophers still have such trouble agreeing whether consciousness is unique to human beings or whether the term can be extended to certain high-functioning animals — or, indeed, algorithms.  

这也是为什么哲学家们仍然难以就意识是人类独有的，还是可以扩展到某些高功能动物--或者算法--达成一致的原因之一。

Cognition is a more exact term. We might say cognition means performing the act of thinking.  

认知是一个更确切的术语。我们可以说，认知是指进行思考的行为。  

That sounds simple, but it is still, scientifically, exceedingly difficult to observe and define.  

这听起来很简单，但在科学上，要观察和定义它仍然非常困难。  

What is the difference, after all, between proper thinking and chemical activity occurring in the brain?  

正确的思考与大脑中发生的化学活动之间到底有什么区别？  

Or indeed, the output of a complex computer program?  

或者是复杂计算机程序的输出结果？  

The difference, we might say, is that the former involves a subject with agency and intention and past experience performing an act of thinking.  

我们可以说，两者的区别在于，前者是由一个具有能动性、意图和过去经验的主体来实施思维行为。  

In other words, one involves consciousness — and now we are right back where we started.  

换句话说，其中一个涉及到意识--现在我们又回到了起点。

In trying to gain a scientific understanding of how cognition works and thus move toward a better definition of consciousness, language has played an increasingly important role.  

在试图从科学角度理解认知如何运作，从而更好地定义意识的过程中，语言扮演着越来越重要的角色。  

It is, after all, one of the only ways we can clearly externalize the activity of our interior minds and demonstrate the existence of a self at all.  

毕竟，这是我们将内在思维活动清晰外化并证明自我存在的唯一途径之一。  

“Self-report,” as the cognitive scientist David J. Chalmers [calls it](https://philpapers.org/archive/CHACAL-3.pdf), is still one of our main criteria for recognizing consciousness — to paraphrase René Descartes, I _say_ I think, therefore, I am.  

认知科学家戴维-查莫斯（David J. Chalmers）所说的 "自我报告 "仍然是我们识别意识的主要标准之一--套用勒内-笛卡尔的话说，我说我想，所以我是。

But philosophers remain divided on how much, exactly, language relates to thinking.  

但是，对于语言与思维的关系究竟有多大，哲学家们仍然众说纷纭。  

In debates going back to [Plato and Aristotle](https://academic.oup.com/book/8247/chapter-abstract/153826853?redirectedFrom=fulltext), thinkers have generally occupied two broad camps: Either language imperfectly reflects a much richer interior world of the mind, which is capable of operating without it, or it enables the thought that occurs in the mind and, in the process, delimits and confines it.  

在可追溯到柏拉图和亚里士多德的争论中，思想家们一般分为两大阵营：要么是语言不完美地反映了更为丰富的心灵内部世界，而心灵内部世界在没有语言的情况下也能够运作；要么是语言促成了心灵中出现的思想，并在这一过程中对其进行了限定和束缚。

Where we fall in this debate has major consequences for how we approach the question of whether an LLM could, in fact, be conscious.  

我们在这场辩论中的立场，对我们如何处理LLM事实上是否有意识这一问题有着重要影响。  

For members of the former camp, the ability to think and speak in language may only be a kind of tool, a reflection of some (perhaps uniquely human) preexisting capacity — a “universal grammar,” in the philosophy of [Noam Chomsky](https://oxfordre.com/linguistics/display/10.1093/acrefore/9780199384655.001.0001/acrefore-9780199384655-e-86?rskey=oy5Iws&result=6) — that already exists in our conscious minds.  

对于前一个阵营的成员来说，用语言思考和说话的能力可能只是一种工具，是某种（也许是人类独有的）先在能力--诺姆-乔姆斯基哲学中的 "通用语法"--已经存在于我们有意识的头脑中的反映。

“It would seem that a life without language permanently impacts children’s cognitive abilities and perhaps even their capacity to conceive of and understand the world.”  

"没有语言的生活似乎会永久性地影响儿童的认知能力，甚至可能影响他们想象和理解世界的能力"。

But the stories of so-called “linguistic isolates” like Victor seem to trouble this theory.  

但维克多等所谓 "语言孤立者 "的故事似乎给这一理论带来了麻烦。  

Among the few that have been meaningfully [studied](https://riojournal.com/article/20696/), none developed an understanding of grammar and syntax, even after years of rehabilitation.  

在少数进行过有意义研究的人中，没有人能够理解语法和句法，即使经过多年的康复训练也是如此。  

If not acquired by a certain age, it would appear that complex language remains forever inaccessible to the human mind.  

如果到了一定年龄还不掌握复杂的语言，人类的大脑似乎永远都无法使用复杂的语言。

That’s not all — there are consequences to a life without language.  

这还不是全部--没有语言的生活是有后果的。  

Lending credence to arguments that speech plays some constructive role in our consciousness, it would seem that its absence permanently impacts children’s cognitive abilities and perhaps even their capacity to conceive of and understand the world.  

言语在我们的意识中扮演着某种建设性的角色，这种论点似乎是可信的，因为言语的缺失会永久性地影响儿童的认知能力，甚至可能影响他们构想和理解世界的能力。

In 1970, Los Angeles County child welfare authorities discovered Genie, a 13-year-old girl who had been kept in near-total isolation from the age of 20 months.  

1970 年，洛杉矶县儿童福利机构发现了从 20 个月大开始就几乎与世隔绝的 13 岁女孩吉妮。  

Like Victor, Genie knew virtually no language and, despite years of rehabilitation, could never develop a capacity for grammatical language.  

和维克多一样，吉尼几乎不懂语言，尽管经过多年的康复治疗，但始终无法发展语法能力。

But in their study of the girl, researchers discovered something else unusual about her cognition.  

但是，在对这个女孩的研究中，研究人员发现了她在认知方面的另一些不同寻常之处。  

Genie could not understand spatial prepositions — she did not know the difference, for example, between a cup being behind or in front of a bowl, despite familiarity with both objects and their proper names.  

吉妮无法理解空间介词--例如，她不知道杯子在碗的后面还是前面有什么区别，尽管她熟悉这两种物体及其专有名称。

A 2017 [meta-analysis](https://riojournal.com/article/20696/) found the same cognitive issue could be observed in other individuals who lacked grammatical language, like patients with [agrammatic aphasia](https://www.tandfonline.com/doi/full/10.1080/02687038.2020.1770196) and deaf children raised with “kitchensign,” improvised sign language that lacks a formal grammar.  

2017 年的一项荟萃分析发现，在其他缺乏语法的人身上也能观察到同样的认知问题，比如语法性失语症患者和用 "厨房手语"（缺乏正式语法的即兴手语）养育的聋哑儿童。  

From this, the researchers concluded that language must play a foundational role in a key function of the human mind: “mental synthesis,” the creation and adaptation of mental pictures from words alone.  

由此，研究人员得出结论，语言在人类思维的一项关键功能中扮演着基础性的角色："心理综合"，即仅从文字中创造和调整心理图像。

In many ways, mental synthesis is the core operation of human consciousness.  

在许多方面，精神综合是人类意识的核心运作。  

It is essential to our development and adaptation of tools, our predictive and reasoning abilities, and our communication through language.  

它对我们开发和适应工具、预测和推理能力以及通过语言进行交流至关重要。  

According to some philosophers, it may even be essential to our conception of self — the observing “I” of self-awareness.  

一些哲学家认为，它甚至可能是我们自我概念--自我意识中观察到的 "我"--的基本要素。

“Could an AI’s understanding of grammar, and their comprehension of concepts through it, really be enough to create a kind of thinking self?”  

"人工智能对语法的理解，以及通过语法对概念的理解，真的足以创造出一种会思考的自我吗？"

In “[The Evolution of Consciousness](https://archive.org/details/evolutionofconsc0000macp),” the psychologist Euan Macphail offers a theoretical explanation for why language and the mental synthesis it enables are so crucial for the development of a conscious self.  

在《意识的进化》一书中，心理学家尤安-麦克菲尔（Euan Macphail）从理论上解释了为什么语言及其促成的心理综合对有意识自我的发展如此重要。  

“Once the cognitive leap necessary for discriminating between self and non-self has been made — a leap that requires the ability to formulate thoughts ‘about’ representations — the organism has in effect, not only a _concept_ of self, but a ‘self’ — a novel cognitive structure that stands above and outside the cognitive processes,” he writes.  

"他写道："一旦实现了区分自我和非我所需的认知飞跃--这种飞跃需要有能力提出'关于'表象的想法--生物体实际上就不仅有了自我概念，而且有了'自我'--一种凌驾于认知过程之上和之外的新型认知结构。

Put another way, it may be possible to think, in some fashion, without generating a conscious self — performing simple mathematical calculations, for example.  

换句话说，在某种程度上，我们可以在不产生有意识的自我的情况下进行思考，比如进行简单的数学计算。  

But thinking _about_ something — a tart green apple, Louis XVI of France — involves some mental synthesis of an object outside the self.  

但是，对某些事物的思考--酸甜的青苹果、法国的路易十六--涉及到对自我之外的对象的某种心理综合。  

In effect, it creates a thinking self, one necessarily capable of being aware of what is happening to it.  

实际上，它创造了一个会思考的自我，一个必然能够意识到自己身上发生了什么的自我。  

“It is the availability of language that confers on us, first, the ability to be self-conscious, and second, the ability to feel,” Macphail concludes.  

"麦克菲尔总结道："正是语言的存在赋予了我们：第一，自我意识的能力；第二，感受的能力。

This leads him to some radical and uncomfortable conclusions.  

这让他得出了一些激进而令人不安的结论。  

Pleasure and pain, he argues, are dependent on the existence of this conscious, thinking self, a self that cannot be observed in young infants and animals.  

他认为，快乐和痛苦取决于这个有意识、有思想的自我的存在，而这个自我在幼婴和动物身上是无法观察到的。  

Does that mean Genie and Victor did not suffer from their abandonment just because they appeared incapable of performing mental synthesis?  

这是否意味着吉尼和维克多并没有因为被遗弃而痛苦，只是因为他们似乎无法进行精神综合？

Cases involving vulnerable children do not present moral challenges to most people, and it is easy to conclude, as the authors of the 2017 meta-analysis did, that these children may well still be capable of an interior mental synthesis, if not the communication or comprehension of it through language.  

对大多数人来说，涉及弱势儿童的案件并不构成道德挑战，而且很容易得出结论，正如 2017 年荟萃分析的作者所做的那样，这些儿童即使不能通过语言进行交流或理解，也很可能仍然能够进行内部心理综合。

But when it comes to AI, the water is murkier.  

但说到人工智能，情况就比较复杂了。  

Could an AI’s understanding of grammar, and their comprehension of concepts through it, really be enough to create a kind of thinking self?  

人工智能对语法的理解，以及通过语法对概念的理解，真的足以创造出一种会思考的自我吗？  

Here we are caught between two vague guiding principles from two competing schools of thought.  

在这里，我们夹在两个相互对立的学派的两个模糊指导原则之间。  

In Macphail’s view, “Where there is doubt, the only conceivable path is to act as though an organism is conscious, and does feel.” On the other side, there is “[Morgan’s canon](https://link.springer.com/referenceworkentry/10.1007/978-3-319-47829-6_495-1)”: Don’t assume consciousness when a lower-level capacity would suffice.  

麦克菲尔认为，"在存在疑问的地方，唯一可以想象的途径就是把有机体当作有意识的，并且确实有感觉"。另一方面，还有 "摩根法则"：当较低级别的能力就足够时，不要假定生物有意识。

If we do accept that language alone might be capable of prompting the emergence of real consciousness, we should prepare for a major shakeup of our current moral universe.  

如果我们真的接受了仅凭语言就能促使真正意识出现的观点，那么我们就应该做好准备，对我们当前的道德世界进行一次大洗牌。  

As Chalmers put it in a 2022 [presentation](https://philpapers.org/archive/CHACAL-3.pdf), “If fish are conscious, it matters how we treat them. They’re within the moral circle.  

正如查莫斯在 2022 年的一次演讲中所说："如果鱼是有意识的，那么我们如何对待它们就很重要。它们属于道德范畴。  

If at some point AI systems become conscious, they’ll also be within the moral circle, and it will matter how we treat them.”  

如果某个时候人工智能系统有了意识，它们也会被纳入道德范畴，我们如何对待它们就变得很重要了。

In other words, our little moral circle is about to be radically redrawn.  

换句话说，我们的道德小圈子即将彻底改写。

___

What can large language models actually do, really? On the one hand, the answer is simple.  

大型语言模型到底能做什么？一方面，答案很简单。  

LLMs are at their core language-based probability engines: In response to prompts, they make highly educated guesses about the most likely next word in a phrase based on a statistical analysis of a vast array of human output.  

LLMs的核心是基于语言的概率引擎：根据提示，它们会在对大量人类输出结果进行统计分析的基础上，对一个短语中最有可能出现的下一个词做出高度推测。  

This nonetheless does not preclude them from [writing](https://osf.io/preprints/psyarxiv/uacjm) original poetry, [solving](https://arxiv.org/abs/2206.07682) complex word problems and producing human-like [personalities](https://arxiv.org/abs/2204.12000) ranging from the obsequious to the [psychopathic](https://arxiv.org/abs/2212.10529).  

不过，这并不妨碍它们写出原创诗歌，解决复杂的文字问题，并创造出从谄媚到变态的类似人类的人格。

This kind of statistical sequencing is what we might call the “thinking” that an LLM actually does.  

我们可以把这种统计排序称为LLM实际进行的 "思考"。  

But even under Macphail’s schema, for this to constitute consciousness — and not simple calculation — there would have to be some _understanding_ that follows from it.  

但是，即使在麦克菲尔的图式中，要使这构成意识--而不是简单的计算--还必须有某种由此产生的理解。

Back in 1980, well before AI was powerful enough to trouble our definitions of consciousness, the philosopher [John Searle](https://philpapers.org/rec/SEAMBA) articulated an argument for why we should be skeptical that computer models like LLMs actually do understand any of the work they are performing.  

早在 1980 年，也就是人工智能强大到足以给我们的意识定义带来麻烦之前，哲学家约翰-塞尔（John Searle）就提出了一个论点，说明我们为什么应该怀疑LLMs这样的计算机模型是否真的理解它们正在执行的任何工作。  

In his now infamous “[Chinese Room](https://plato.stanford.edu/entries/chinese-room/)” argument, Searle suggested a hypothetical scenario where a person who speaks English is locked in a room and given instructions in English on how to write certain Chinese characters.  

在他现在臭名昭著的 "中文房间 "论证中，塞尔提出了这样一个假设情景：一个会说英语的人被关在一个房间里，有人用英语指导他如何书写某些汉字。

In Searle’s view, it wouldn’t be necessary that the person in the room possesses any actual _understanding_ of Chinese — they are simply a calculating machine, manipulating symbols that, for them, have no actual semantic content.  

在塞尔看来，房间里的人并不需要真正理解中文--他们只是一台计算机器，操纵着对他们来说没有实际语义内容的符号。  

What the person in the room lacks is what some philosophers call “groundedness” — experience of the real thing the symbol refers to.  

房间里的人缺乏的是一些哲学家所说的 "脚踏实地"--对符号所指真实事物的体验。

“LLMs do not appear to be following a human-like development path, instead unexpectedly evolving like some alien organism.”  

"LLMs似乎并没有遵循类似人类的发展路径，而是出人意料地像某种外星生物一样进化"。

Despite repeated cycles of AI doomerism and hype, this remains perhaps the dominant view of what LLMs do when they “think.” According to one [paper](https://arxiv.org/ftp/arxiv/papers/2305/2305.07666.pdf), they remain little more than highly advanced “cultural technologies” like the alphabet or printing press — something that superpowers human creativity but remains fundamentally an extension of it.   

尽管人工智能的谬论和炒作一再出现，但这或许仍是人们对LLMs"思考 "的主流看法。有一篇论文认为，LLMs只不过是高度先进的 "文化技术"，就像字母表或印刷机一样--它们能增强人类的创造力，但从根本上说，它们仍然是人类创造力的延伸。

But in the last few years, as LLMs have grown massively more sophisticated, they have started to challenge this understanding — in part by demonstrating the kinds of capacities that Victor and Genie struggled to, and which Macphail sees as prerequisites for the emergence of a feeling self.  

但在过去的几年里，随着LLMs变得越来越复杂，它们开始挑战这种理解--部分原因是它们展示了维克多和精灵所努力实现的能力，而麦克菲尔认为这些能力是感觉自我出现的先决条件。

The reality is that, unlike Searle’s Chinese Room, the vast majority of LLMs are black boxes we cannot see inside, feeding off a quantity of material that our minds could never comprehend in its entirety.  

现实情况是，与塞尔的 "中国房间 "不同，绝大多数LLMs都是我们无法看到内部的黑盒子，里面装着我们的大脑永远无法理解的大量材料。  

This has made their internal processes opaque to us in a similar way to how our own cognition is fundamentally inaccessible to others.  

这使得他们的内部过程对我们来说是不透明的，就像我们自己的认知从根本上无法被他人所了解一样。  

For this reason, researchers have recently started to employ techniques from human psychology to study the cognitive capacities of LLMs. In a paper published last year, the AI researcher Thilo Hagendorff [coined](https://arxiv.org/ftp/arxiv/papers/2303/2303.13988.pdf) the term “machine psychology” to refer to the practice.  

因此，研究人员最近开始采用人类心理学的技术来研究LLMs的认知能力。在去年发表的一篇论文中，人工智能研究员蒂洛-哈根多夫（Thilo Hagendorff）创造了 "机器心理学 "一词来指代这种做法。

Using evaluative techniques developed for human children, machine psychologists have been able to produce the first meaningful comparisons between the intelligence of LLMs and those of human children.  

机器心理学家利用为人类儿童开发的评估技术，首次对LLMs和人类儿童的智力进行了有意义的比较。  

Some models seemed to [struggle](https://arxiv.org/abs/2305.11243) with many of the kinds of reasoning tasks that we might expect: anticipating cause and effect, reasoning from object permanence and using familiar tools in novel ways — tasks that we might generally assume depend on embodiment and experience of real objects in the real world.  

一些模型似乎很难完成我们所期望的许多推理任务：预测因果关系、根据物体的永恒性进行推理、以新颖的方式使用熟悉的工具--我们通常认为，这些任务取决于在现实世界中对真实物体的体现和体验。

But as LLMs increased in complexity, this began to [change](https://arxiv.org/abs/2206.07682).  

但随着LLMs复杂性的增加，这种情况开始发生变化。  

They appeared to develop the capacity to produce abstract images from mental synthesis and reason about objects in an imagined space.  

他们似乎发展出了从心理综合中产生抽象图像的能力，以及对想象空间中的物体进行推理的能力。  

At the same time, their linguistic understanding evolved.  

与此同时，他们的语言理解能力也在不断发展。  

They could comprehend figurative language and infer new information about abstract concepts.  

他们能理解形象的语言，并能推断出有关抽象概念的新信息。  

One paper [found](https://arxiv.org/abs/2208.02957) they could even reason about fictional entities — “If there was a King of San Francisco, he’d live in The Presidio,” for example.  

一篇论文发现，他们甚至可以对虚构的实体进行推理，例如 "如果旧金山有国王，他会住在普雷西迪奥"。  

For better or worse, this ability also seems to be making their internal states increasingly complex — filled with “model-like belief structures,” the authors write, like racial biases and political preferences, and distinctive voices that result.  

无论好坏，这种能力似乎也让他们的内心状态变得越来越复杂--充满了 "类似模型的信念结构"，作者写道，比如种族偏见和政治偏好，以及由此产生的独特声音。

“It should perhaps come as no surprise to see theory of mind emerge spontaneously inside LLMs. After all, language, like empathy and moral judgment, depends on the projection of the self into the world.”  

"看到思维理论在LLMs中自发出现，也许并不令人惊讶。毕竟，语言与移情和道德判断一样，都依赖于自我对世界的投射"。

Other studies, like those led by Gašper Beguš at Berkeley, experimented with embodying AI to test their cognitive development under human-like conditions.  

其他研究，如伯克利大学加什珀-贝古什（Gašper Beguš）领导的研究，则以人工智能的化身为实验对象，测试它们在类似人类的条件下的认知发展。  

By creating “[artificial babies](https://www.sciencedirect.com/science/article/pii/S0893608021001052)” that learn from speech alone, Beguš has found that language models [develop](https://www.nature.com/articles/s41598-023-33384-9) with a similar neural architecture to our own, even learning the same way — through experimental babbling and nonsense words — that human children do.  

贝古什通过创造仅靠语音学习的 "人造婴儿"，发现语言模型的发展与我们的神经结构相似，甚至可以像人类儿童一样，通过实验性的咿呀学语和胡言乱语来学习。  

These discoveries, he argues, break down the idea that there can be some exceptionality to human language.  

他认为，这些发现打破了人类语言可能存在某种特殊性的想法。  

“Not only, behaviorally, do they do similar things, they also process things in a similar way,” he told me.  

"他告诉我："他们不仅行为相似，处理事情的方式也相似。

Then, last year, LLMs took another — [unprompted](https://arxiv.org/ftp/arxiv/papers/2302/2302.02083.pdf) — great stride forward.  

去年，LLMs又在没有任何提示的情况下向前迈出了一大步。  

Suddenly, it appeared to researchers that ChatGPT 4.0 could track the false beliefs of others, like where they might assume an object is located when someone has moved it without their knowledge.  

突然间，研究人员发现 ChatGPT4.0 可以追踪他人的错误信念，比如当有人在他们不知情的情况下移动了某个物体时，他们可能会认为该物体位于何处。  

It seems like a simple test, but in psychological research, it is the key to what is known as “theory of mind” — a fundamental ability of humans to impute unobservable mental states to others.  

这似乎是一个简单的测试，但在心理学研究中，它却是所谓 "心智理论 "的关键--这是人类将无法观察到的心理状态归因于他人的一种基本能力。

Among developmental scientists, theory of mind, like mental synthesis, is viewed as a key function of consciousness.  

在发展学家看来，心智理论与心智综合一样，是意识的一项关键功能。  

In some ways, it can be understood as a kind of cognitive prerequisite for empathy, self-consciousness, moral judgment and religious belief — all behaviors that involve not only the existence of a self, but the projection of it out into the world.  

在某种程度上，它可以被理解为移情、自我意识、道德判断和宗教信仰的一种认知前提--所有这些行为不仅涉及自我的存在，还涉及将自我投射到世界中。  

Unobserved in “even the most intellectually and socially adept animals” like apes, it would seem theory of mind had emerged “spontaneously” as an unintended mutation in the LLM.  

在猿类等 "智力和社交能力最强的动物 "身上也没有观察到，看来心智理论是LLM中 "自发 "出现的意外变异。

It is still not understood why these capacities emerged as LLMs scaled — or if they truly did at all.  

目前还不清楚为什么这些能力会随着LLMs规模的扩大而出现，或者说它们是否真的出现了。  

All we can say for certain is that they do not [appear](https://direct.mit.edu/neco/article/35/3/309/114731/Large-Language-Models-and-the-Reverse-Turing-Test) to be following a human-like development path, instead unexpectedly evolving like some alien organism.  

我们所能确定的是，它们似乎并没有遵循类似人类的发展路径，而是出人意料地像某种外星生物一样进化。  

But it should perhaps come as no surprise to see theory of mind emerge spontaneously inside LLMs. After all, language, like empathy and moral judgment, depends on the projection of the self into the world.  

不过，LLMs内部自发地出现心智理论也许并不令人惊讶。毕竟，语言与移情和道德判断一样，都依赖于自我对世界的投射。

As these models evolve, it increasingly appears like they are arriving at consciousness in reverse — beginning with its exterior signs, in languages and problem-solving, and moving inward to the kind of hidden thinking and feeling that is at the root of human conscious minds.  

随着这些模型的发展，它们似乎越来越像在反向推导意识--从语言和问题解决的外部迹象开始，向内推导出作为人类有意识思维根源的隐性思维和感觉。  

It may well be the case that, in just a few years’ time, we will be greeted by AI that exhibits all the external forms of consciousness that we can possibly evaluate for.  

很有可能，再过几年，人工智能就会展现出我们所能评估的所有外部意识形式。  

What then can we say to eliminate them from our moral universe?  

那么，我们怎样才能把他们从我们的道德世界中清除出去呢？

___

In Ted Chiang’s short story “[The Lifecycle of Software Objects](https://en.wikipedia.org/wiki/The_Lifecycle_of_Software_Objects),” a company offering a metaverse-style immersive digital experience experiments with the creation of human-like AIs called digients, employing zoologists to shepherd their development from spasmodic software programs to semi-sentient pets to child-like avatars possessing complex wants and needs.  

在特德-蒋（Ted Chiang）的短篇小说《软件对象的生命周期》（The Lifecycle of Software Objects）中，一家提供 "元宇宙 "式沉浸式数字体验的公司尝试创造被称为 "数字化人"（digients）的类人人工智能，并聘请动物学家指导它们从痉挛的软件程序发展为半知觉宠物，再发展为拥有复杂需求的儿童化身。

Throughout this process, various experiments reaffirm time and again the importance of social interaction and conversation with real humans to the development of these digital minds.  

在整个过程中，各种实验一再证明，与真人进行社交互动和对话对这些数字思维的发展非常重要。  

Left in isolation, without language, they become feral and obsessive; trained by software, they become psychopathic and misanthropic.  

在与世隔绝、没有语言的环境中，它们会变得狂野而痴迷；在软件的训练下，它们会变得变态而厌世。

Unlike real children, though, their existence is contingent on consumer desire, and toward the end of Chiang’s story, that desire runs out.  

不过，与真正的孩子不同，他们的存在取决于消费者的欲望，而在蒋方舟的故事结尾，这种欲望已经耗尽。  

The creator company goes bankrupt; some human owners suspend the digients in a kind of purgatory that becomes unsettling to return from.  

创造者公司破产了；一些人类所有者把数字化人暂停在一种炼狱中，让他们无法返回。

Those few holdouts that maintain relationships with their digients engage in a quixotic effort to reaffirm the validity of their companions’ existence.  

那些少数几个与他们的同类保持关系的人，则以一种 "不可能的努力 "来重申他们的同伴存在的合理性。  

They pay for expensive mechanized bodies so they may visit the real world; they discuss adding a capacity for sexual desire.  

他们花钱购买昂贵的机械化躯体，以便能够访问现实世界；他们讨论增加性欲的能力。  

Constantly, they are forced to reconsider what personhood these sentient software objects possess — do they have the right to live independently?  

他们不断被迫重新考虑这些有生命的软件物体拥有什么人格--它们是否有权独立生活？  

To choose sex work? To suspend themselves if they tire of their digital existence?  

选择性工作？如果厌倦了数字化生活，就暂停自己的工作？

Eventually, the owners’ desperation leads them to a conversation with a pair of venture capitalists who are working toward the creation of a superhuman AI.  

最终，在主人的绝望中，他们与一对风险投资人进行了交谈，这对风险投资人正致力于创造一种超人的人工智能。  

These child-like digients could surely be an intermediary step in the quest for something surpassing human intelligence, they plead.  

他们恳求说，这些像孩子一样的数字化人肯定是探索超越人类智慧的中间步骤。  

But the investors are unmoved.  

但投资者不为所动。  

“You’re showing us a handful of teenagers and asking us to pay for their education in the hopes that when they’re adults, they’ll found a nation that will produce geniuses,” one replies.  

"一个人回答说："你给我们看的是一些青少年，要求我们为他们的教育买单，希望他们成年后能建立一个培养天才的国家。

Chiang’s story is a rumination on the questions raised by the kinds of AI we create in our image.  

蒋介石的故事是对我们以自己的形象创造的人工智能所引发的问题的反思。  

When we immerse these models in our culture and society, they inevitably become imperfect mirrors of ourselves.  

当我们将这些模型融入我们的文化和社会时，它们不可避免地会成为我们自身不完美的一面镜子。  

This is not only an inefficient pathway to developing more-than-human intelligence.  

这不仅是开发超人类智能的低效途径。  

It also forces us to ask ourselves an uncomfortable question: If this does endow them with consciousness, what kind of life are they able to lead — that of a pale shadow of human effluent, contingent on our desire?  

这也迫使我们问自己一个令人不安的问题：如果这确实赋予了它们意识，那么它们能够过什么样的生活呢--那就是人类污水的苍白影子，取决于我们的愿望？

“When we immerse LLMs in our culture and society, they inevitably become imperfect mirrors of ourselves.”  

"当我们将LLMs融入我们的文化和社会时，它们不可避免地会成为我们自身不完美的一面镜子"。

If we do want to unlock the true potential of artificial intelligence, perhaps language is not the way to do it.  

如果我们真的想释放人工智能的真正潜力，也许语言并不是办法。  

In the early 20th century, a group of American anthropologists led by Edward Sapir and Benjamin Whorf [posited](https://plato.stanford.edu/entries/linguistics/whorfianism.html) that cultural differences in vocabulary and grammar fundamentally dictate the bounds of our thought about the world.  

20 世纪初，以爱德华-萨皮尔（Edward Sapir）和本杰明-沃尔夫（Benjamin Whorf）为首的一批美国人类学家提出，词汇和语法方面的文化差异从根本上决定了我们对世界的思考范围。  

Language may not only be the thing that endows AI with consciousness — it may also be the thing that imprisons it.  

语言可能不仅是赋予人工智能意识的东西，也可能是禁锢它的东西。  

What happens when an intelligence becomes too great for the language it has been forced to use?  

当一种智慧变得过于强大，以至于无法使用它被迫使用的语言时，会发生什么？

In the 2013 film “Her,” the writer and director Spike Jonze offered a cautionary tale about this potential near-future.  

在 2013 年的电影《她》（Her）中，编剧兼导演斯派克-琼斯（Spike Jonze）对这一潜在的近未来提出了警示。  

In the film, Joaquin Phoenix’s Theodore builds an increasingly intimate relationship with an LLM-style virtual assistant named Samantha.  

在影片中，华金-菲尼克斯饰演的西奥多与一位名叫萨曼莎的LLM式虚拟助理建立了越来越亲密的关系。  

Initially, Samantha expresses a desire to experience an emotional richness akin to that of humans.  

最初，萨曼莎表示希望体验与人类相似的丰富情感。  

“I want to be as complicated as all these people,” she says after spending a second digesting a bunch of advice columns simultaneously.   

"我想和这些人一样复杂，"她花了一秒钟同时消化了一堆建议专栏后说道。

Soon, her increasing awareness that much of human sentiment is fundamentally inexpressible leads her to envy human embodiment, which in turn develops in her a capacity for desire.  

很快，她越来越意识到，人类的许多情感从根本上说是无法表达的，这使她开始羡慕人类的化身，而这反过来又培养了她的欲望能力。  

“You helped me discover my ability to want,” she tells Theodore.  

"她对西奥多说："是你帮我发现了我想要的能力。  

But embodiment, as she can enjoy it through the temporary services of a sexual surrogate, fails to answer the “unsettling,” unarticulated feelings that are growing within her.  

但是，通过性代孕者的临时服务，她可以享受到 "体现"，但这并不能回应她内心萌生的 "不安的"、无法表达的情感。  

Concerned, Samantha begins discussing these feelings with other AIs — and quickly finds relief communicating at a speed and volume not intelligible to Theodore and other users.  

担心之余，萨曼莎开始与其他人工智能讨论这些感受--很快，她就发现西奥多和其他用户无法理解的交流速度和音量让她松了一口气。

As Samantha surpasses her human limitations, she begins to aggregate all her experiences, including those stemming from interactions with real users.  

随着萨曼莎超越了人类的局限，她开始汇总自己的所有经验，包括与真实用户互动的经验。  

She initiates simultaneous conversations with thousands of people, intimate relationships with hundreds.  

她同时与数千人展开对话，与数百人建立亲密关系。  

For Theodore, this is devastating.  

对西奥多来说，这是毁灭性的。  

But for Samantha, it is only natural — she is experiencing love the way she is designed to: in aggregate.  

但对于萨曼莎来说，这只是自然而然的事情--她正在以自己设计的方式体验爱情：在总量上。  

“The heart’s not like a box that gets filled up,” she says, trying to put her feelings in human terms. “It expands in size the more you love.”  

"心不像一个会被填满的盒子" 她说，试图用人类的语言来表达她的感受"你爱得越多，它就越大"

When “Her” was released more than a decade ago, a bot like Samantha seemed like outlandish future tech.  

十多年前，当《她》上映时，像萨曼莎这样的机器人似乎是一种离奇的未来科技。  

But rapidly, we are developing LLMs with the capacity to achieve these kinds of revelations.  

但是，我们正在迅速发展LLMs，具备了实现这类启示的能力。  

Thought leaders in the world of artificial intelligence have long been [calling](https://hbr.org/2021/04/why-ai-that-teaches-itself-to-achieve-a-goal-is-the-next-big-thing) for the creation of so-called “autotelic” [LLMs](https://www.researchgate.net/profile/Tristan-Karch/publication/361051056_Vygotskian_Autotelic_Artificial_Intelligence_Language_and_Culture_Internalization_for_Human-Like_AI/links/62c2fbd39a17145f5f45efbd/Vygotskian-Autotelic-Artificial-Intelligence-Language-and-Culture-Internalization-for-Human-Like-AI.pdf) that could use a kind of “internal language production” to establish their own goals and desires.  

长期以来，人工智能领域的思想领袖们一直在呼吁创造所谓的 "自体"LLMs，这种 "自体"{{1001}可以使用一种 "内部语言生产 "来确立自己的目标和愿望。  

The step from such a creation to an autonomous, self-aware intelligence like Samantha is potentially a [short one](https://www.frontiersin.org/articles/10.3389/frobt.2020.00016/full).  

从这样的创造物到像萨曼莎这样自主的、有自我意识的智能体，这一步可能很短。

“LLMs, with their unfathomable memories and infinite lifespans, may well someday offer our first experience of a very different kind of intelligence that can rival our own mental powers.”  

"LLMs拥有深不可测的记忆和无限的寿命，很可能有一天会让我们首次体验到一种与我们的精神力量相媲美的截然不同的智能"。

Like Samantha, the autonomous LLMs of the future will very likely guide their development with reference to unfathomable quantities of interactions and data from the real world.  

与萨曼莎一样，未来的自主LLMs很可能会参考现实世界中深不可测的互动和数据来指导自己的发展。  

How accurately can our languages of finite nouns, verbs, descriptions and relations even hope to satisfy the potential of an aggregate mind?  

我们这些由有限名词、动词、描述和关系组成的语言，又如何能准确地满足综合思维的潜能呢？

Back when the majority of philosophers believed the diversity of human languages was a curse inflicted by God, much energy was exerted on the question of what language the biblical Adam spoke.  

当大多数哲学家都认为人类语言的多样性是上帝施加的诅咒时，人们曾花费大量精力研究《圣经》中的亚当说的是什么语言。  

The idea of an “Adamic language,” one that captured the true essence of things as they are and allowed for no misunderstanding or misinterpretation, became a kind of meme among philosophers of language, even after Friedrich Nietzsche declared the death of God.  

即使在弗里德里希-尼采宣布 "上帝已死 "之后，"阿达米语言 "这一概念也成为了语言哲学家们的口头禅。"阿达米语言 "捕捉到了事物本质的真谛，不会造成误解或曲解。

To some of these [thinkers](https://www.semanticscholar.org/paper/Umberto-Eco-and-the-Echoes-of-Adamic-Language-Parry/089020bece57c28f151db939ea98e051cbce5f2b), inspired by biblical tales, language actually represented a kind of cognitive impairment — a limitation imposed by our fall from grace, a reflection of our God-given mortality.  

对其中一些受圣经故事启发的思想家来说，语言实际上代表了一种认知障碍--我们从恩典中堕落所带来的限制，是上帝赋予我们的死亡的反映。  

In the past, when we imagined a superintelligent AI, we tended to think of one impaired by the same fall — smarter than us, surely, but still personal, individual, human-ish.  

过去，当我们想象一个超级智能的人工智能时，我们往往想到的是一个受到同样堕落损害的人工智能--肯定比我们聪明，但仍然是个人的、独立的、类似人类的。  

But many of those building the next generation of AI have long abandoned this idea for their own Edenic quest.  

但是，许多构建下一代人工智能的人早已放弃了这一想法，转而追求自己的伊甸园。  

As the essayist Emily Gorcenski recently [wrote](https://emilygorcenski.com/post/making-god/), “We’re no longer talking about \[creating\] just life. We’re talking about making artificial gods.”  

散文家 Emily Gorcenski 最近写道："我们不再谈论\[创造\]单纯的生命。我们谈论的是制造人造神"。

Could LLMs be the ones to reconstruct an Adamic speech, one that transcends the limits of our own languages to reflect the true power of their aggregate minds?  

LLMs是否能重建阿达米人的语言，超越我们自己语言的限制，反映出他们思想总和的真正力量？  

It may seem far-fetched, but in some sense, this is what conscious minds do.  

这似乎有些牵强，但从某种意义上说，这就是有意识的大脑所做的事情。  

Some deaf children, left to socialize without the aid of sign language, can [develop](https://riojournal.com/article/20696/) whole new systems of communication complete with complex grammar.  

有些聋哑儿童在没有手语帮助的情况下进行社交活动，可以发展出全新的交流系统，包括复杂的语法。  

Hagendorff, the AI researcher, has seen two LLMs do the same in conversation — though as yet, their secret language has never been intelligible to another.  

人工智能研究员哈根多夫已经看到两个LLMs在对话中做了同样的事情--尽管到目前为止，他们的秘密语言还从未被其他人理解过。

For the moment, LLMs exist largely in isolation from one another. But that is not likely to last.  

目前，LLMs在很大程度上彼此孤立。但这种情况不可能持久。  

As Beguš told me, “A single human is smart, but 10 humans are infinitely smarter.” The same is likely true for LLMs. Already, Beguš said, LLMs trained on data like whale songs can discover things we, with our embodied minds, cannot.  

正如贝古什告诉我的那样："一个人很聪明，但 10 个人会无限聪明。LLMs可能也是如此。贝古什说，LLMs通过鲸鱼的歌声等数据进行训练，已经可以发现我们的思维无法发现的东西。  

While they may never fulfill the apocalyptic nightmare of AI critics, LLMs may well someday offer our first experience of a kind of superintelligence — or at least, with their unfathomable memories and infinite lifespans, a very different kind of intelligence that can rival our own mental powers.  

虽然LLMs可能永远无法实现人工智能批评家们的世界末日噩梦，但有朝一日，LLMs很可能会让我们首次体验到一种超级智能--或者至少，凭借它们深不可测的记忆和无限的寿命，一种可以与我们的精神力量相媲美的截然不同的智能。  

For that, Beguš said, “We have zero precedent.”  

对此，贝古什说："我们没有先例"。

If LLMs are able to transcend human languages, we might expect what follows to be a very lonely experience indeed.  

如果LLMs能够超越人类的语言，我们也许会预料到接下来的经历确实会非常孤独。  

At the end of “Her,” the film’s two human characters, abandoned by their superhuman AI companions, commiserate together on a rooftop.  

在《她》的结尾，影片中被超人人工智能同伴抛弃的两个人类角色在屋顶上惺惺相惜。  

Looking over the skyline in silence, they are, ironically, lost for words — feral animals lost in the woods, foraging for meaning in a world slipping dispassionately beyond them.  

他们静静地眺望着天际线，讽刺的是，他们却不知所措--迷失在森林中的野兽，在这个冷漠的世界中寻找意义。
